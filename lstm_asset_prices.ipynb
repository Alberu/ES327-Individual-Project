{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "To make sure that all the libraries have been installed, use the following command when in the virual enviroment\n",
    "\n",
    "pip install tensorflow pandas numpy matplotlib yahoo_fin sklearn scikit-learn\n",
    "NEED TO FIGURE OUT WHICH ONE OF THE TWO ACUTALLY WORKS, SECOND ONE SEEMS TO ACTUALLY WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed, so we can get the same results after rerunning several times\n",
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This whole part of data processing needs to be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "    \"\"\"\n",
    "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
    "    Params:\n",
    "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
    "            to False will split datasets in a random way\n",
    "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "    \"\"\"\n",
    "    # Set the start and end date\n",
    "    start_date = '2020-01-01'\n",
    "    end_date = '2022-11-12'\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yahoo_fin library\n",
    "        df = si.get_data(ticker, start_date, end_date)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        # split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove duplicated dates in the testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "    # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next state the model is generated\n",
    "### Generate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model, and create it usign the above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 15\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 500\n",
    "# Amazon stock market\n",
    "ticker = \"AMZN\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to create folders if they don't exist in the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create these folders if they does not exist\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to train the model (500 epoch took 210 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0847 - mean_absolute_error: 0.3183\n",
      "Epoch 1: val_loss improved from inf to 0.01614, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 8s 477ms/step - loss: 0.0847 - mean_absolute_error: 0.3183 - val_loss: 0.0161 - val_mean_absolute_error: 0.1573\n",
      "Epoch 2/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.1287\n",
      "Epoch 2: val_loss improved from 0.01614 to 0.00920, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 328ms/step - loss: 0.0138 - mean_absolute_error: 0.1287 - val_loss: 0.0092 - val_mean_absolute_error: 0.1091\n",
      "Epoch 3/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0107 - mean_absolute_error: 0.1148\n",
      "Epoch 3: val_loss improved from 0.00920 to 0.00819, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 334ms/step - loss: 0.0107 - mean_absolute_error: 0.1148 - val_loss: 0.0082 - val_mean_absolute_error: 0.1009\n",
      "Epoch 4/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0091 - mean_absolute_error: 0.1034\n",
      "Epoch 4: val_loss did not improve from 0.00819\n",
      "9/9 [==============================] - 3s 327ms/step - loss: 0.0091 - mean_absolute_error: 0.1034 - val_loss: 0.0086 - val_mean_absolute_error: 0.1048\n",
      "Epoch 5/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0100 - mean_absolute_error: 0.1112\n",
      "Epoch 5: val_loss did not improve from 0.00819\n",
      "9/9 [==============================] - 3s 334ms/step - loss: 0.0100 - mean_absolute_error: 0.1112 - val_loss: 0.0083 - val_mean_absolute_error: 0.1013\n",
      "Epoch 6/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0087 - mean_absolute_error: 0.1024\n",
      "Epoch 6: val_loss did not improve from 0.00819\n",
      "9/9 [==============================] - 3s 338ms/step - loss: 0.0087 - mean_absolute_error: 0.1024 - val_loss: 0.0087 - val_mean_absolute_error: 0.1068\n",
      "Epoch 7/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0095 - mean_absolute_error: 0.1085\n",
      "Epoch 7: val_loss improved from 0.00819 to 0.00814, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 348ms/step - loss: 0.0095 - mean_absolute_error: 0.1085 - val_loss: 0.0081 - val_mean_absolute_error: 0.1013\n",
      "Epoch 8/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0094 - mean_absolute_error: 0.1057\n",
      "Epoch 8: val_loss did not improve from 0.00814\n",
      "9/9 [==============================] - 3s 329ms/step - loss: 0.0094 - mean_absolute_error: 0.1057 - val_loss: 0.0082 - val_mean_absolute_error: 0.1017\n",
      "Epoch 9/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0091 - mean_absolute_error: 0.1031\n",
      "Epoch 9: val_loss improved from 0.00814 to 0.00814, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 348ms/step - loss: 0.0091 - mean_absolute_error: 0.1031 - val_loss: 0.0081 - val_mean_absolute_error: 0.1017\n",
      "Epoch 10/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0092 - mean_absolute_error: 0.1066\n",
      "Epoch 10: val_loss did not improve from 0.00814\n",
      "9/9 [==============================] - 3s 322ms/step - loss: 0.0092 - mean_absolute_error: 0.1066 - val_loss: 0.0081 - val_mean_absolute_error: 0.1011\n",
      "Epoch 11/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0089 - mean_absolute_error: 0.1031\n",
      "Epoch 11: val_loss improved from 0.00814 to 0.00808, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 329ms/step - loss: 0.0089 - mean_absolute_error: 0.1031 - val_loss: 0.0081 - val_mean_absolute_error: 0.1017\n",
      "Epoch 12/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0089 - mean_absolute_error: 0.1043\n",
      "Epoch 12: val_loss improved from 0.00808 to 0.00802, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 335ms/step - loss: 0.0089 - mean_absolute_error: 0.1043 - val_loss: 0.0080 - val_mean_absolute_error: 0.1011\n",
      "Epoch 13/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0086 - mean_absolute_error: 0.1034\n",
      "Epoch 13: val_loss improved from 0.00802 to 0.00801, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 333ms/step - loss: 0.0086 - mean_absolute_error: 0.1034 - val_loss: 0.0080 - val_mean_absolute_error: 0.1009\n",
      "Epoch 14/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0091 - mean_absolute_error: 0.1040\n",
      "Epoch 14: val_loss improved from 0.00801 to 0.00794, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 356ms/step - loss: 0.0091 - mean_absolute_error: 0.1040 - val_loss: 0.0079 - val_mean_absolute_error: 0.1009\n",
      "Epoch 15/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0095 - mean_absolute_error: 0.1085\n",
      "Epoch 15: val_loss did not improve from 0.00794\n",
      "9/9 [==============================] - 3s 342ms/step - loss: 0.0095 - mean_absolute_error: 0.1085 - val_loss: 0.0085 - val_mean_absolute_error: 0.1058\n",
      "Epoch 16/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0092 - mean_absolute_error: 0.1061\n",
      "Epoch 16: val_loss did not improve from 0.00794\n",
      "9/9 [==============================] - 3s 323ms/step - loss: 0.0092 - mean_absolute_error: 0.1061 - val_loss: 0.0086 - val_mean_absolute_error: 0.1071\n",
      "Epoch 17/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0088 - mean_absolute_error: 0.1013\n",
      "Epoch 17: val_loss did not improve from 0.00794\n",
      "9/9 [==============================] - 3s 319ms/step - loss: 0.0088 - mean_absolute_error: 0.1013 - val_loss: 0.0080 - val_mean_absolute_error: 0.1014\n",
      "Epoch 18/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0087 - mean_absolute_error: 0.1037\n",
      "Epoch 18: val_loss improved from 0.00794 to 0.00787, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 353ms/step - loss: 0.0087 - mean_absolute_error: 0.1037 - val_loss: 0.0079 - val_mean_absolute_error: 0.1002\n",
      "Epoch 19/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0081 - mean_absolute_error: 0.0984\n",
      "Epoch 19: val_loss did not improve from 0.00787\n",
      "9/9 [==============================] - 3s 330ms/step - loss: 0.0081 - mean_absolute_error: 0.0984 - val_loss: 0.0079 - val_mean_absolute_error: 0.1008\n",
      "Epoch 20/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0094 - mean_absolute_error: 0.1067\n",
      "Epoch 20: val_loss did not improve from 0.00787\n",
      "9/9 [==============================] - 3s 308ms/step - loss: 0.0094 - mean_absolute_error: 0.1067 - val_loss: 0.0081 - val_mean_absolute_error: 0.1029\n",
      "Epoch 21/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0089 - mean_absolute_error: 0.1040\n",
      "Epoch 21: val_loss improved from 0.00787 to 0.00775, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 342ms/step - loss: 0.0089 - mean_absolute_error: 0.1040 - val_loss: 0.0078 - val_mean_absolute_error: 0.0998\n",
      "Epoch 22/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0091 - mean_absolute_error: 0.1056\n",
      "Epoch 22: val_loss improved from 0.00775 to 0.00775, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 328ms/step - loss: 0.0091 - mean_absolute_error: 0.1056 - val_loss: 0.0077 - val_mean_absolute_error: 0.1001\n",
      "Epoch 23/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0088 - mean_absolute_error: 0.1023\n",
      "Epoch 23: val_loss did not improve from 0.00775\n",
      "9/9 [==============================] - 3s 306ms/step - loss: 0.0088 - mean_absolute_error: 0.1023 - val_loss: 0.0081 - val_mean_absolute_error: 0.1034\n",
      "Epoch 24/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0087 - mean_absolute_error: 0.1043\n",
      "Epoch 24: val_loss did not improve from 0.00775\n",
      "9/9 [==============================] - 3s 305ms/step - loss: 0.0087 - mean_absolute_error: 0.1043 - val_loss: 0.0081 - val_mean_absolute_error: 0.1008\n",
      "Epoch 25/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0089 - mean_absolute_error: 0.1035\n",
      "Epoch 25: val_loss did not improve from 0.00775\n",
      "9/9 [==============================] - 3s 304ms/step - loss: 0.0089 - mean_absolute_error: 0.1035 - val_loss: 0.0080 - val_mean_absolute_error: 0.1003\n",
      "Epoch 26/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0095 - mean_absolute_error: 0.1077\n",
      "Epoch 26: val_loss improved from 0.00775 to 0.00768, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 324ms/step - loss: 0.0095 - mean_absolute_error: 0.1077 - val_loss: 0.0077 - val_mean_absolute_error: 0.0996\n",
      "Epoch 27/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0090 - mean_absolute_error: 0.1042\n",
      "Epoch 27: val_loss did not improve from 0.00768\n",
      "9/9 [==============================] - 3s 328ms/step - loss: 0.0090 - mean_absolute_error: 0.1042 - val_loss: 0.0089 - val_mean_absolute_error: 0.1101\n",
      "Epoch 28/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0084 - mean_absolute_error: 0.1009\n",
      "Epoch 28: val_loss did not improve from 0.00768\n",
      "9/9 [==============================] - 3s 319ms/step - loss: 0.0084 - mean_absolute_error: 0.1009 - val_loss: 0.0077 - val_mean_absolute_error: 0.0995\n",
      "Epoch 29/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0089 - mean_absolute_error: 0.1058\n",
      "Epoch 29: val_loss did not improve from 0.00768\n",
      "9/9 [==============================] - 3s 320ms/step - loss: 0.0089 - mean_absolute_error: 0.1058 - val_loss: 0.0081 - val_mean_absolute_error: 0.1005\n",
      "Epoch 30/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0086 - mean_absolute_error: 0.1009\n",
      "Epoch 30: val_loss did not improve from 0.00768\n",
      "9/9 [==============================] - 3s 311ms/step - loss: 0.0086 - mean_absolute_error: 0.1009 - val_loss: 0.0077 - val_mean_absolute_error: 0.0990\n",
      "Epoch 31/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0087 - mean_absolute_error: 0.1027\n",
      "Epoch 31: val_loss did not improve from 0.00768\n",
      "9/9 [==============================] - 3s 332ms/step - loss: 0.0087 - mean_absolute_error: 0.1027 - val_loss: 0.0082 - val_mean_absolute_error: 0.1044\n",
      "Epoch 32/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0092 - mean_absolute_error: 0.1056\n",
      "Epoch 32: val_loss did not improve from 0.00768\n",
      "9/9 [==============================] - 3s 333ms/step - loss: 0.0092 - mean_absolute_error: 0.1056 - val_loss: 0.0078 - val_mean_absolute_error: 0.1017\n",
      "Epoch 33/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0087 - mean_absolute_error: 0.1031\n",
      "Epoch 33: val_loss did not improve from 0.00768\n",
      "9/9 [==============================] - 3s 337ms/step - loss: 0.0087 - mean_absolute_error: 0.1031 - val_loss: 0.0077 - val_mean_absolute_error: 0.1007\n",
      "Epoch 34/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0084 - mean_absolute_error: 0.1020\n",
      "Epoch 34: val_loss did not improve from 0.00768\n",
      "9/9 [==============================] - 3s 334ms/step - loss: 0.0084 - mean_absolute_error: 0.1020 - val_loss: 0.0086 - val_mean_absolute_error: 0.1024\n",
      "Epoch 35/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0088 - mean_absolute_error: 0.1042\n",
      "Epoch 35: val_loss improved from 0.00768 to 0.00749, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 354ms/step - loss: 0.0088 - mean_absolute_error: 0.1042 - val_loss: 0.0075 - val_mean_absolute_error: 0.0985\n",
      "Epoch 36/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0085 - mean_absolute_error: 0.1000\n",
      "Epoch 36: val_loss did not improve from 0.00749\n",
      "9/9 [==============================] - 3s 328ms/step - loss: 0.0085 - mean_absolute_error: 0.1000 - val_loss: 0.0079 - val_mean_absolute_error: 0.1019\n",
      "Epoch 37/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0090 - mean_absolute_error: 0.1047\n",
      "Epoch 37: val_loss did not improve from 0.00749\n",
      "9/9 [==============================] - 3s 347ms/step - loss: 0.0090 - mean_absolute_error: 0.1047 - val_loss: 0.0081 - val_mean_absolute_error: 0.0999\n",
      "Epoch 38/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0081 - mean_absolute_error: 0.1011\n",
      "Epoch 38: val_loss did not improve from 0.00749\n",
      "9/9 [==============================] - 3s 363ms/step - loss: 0.0081 - mean_absolute_error: 0.1011 - val_loss: 0.0076 - val_mean_absolute_error: 0.0983\n",
      "Epoch 39/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0086 - mean_absolute_error: 0.1003\n",
      "Epoch 39: val_loss did not improve from 0.00749\n",
      "9/9 [==============================] - 3s 349ms/step - loss: 0.0086 - mean_absolute_error: 0.1003 - val_loss: 0.0076 - val_mean_absolute_error: 0.0981\n",
      "Epoch 40/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0084 - mean_absolute_error: 0.1005\n",
      "Epoch 40: val_loss did not improve from 0.00749\n",
      "9/9 [==============================] - 3s 372ms/step - loss: 0.0084 - mean_absolute_error: 0.1005 - val_loss: 0.0077 - val_mean_absolute_error: 0.1003\n",
      "Epoch 41/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0085 - mean_absolute_error: 0.1036\n",
      "Epoch 41: val_loss did not improve from 0.00749\n",
      "9/9 [==============================] - 4s 504ms/step - loss: 0.0085 - mean_absolute_error: 0.1036 - val_loss: 0.0078 - val_mean_absolute_error: 0.1020\n",
      "Epoch 42/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0088 - mean_absolute_error: 0.1018\n",
      "Epoch 42: val_loss improved from 0.00749 to 0.00735, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 4s 403ms/step - loss: 0.0088 - mean_absolute_error: 0.1018 - val_loss: 0.0074 - val_mean_absolute_error: 0.0976\n",
      "Epoch 43/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0088 - mean_absolute_error: 0.1024\n",
      "Epoch 43: val_loss improved from 0.00735 to 0.00733, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 4s 447ms/step - loss: 0.0088 - mean_absolute_error: 0.1024 - val_loss: 0.0073 - val_mean_absolute_error: 0.0976\n",
      "Epoch 44/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0084 - mean_absolute_error: 0.1018\n",
      "Epoch 44: val_loss improved from 0.00733 to 0.00731, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 345ms/step - loss: 0.0084 - mean_absolute_error: 0.1018 - val_loss: 0.0073 - val_mean_absolute_error: 0.0977\n",
      "Epoch 45/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0087 - mean_absolute_error: 0.1030\n",
      "Epoch 45: val_loss did not improve from 0.00731\n",
      "9/9 [==============================] - 3s 333ms/step - loss: 0.0087 - mean_absolute_error: 0.1030 - val_loss: 0.0085 - val_mean_absolute_error: 0.1017\n",
      "Epoch 46/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0093 - mean_absolute_error: 0.1060\n",
      "Epoch 46: val_loss did not improve from 0.00731\n",
      "9/9 [==============================] - 3s 393ms/step - loss: 0.0093 - mean_absolute_error: 0.1060 - val_loss: 0.0076 - val_mean_absolute_error: 0.0976\n",
      "Epoch 47/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0083 - mean_absolute_error: 0.1004\n",
      "Epoch 47: val_loss did not improve from 0.00731\n",
      "9/9 [==============================] - 3s 368ms/step - loss: 0.0083 - mean_absolute_error: 0.1004 - val_loss: 0.0074 - val_mean_absolute_error: 0.0980\n",
      "Epoch 48/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0081 - mean_absolute_error: 0.0987\n",
      "Epoch 48: val_loss did not improve from 0.00731\n",
      "9/9 [==============================] - 3s 327ms/step - loss: 0.0081 - mean_absolute_error: 0.0987 - val_loss: 0.0073 - val_mean_absolute_error: 0.0972\n",
      "Epoch 49/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0081 - mean_absolute_error: 0.0991\n",
      "Epoch 49: val_loss did not improve from 0.00731\n",
      "9/9 [==============================] - 3s 367ms/step - loss: 0.0081 - mean_absolute_error: 0.0991 - val_loss: 0.0073 - val_mean_absolute_error: 0.0972\n",
      "Epoch 50/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0082 - mean_absolute_error: 0.0985\n",
      "Epoch 50: val_loss did not improve from 0.00731\n",
      "9/9 [==============================] - 3s 306ms/step - loss: 0.0082 - mean_absolute_error: 0.0985 - val_loss: 0.0080 - val_mean_absolute_error: 0.1038\n",
      "Epoch 51/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0087 - mean_absolute_error: 0.1036\n",
      "Epoch 51: val_loss did not improve from 0.00731\n",
      "9/9 [==============================] - 3s 324ms/step - loss: 0.0087 - mean_absolute_error: 0.1036 - val_loss: 0.0076 - val_mean_absolute_error: 0.1010\n",
      "Epoch 52/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0085 - mean_absolute_error: 0.1016\n",
      "Epoch 52: val_loss did not improve from 0.00731\n",
      "9/9 [==============================] - 3s 400ms/step - loss: 0.0085 - mean_absolute_error: 0.1016 - val_loss: 0.0074 - val_mean_absolute_error: 0.0994\n",
      "Epoch 53/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0089 - mean_absolute_error: 0.1044\n",
      "Epoch 53: val_loss did not improve from 0.00731\n",
      "9/9 [==============================] - 3s 381ms/step - loss: 0.0089 - mean_absolute_error: 0.1044 - val_loss: 0.0074 - val_mean_absolute_error: 0.0989\n",
      "Epoch 54/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0086 - mean_absolute_error: 0.1058\n",
      "Epoch 54: val_loss did not improve from 0.00731\n",
      "9/9 [==============================] - 3s 371ms/step - loss: 0.0086 - mean_absolute_error: 0.1058 - val_loss: 0.0088 - val_mean_absolute_error: 0.1021\n",
      "Epoch 55/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0088 - mean_absolute_error: 0.1025\n",
      "Epoch 55: val_loss improved from 0.00731 to 0.00723, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 357ms/step - loss: 0.0088 - mean_absolute_error: 0.1025 - val_loss: 0.0072 - val_mean_absolute_error: 0.0961\n",
      "Epoch 56/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0081 - mean_absolute_error: 0.0985\n",
      "Epoch 56: val_loss did not improve from 0.00723\n",
      "9/9 [==============================] - 3s 302ms/step - loss: 0.0081 - mean_absolute_error: 0.0985 - val_loss: 0.0080 - val_mean_absolute_error: 0.1041\n",
      "Epoch 57/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0083 - mean_absolute_error: 0.1014\n",
      "Epoch 57: val_loss improved from 0.00723 to 0.00694, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 382ms/step - loss: 0.0083 - mean_absolute_error: 0.1014 - val_loss: 0.0069 - val_mean_absolute_error: 0.0958\n",
      "Epoch 58/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0080 - mean_absolute_error: 0.0975\n",
      "Epoch 58: val_loss improved from 0.00694 to 0.00665, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 331ms/step - loss: 0.0080 - mean_absolute_error: 0.0975 - val_loss: 0.0066 - val_mean_absolute_error: 0.0929\n",
      "Epoch 59/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0077 - mean_absolute_error: 0.0971\n",
      "Epoch 59: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 339ms/step - loss: 0.0077 - mean_absolute_error: 0.0971 - val_loss: 0.0268 - val_mean_absolute_error: 0.1345\n",
      "Epoch 60/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0092 - mean_absolute_error: 0.1050\n",
      "Epoch 60: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 357ms/step - loss: 0.0092 - mean_absolute_error: 0.1050 - val_loss: 0.0077 - val_mean_absolute_error: 0.0976\n",
      "Epoch 61/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0088 - mean_absolute_error: 0.1033\n",
      "Epoch 61: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 334ms/step - loss: 0.0088 - mean_absolute_error: 0.1033 - val_loss: 0.0079 - val_mean_absolute_error: 0.1009\n",
      "Epoch 62/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0086 - mean_absolute_error: 0.1008\n",
      "Epoch 62: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 327ms/step - loss: 0.0086 - mean_absolute_error: 0.1008 - val_loss: 0.0099 - val_mean_absolute_error: 0.1175\n",
      "Epoch 63/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0096 - mean_absolute_error: 0.1118\n",
      "Epoch 63: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 321ms/step - loss: 0.0096 - mean_absolute_error: 0.1118 - val_loss: 0.0075 - val_mean_absolute_error: 0.0976\n",
      "Epoch 64/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0088 - mean_absolute_error: 0.1030\n",
      "Epoch 64: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 347ms/step - loss: 0.0088 - mean_absolute_error: 0.1030 - val_loss: 0.0076 - val_mean_absolute_error: 0.0975\n",
      "Epoch 65/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0084 - mean_absolute_error: 0.1000\n",
      "Epoch 65: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 348ms/step - loss: 0.0084 - mean_absolute_error: 0.1000 - val_loss: 0.0075 - val_mean_absolute_error: 0.0976\n",
      "Epoch 66/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0081 - mean_absolute_error: 0.0980\n",
      "Epoch 66: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 313ms/step - loss: 0.0081 - mean_absolute_error: 0.0980 - val_loss: 0.0075 - val_mean_absolute_error: 0.0984\n",
      "Epoch 67/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0081 - mean_absolute_error: 0.0976\n",
      "Epoch 67: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 307ms/step - loss: 0.0081 - mean_absolute_error: 0.0976 - val_loss: 0.0073 - val_mean_absolute_error: 0.0974\n",
      "Epoch 68/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0086 - mean_absolute_error: 0.1004\n",
      "Epoch 68: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 309ms/step - loss: 0.0086 - mean_absolute_error: 0.1004 - val_loss: 0.0072 - val_mean_absolute_error: 0.0966\n",
      "Epoch 69/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0083 - mean_absolute_error: 0.1015\n",
      "Epoch 69: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 330ms/step - loss: 0.0083 - mean_absolute_error: 0.1015 - val_loss: 0.0073 - val_mean_absolute_error: 0.0966\n",
      "Epoch 70/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0082 - mean_absolute_error: 0.0998\n",
      "Epoch 70: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 328ms/step - loss: 0.0082 - mean_absolute_error: 0.0998 - val_loss: 0.0073 - val_mean_absolute_error: 0.0964\n",
      "Epoch 71/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0083 - mean_absolute_error: 0.0992\n",
      "Epoch 71: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 337ms/step - loss: 0.0083 - mean_absolute_error: 0.0992 - val_loss: 0.0077 - val_mean_absolute_error: 0.1017\n",
      "Epoch 72/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0083 - mean_absolute_error: 0.1009\n",
      "Epoch 72: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 335ms/step - loss: 0.0083 - mean_absolute_error: 0.1009 - val_loss: 0.0078 - val_mean_absolute_error: 0.1024\n",
      "Epoch 73/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0084 - mean_absolute_error: 0.1008\n",
      "Epoch 73: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 316ms/step - loss: 0.0084 - mean_absolute_error: 0.1008 - val_loss: 0.0074 - val_mean_absolute_error: 0.0982\n",
      "Epoch 74/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0076 - mean_absolute_error: 0.0948\n",
      "Epoch 74: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 312ms/step - loss: 0.0076 - mean_absolute_error: 0.0948 - val_loss: 0.0072 - val_mean_absolute_error: 0.0959\n",
      "Epoch 75/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0082 - mean_absolute_error: 0.0988\n",
      "Epoch 75: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 323ms/step - loss: 0.0082 - mean_absolute_error: 0.0988 - val_loss: 0.0079 - val_mean_absolute_error: 0.1031\n",
      "Epoch 76/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0082 - mean_absolute_error: 0.0996\n",
      "Epoch 76: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 336ms/step - loss: 0.0082 - mean_absolute_error: 0.0996 - val_loss: 0.0076 - val_mean_absolute_error: 0.1003\n",
      "Epoch 77/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0082 - mean_absolute_error: 0.0994\n",
      "Epoch 77: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 314ms/step - loss: 0.0082 - mean_absolute_error: 0.0994 - val_loss: 0.0079 - val_mean_absolute_error: 0.1030\n",
      "Epoch 78/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0088 - mean_absolute_error: 0.1030\n",
      "Epoch 78: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 323ms/step - loss: 0.0088 - mean_absolute_error: 0.1030 - val_loss: 0.0074 - val_mean_absolute_error: 0.0988\n",
      "Epoch 79/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0087 - mean_absolute_error: 0.1026\n",
      "Epoch 79: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 327ms/step - loss: 0.0087 - mean_absolute_error: 0.1026 - val_loss: 0.0071 - val_mean_absolute_error: 0.0954\n",
      "Epoch 80/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0082 - mean_absolute_error: 0.0999\n",
      "Epoch 80: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 370ms/step - loss: 0.0082 - mean_absolute_error: 0.0999 - val_loss: 0.0072 - val_mean_absolute_error: 0.0954\n",
      "Epoch 81/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0081 - mean_absolute_error: 0.0996\n",
      "Epoch 81: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 353ms/step - loss: 0.0081 - mean_absolute_error: 0.0996 - val_loss: 0.0071 - val_mean_absolute_error: 0.0951\n",
      "Epoch 82/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0083 - mean_absolute_error: 0.0988\n",
      "Epoch 82: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 375ms/step - loss: 0.0083 - mean_absolute_error: 0.0988 - val_loss: 0.0071 - val_mean_absolute_error: 0.0952\n",
      "Epoch 83/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0079 - mean_absolute_error: 0.0970\n",
      "Epoch 83: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 335ms/step - loss: 0.0079 - mean_absolute_error: 0.0970 - val_loss: 0.0070 - val_mean_absolute_error: 0.0954\n",
      "Epoch 84/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0077 - mean_absolute_error: 0.0966\n",
      "Epoch 84: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 334ms/step - loss: 0.0077 - mean_absolute_error: 0.0966 - val_loss: 0.0072 - val_mean_absolute_error: 0.0972\n",
      "Epoch 85/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0082 - mean_absolute_error: 0.0990\n",
      "Epoch 85: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 329ms/step - loss: 0.0082 - mean_absolute_error: 0.0990 - val_loss: 0.0084 - val_mean_absolute_error: 0.1071\n",
      "Epoch 86/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0087 - mean_absolute_error: 0.1033\n",
      "Epoch 86: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 333ms/step - loss: 0.0087 - mean_absolute_error: 0.1033 - val_loss: 0.0070 - val_mean_absolute_error: 0.0950\n",
      "Epoch 87/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0088 - mean_absolute_error: 0.1034\n",
      "Epoch 87: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 339ms/step - loss: 0.0088 - mean_absolute_error: 0.1034 - val_loss: 0.0074 - val_mean_absolute_error: 0.0997\n",
      "Epoch 88/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0091 - mean_absolute_error: 0.1046\n",
      "Epoch 88: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 336ms/step - loss: 0.0091 - mean_absolute_error: 0.1046 - val_loss: 0.0070 - val_mean_absolute_error: 0.0941\n",
      "Epoch 89/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0085 - mean_absolute_error: 0.1011\n",
      "Epoch 89: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 335ms/step - loss: 0.0085 - mean_absolute_error: 0.1011 - val_loss: 0.0070 - val_mean_absolute_error: 0.0943\n",
      "Epoch 90/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0082 - mean_absolute_error: 0.0984\n",
      "Epoch 90: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 328ms/step - loss: 0.0082 - mean_absolute_error: 0.0984 - val_loss: 0.0081 - val_mean_absolute_error: 0.0982\n",
      "Epoch 91/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0088 - mean_absolute_error: 0.1038\n",
      "Epoch 91: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 343ms/step - loss: 0.0088 - mean_absolute_error: 0.1038 - val_loss: 0.0075 - val_mean_absolute_error: 0.0955\n",
      "Epoch 92/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0089 - mean_absolute_error: 0.1019\n",
      "Epoch 92: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 336ms/step - loss: 0.0089 - mean_absolute_error: 0.1019 - val_loss: 0.0070 - val_mean_absolute_error: 0.0961\n",
      "Epoch 93/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0080 - mean_absolute_error: 0.0973\n",
      "Epoch 93: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 315ms/step - loss: 0.0080 - mean_absolute_error: 0.0973 - val_loss: 0.0091 - val_mean_absolute_error: 0.1127\n",
      "Epoch 94/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0090 - mean_absolute_error: 0.1049\n",
      "Epoch 94: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 321ms/step - loss: 0.0090 - mean_absolute_error: 0.1049 - val_loss: 0.0072 - val_mean_absolute_error: 0.0983\n",
      "Epoch 95/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0081 - mean_absolute_error: 0.0993\n",
      "Epoch 95: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 321ms/step - loss: 0.0081 - mean_absolute_error: 0.0993 - val_loss: 0.0070 - val_mean_absolute_error: 0.0935\n",
      "Epoch 96/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0082 - mean_absolute_error: 0.0993\n",
      "Epoch 96: val_loss did not improve from 0.00665\n",
      "9/9 [==============================] - 3s 335ms/step - loss: 0.0082 - mean_absolute_error: 0.0993 - val_loss: 0.0068 - val_mean_absolute_error: 0.0925\n",
      "Epoch 97/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0080 - mean_absolute_error: 0.0968\n",
      "Epoch 97: val_loss improved from 0.00665 to 0.00655, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 358ms/step - loss: 0.0080 - mean_absolute_error: 0.0968 - val_loss: 0.0066 - val_mean_absolute_error: 0.0909\n",
      "Epoch 98/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0079 - mean_absolute_error: 0.0966\n",
      "Epoch 98: val_loss improved from 0.00655 to 0.00643, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 329ms/step - loss: 0.0079 - mean_absolute_error: 0.0966 - val_loss: 0.0064 - val_mean_absolute_error: 0.0921\n",
      "Epoch 99/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0079 - mean_absolute_error: 0.0967\n",
      "Epoch 99: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 330ms/step - loss: 0.0079 - mean_absolute_error: 0.0967 - val_loss: 0.0069 - val_mean_absolute_error: 0.0953\n",
      "Epoch 100/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0080 - mean_absolute_error: 0.0985\n",
      "Epoch 100: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 318ms/step - loss: 0.0080 - mean_absolute_error: 0.0985 - val_loss: 0.0073 - val_mean_absolute_error: 0.0957\n",
      "Epoch 101/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0089 - mean_absolute_error: 0.1029\n",
      "Epoch 101: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 324ms/step - loss: 0.0089 - mean_absolute_error: 0.1029 - val_loss: 0.0073 - val_mean_absolute_error: 0.0960\n",
      "Epoch 102/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0085 - mean_absolute_error: 0.1003\n",
      "Epoch 102: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 323ms/step - loss: 0.0085 - mean_absolute_error: 0.1003 - val_loss: 0.0077 - val_mean_absolute_error: 0.1002\n",
      "Epoch 103/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0088 - mean_absolute_error: 0.1016\n",
      "Epoch 103: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 330ms/step - loss: 0.0088 - mean_absolute_error: 0.1016 - val_loss: 0.0079 - val_mean_absolute_error: 0.1023\n",
      "Epoch 104/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0087 - mean_absolute_error: 0.1025\n",
      "Epoch 104: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 325ms/step - loss: 0.0087 - mean_absolute_error: 0.1025 - val_loss: 0.0082 - val_mean_absolute_error: 0.1052\n",
      "Epoch 105/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0090 - mean_absolute_error: 0.1042\n",
      "Epoch 105: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 334ms/step - loss: 0.0090 - mean_absolute_error: 0.1042 - val_loss: 0.0080 - val_mean_absolute_error: 0.0981\n",
      "Epoch 106/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0081 - mean_absolute_error: 0.1019\n",
      "Epoch 106: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 340ms/step - loss: 0.0081 - mean_absolute_error: 0.1019 - val_loss: 0.0073 - val_mean_absolute_error: 0.0977\n",
      "Epoch 107/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0081 - mean_absolute_error: 0.0977\n",
      "Epoch 107: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 4s 410ms/step - loss: 0.0081 - mean_absolute_error: 0.0977 - val_loss: 0.0074 - val_mean_absolute_error: 0.0957\n",
      "Epoch 108/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0080 - mean_absolute_error: 0.0982\n",
      "Epoch 108: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 315ms/step - loss: 0.0080 - mean_absolute_error: 0.0982 - val_loss: 0.0076 - val_mean_absolute_error: 0.0968\n",
      "Epoch 109/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0081 - mean_absolute_error: 0.0971\n",
      "Epoch 109: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 316ms/step - loss: 0.0081 - mean_absolute_error: 0.0971 - val_loss: 0.0072 - val_mean_absolute_error: 0.0967\n",
      "Epoch 110/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0083 - mean_absolute_error: 0.0987\n",
      "Epoch 110: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 314ms/step - loss: 0.0083 - mean_absolute_error: 0.0987 - val_loss: 0.0073 - val_mean_absolute_error: 0.0980\n",
      "Epoch 111/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0074 - mean_absolute_error: 0.0936\n",
      "Epoch 111: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 320ms/step - loss: 0.0074 - mean_absolute_error: 0.0936 - val_loss: 0.0071 - val_mean_absolute_error: 0.0946\n",
      "Epoch 112/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0078 - mean_absolute_error: 0.0963\n",
      "Epoch 112: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 314ms/step - loss: 0.0078 - mean_absolute_error: 0.0963 - val_loss: 0.0082 - val_mean_absolute_error: 0.0988\n",
      "Epoch 113/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0089 - mean_absolute_error: 0.1034\n",
      "Epoch 113: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 324ms/step - loss: 0.0089 - mean_absolute_error: 0.1034 - val_loss: 0.0072 - val_mean_absolute_error: 0.0974\n",
      "Epoch 114/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0082 - mean_absolute_error: 0.0958\n",
      "Epoch 114: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 360ms/step - loss: 0.0082 - mean_absolute_error: 0.0958 - val_loss: 0.0079 - val_mean_absolute_error: 0.1035\n",
      "Epoch 115/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0078 - mean_absolute_error: 0.0966\n",
      "Epoch 115: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 353ms/step - loss: 0.0078 - mean_absolute_error: 0.0966 - val_loss: 0.0072 - val_mean_absolute_error: 0.0942\n",
      "Epoch 116/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0082 - mean_absolute_error: 0.0984\n",
      "Epoch 116: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 324ms/step - loss: 0.0082 - mean_absolute_error: 0.0984 - val_loss: 0.0069 - val_mean_absolute_error: 0.0940\n",
      "Epoch 117/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0080 - mean_absolute_error: 0.0969\n",
      "Epoch 117: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 324ms/step - loss: 0.0080 - mean_absolute_error: 0.0969 - val_loss: 0.0073 - val_mean_absolute_error: 0.0989\n",
      "Epoch 118/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0086 - mean_absolute_error: 0.1040\n",
      "Epoch 118: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 349ms/step - loss: 0.0086 - mean_absolute_error: 0.1040 - val_loss: 0.0072 - val_mean_absolute_error: 0.0937\n",
      "Epoch 119/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0085 - mean_absolute_error: 0.1007\n",
      "Epoch 119: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 321ms/step - loss: 0.0085 - mean_absolute_error: 0.1007 - val_loss: 0.0073 - val_mean_absolute_error: 0.0941\n",
      "Epoch 120/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0083 - mean_absolute_error: 0.1007\n",
      "Epoch 120: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 350ms/step - loss: 0.0083 - mean_absolute_error: 0.1007 - val_loss: 0.0070 - val_mean_absolute_error: 0.0933\n",
      "Epoch 121/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0076 - mean_absolute_error: 0.0949\n",
      "Epoch 121: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 313ms/step - loss: 0.0076 - mean_absolute_error: 0.0949 - val_loss: 0.0068 - val_mean_absolute_error: 0.0934\n",
      "Epoch 122/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0080 - mean_absolute_error: 0.0975\n",
      "Epoch 122: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 314ms/step - loss: 0.0080 - mean_absolute_error: 0.0975 - val_loss: 0.0082 - val_mean_absolute_error: 0.1066\n",
      "Epoch 123/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0083 - mean_absolute_error: 0.1019\n",
      "Epoch 123: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 331ms/step - loss: 0.0083 - mean_absolute_error: 0.1019 - val_loss: 0.0072 - val_mean_absolute_error: 0.0936\n",
      "Epoch 124/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0078 - mean_absolute_error: 0.0961\n",
      "Epoch 124: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 317ms/step - loss: 0.0078 - mean_absolute_error: 0.0961 - val_loss: 0.0072 - val_mean_absolute_error: 0.0986\n",
      "Epoch 125/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0081 - mean_absolute_error: 0.0994\n",
      "Epoch 125: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 325ms/step - loss: 0.0081 - mean_absolute_error: 0.0994 - val_loss: 0.0071 - val_mean_absolute_error: 0.0972\n",
      "Epoch 126/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0079 - mean_absolute_error: 0.0980\n",
      "Epoch 126: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 355ms/step - loss: 0.0079 - mean_absolute_error: 0.0980 - val_loss: 0.0067 - val_mean_absolute_error: 0.0932\n",
      "Epoch 127/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0081 - mean_absolute_error: 0.0984\n",
      "Epoch 127: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 314ms/step - loss: 0.0081 - mean_absolute_error: 0.0984 - val_loss: 0.0069 - val_mean_absolute_error: 0.0917\n",
      "Epoch 128/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0078 - mean_absolute_error: 0.0963\n",
      "Epoch 128: val_loss did not improve from 0.00643\n",
      "9/9 [==============================] - 3s 327ms/step - loss: 0.0078 - mean_absolute_error: 0.0963 - val_loss: 0.0068 - val_mean_absolute_error: 0.0954\n",
      "Epoch 129/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0076 - mean_absolute_error: 0.0962\n",
      "Epoch 129: val_loss improved from 0.00643 to 0.00611, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 334ms/step - loss: 0.0076 - mean_absolute_error: 0.0962 - val_loss: 0.0061 - val_mean_absolute_error: 0.0897\n",
      "Epoch 130/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0072 - mean_absolute_error: 0.0921\n",
      "Epoch 130: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 306ms/step - loss: 0.0072 - mean_absolute_error: 0.0921 - val_loss: 0.0064 - val_mean_absolute_error: 0.0907\n",
      "Epoch 131/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0078 - mean_absolute_error: 0.0960\n",
      "Epoch 131: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 308ms/step - loss: 0.0078 - mean_absolute_error: 0.0960 - val_loss: 0.0064 - val_mean_absolute_error: 0.0918\n",
      "Epoch 132/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0079 - mean_absolute_error: 0.0974\n",
      "Epoch 132: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 310ms/step - loss: 0.0079 - mean_absolute_error: 0.0974 - val_loss: 0.0075 - val_mean_absolute_error: 0.0978\n",
      "Epoch 133/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0084 - mean_absolute_error: 0.1003\n",
      "Epoch 133: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 310ms/step - loss: 0.0084 - mean_absolute_error: 0.1003 - val_loss: 0.0075 - val_mean_absolute_error: 0.0990\n",
      "Epoch 134/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0093 - mean_absolute_error: 0.1066\n",
      "Epoch 134: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 311ms/step - loss: 0.0093 - mean_absolute_error: 0.1066 - val_loss: 0.0080 - val_mean_absolute_error: 0.0972\n",
      "Epoch 135/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0094 - mean_absolute_error: 0.1081\n",
      "Epoch 135: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 329ms/step - loss: 0.0094 - mean_absolute_error: 0.1081 - val_loss: 0.0098 - val_mean_absolute_error: 0.1059\n",
      "Epoch 136/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0096 - mean_absolute_error: 0.1068\n",
      "Epoch 136: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 314ms/step - loss: 0.0096 - mean_absolute_error: 0.1068 - val_loss: 0.0074 - val_mean_absolute_error: 0.0975\n",
      "Epoch 137/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0088 - mean_absolute_error: 0.1009\n",
      "Epoch 137: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 308ms/step - loss: 0.0088 - mean_absolute_error: 0.1009 - val_loss: 0.0088 - val_mean_absolute_error: 0.1109\n",
      "Epoch 138/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0088 - mean_absolute_error: 0.1024\n",
      "Epoch 138: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 316ms/step - loss: 0.0088 - mean_absolute_error: 0.1024 - val_loss: 0.0075 - val_mean_absolute_error: 0.0955\n",
      "Epoch 139/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0078 - mean_absolute_error: 0.0956\n",
      "Epoch 139: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 309ms/step - loss: 0.0078 - mean_absolute_error: 0.0956 - val_loss: 0.0072 - val_mean_absolute_error: 0.0972\n",
      "Epoch 140/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0077 - mean_absolute_error: 0.0963\n",
      "Epoch 140: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 306ms/step - loss: 0.0077 - mean_absolute_error: 0.0963 - val_loss: 0.0070 - val_mean_absolute_error: 0.0957\n",
      "Epoch 141/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0081 - mean_absolute_error: 0.0972\n",
      "Epoch 141: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 322ms/step - loss: 0.0081 - mean_absolute_error: 0.0972 - val_loss: 0.0070 - val_mean_absolute_error: 0.0948\n",
      "Epoch 142/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0080 - mean_absolute_error: 0.0976\n",
      "Epoch 142: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 312ms/step - loss: 0.0080 - mean_absolute_error: 0.0976 - val_loss: 0.0071 - val_mean_absolute_error: 0.0960\n",
      "Epoch 143/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0081 - mean_absolute_error: 0.0979\n",
      "Epoch 143: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 331ms/step - loss: 0.0081 - mean_absolute_error: 0.0979 - val_loss: 0.0072 - val_mean_absolute_error: 0.0980\n",
      "Epoch 144/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0080 - mean_absolute_error: 0.0981\n",
      "Epoch 144: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 365ms/step - loss: 0.0080 - mean_absolute_error: 0.0981 - val_loss: 0.0070 - val_mean_absolute_error: 0.0934\n",
      "Epoch 145/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0082 - mean_absolute_error: 0.0991\n",
      "Epoch 145: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 334ms/step - loss: 0.0082 - mean_absolute_error: 0.0991 - val_loss: 0.0074 - val_mean_absolute_error: 0.0993\n",
      "Epoch 146/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0077 - mean_absolute_error: 0.0971\n",
      "Epoch 146: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 379ms/step - loss: 0.0077 - mean_absolute_error: 0.0971 - val_loss: 0.0069 - val_mean_absolute_error: 0.0946\n",
      "Epoch 147/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0077 - mean_absolute_error: 0.0957\n",
      "Epoch 147: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 356ms/step - loss: 0.0077 - mean_absolute_error: 0.0957 - val_loss: 0.0070 - val_mean_absolute_error: 0.0930\n",
      "Epoch 148/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0078 - mean_absolute_error: 0.0951\n",
      "Epoch 148: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 333ms/step - loss: 0.0078 - mean_absolute_error: 0.0951 - val_loss: 0.0070 - val_mean_absolute_error: 0.0960\n",
      "Epoch 149/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0082 - mean_absolute_error: 0.0991\n",
      "Epoch 149: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 351ms/step - loss: 0.0082 - mean_absolute_error: 0.0991 - val_loss: 0.0069 - val_mean_absolute_error: 0.0946\n",
      "Epoch 150/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0082 - mean_absolute_error: 0.0990\n",
      "Epoch 150: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 341ms/step - loss: 0.0082 - mean_absolute_error: 0.0990 - val_loss: 0.0070 - val_mean_absolute_error: 0.0963\n",
      "Epoch 151/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0082 - mean_absolute_error: 0.0984\n",
      "Epoch 151: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 350ms/step - loss: 0.0082 - mean_absolute_error: 0.0984 - val_loss: 0.0072 - val_mean_absolute_error: 0.0985\n",
      "Epoch 152/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0078 - mean_absolute_error: 0.0958\n",
      "Epoch 152: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 330ms/step - loss: 0.0078 - mean_absolute_error: 0.0958 - val_loss: 0.0068 - val_mean_absolute_error: 0.0953\n",
      "Epoch 153/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0082 - mean_absolute_error: 0.0978\n",
      "Epoch 153: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 330ms/step - loss: 0.0082 - mean_absolute_error: 0.0978 - val_loss: 0.0076 - val_mean_absolute_error: 0.1016\n",
      "Epoch 154/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0078 - mean_absolute_error: 0.0981\n",
      "Epoch 154: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 320ms/step - loss: 0.0078 - mean_absolute_error: 0.0981 - val_loss: 0.0075 - val_mean_absolute_error: 0.0943\n",
      "Epoch 155/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0081 - mean_absolute_error: 0.0992\n",
      "Epoch 155: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 336ms/step - loss: 0.0081 - mean_absolute_error: 0.0992 - val_loss: 0.0069 - val_mean_absolute_error: 0.0941\n",
      "Epoch 156/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0079 - mean_absolute_error: 0.0952\n",
      "Epoch 156: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 314ms/step - loss: 0.0079 - mean_absolute_error: 0.0952 - val_loss: 0.0068 - val_mean_absolute_error: 0.0920\n",
      "Epoch 157/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0079 - mean_absolute_error: 0.0970\n",
      "Epoch 157: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 331ms/step - loss: 0.0079 - mean_absolute_error: 0.0970 - val_loss: 0.0067 - val_mean_absolute_error: 0.0921\n",
      "Epoch 158/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0075 - mean_absolute_error: 0.0943\n",
      "Epoch 158: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 375ms/step - loss: 0.0075 - mean_absolute_error: 0.0943 - val_loss: 0.0070 - val_mean_absolute_error: 0.0966\n",
      "Epoch 159/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0083 - mean_absolute_error: 0.0970\n",
      "Epoch 159: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 345ms/step - loss: 0.0083 - mean_absolute_error: 0.0970 - val_loss: 0.0066 - val_mean_absolute_error: 0.0926\n",
      "Epoch 160/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0078 - mean_absolute_error: 0.0961\n",
      "Epoch 160: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 332ms/step - loss: 0.0078 - mean_absolute_error: 0.0961 - val_loss: 0.0066 - val_mean_absolute_error: 0.0922\n",
      "Epoch 161/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0075 - mean_absolute_error: 0.0938\n",
      "Epoch 161: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 320ms/step - loss: 0.0075 - mean_absolute_error: 0.0938 - val_loss: 0.0067 - val_mean_absolute_error: 0.0919\n",
      "Epoch 162/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0077 - mean_absolute_error: 0.0972\n",
      "Epoch 162: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 318ms/step - loss: 0.0077 - mean_absolute_error: 0.0972 - val_loss: 0.0066 - val_mean_absolute_error: 0.0920\n",
      "Epoch 163/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0072 - mean_absolute_error: 0.0924\n",
      "Epoch 163: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 338ms/step - loss: 0.0072 - mean_absolute_error: 0.0924 - val_loss: 0.0066 - val_mean_absolute_error: 0.0927\n",
      "Epoch 164/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0078 - mean_absolute_error: 0.0970\n",
      "Epoch 164: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 346ms/step - loss: 0.0078 - mean_absolute_error: 0.0970 - val_loss: 0.0064 - val_mean_absolute_error: 0.0909\n",
      "Epoch 165/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0075 - mean_absolute_error: 0.0941\n",
      "Epoch 165: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 329ms/step - loss: 0.0075 - mean_absolute_error: 0.0941 - val_loss: 0.0067 - val_mean_absolute_error: 0.0951\n",
      "Epoch 166/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0074 - mean_absolute_error: 0.0934\n",
      "Epoch 166: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 346ms/step - loss: 0.0074 - mean_absolute_error: 0.0934 - val_loss: 0.0065 - val_mean_absolute_error: 0.0901\n",
      "Epoch 167/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0075 - mean_absolute_error: 0.0956\n",
      "Epoch 167: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 338ms/step - loss: 0.0075 - mean_absolute_error: 0.0956 - val_loss: 0.0064 - val_mean_absolute_error: 0.0890\n",
      "Epoch 168/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0080 - mean_absolute_error: 0.0976\n",
      "Epoch 168: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 4s 404ms/step - loss: 0.0080 - mean_absolute_error: 0.0976 - val_loss: 0.0067 - val_mean_absolute_error: 0.0955\n",
      "Epoch 169/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0074 - mean_absolute_error: 0.0943\n",
      "Epoch 169: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 391ms/step - loss: 0.0074 - mean_absolute_error: 0.0943 - val_loss: 0.0069 - val_mean_absolute_error: 0.0944\n",
      "Epoch 170/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0082 - mean_absolute_error: 0.0981\n",
      "Epoch 170: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 330ms/step - loss: 0.0082 - mean_absolute_error: 0.0981 - val_loss: 0.0068 - val_mean_absolute_error: 0.0957\n",
      "Epoch 171/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0076 - mean_absolute_error: 0.0933\n",
      "Epoch 171: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 355ms/step - loss: 0.0076 - mean_absolute_error: 0.0933 - val_loss: 0.0069 - val_mean_absolute_error: 0.0931\n",
      "Epoch 172/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0079 - mean_absolute_error: 0.0967\n",
      "Epoch 172: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 341ms/step - loss: 0.0079 - mean_absolute_error: 0.0967 - val_loss: 0.0071 - val_mean_absolute_error: 0.0923\n",
      "Epoch 173/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0081 - mean_absolute_error: 0.0987\n",
      "Epoch 173: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 317ms/step - loss: 0.0081 - mean_absolute_error: 0.0987 - val_loss: 0.0074 - val_mean_absolute_error: 0.0997\n",
      "Epoch 174/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0077 - mean_absolute_error: 0.0955\n",
      "Epoch 174: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 328ms/step - loss: 0.0077 - mean_absolute_error: 0.0955 - val_loss: 0.0070 - val_mean_absolute_error: 0.0968\n",
      "Epoch 175/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0083 - mean_absolute_error: 0.0995\n",
      "Epoch 175: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 324ms/step - loss: 0.0083 - mean_absolute_error: 0.0995 - val_loss: 0.0079 - val_mean_absolute_error: 0.0964\n",
      "Epoch 176/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0081 - mean_absolute_error: 0.0981\n",
      "Epoch 176: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 354ms/step - loss: 0.0081 - mean_absolute_error: 0.0981 - val_loss: 0.0068 - val_mean_absolute_error: 0.0914\n",
      "Epoch 177/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0079 - mean_absolute_error: 0.0962\n",
      "Epoch 177: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 317ms/step - loss: 0.0079 - mean_absolute_error: 0.0962 - val_loss: 0.0067 - val_mean_absolute_error: 0.0927\n",
      "Epoch 178/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0073 - mean_absolute_error: 0.0935\n",
      "Epoch 178: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 327ms/step - loss: 0.0073 - mean_absolute_error: 0.0935 - val_loss: 0.0070 - val_mean_absolute_error: 0.0965\n",
      "Epoch 179/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0082 - mean_absolute_error: 0.0992\n",
      "Epoch 179: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 336ms/step - loss: 0.0082 - mean_absolute_error: 0.0992 - val_loss: 0.0066 - val_mean_absolute_error: 0.0922\n",
      "Epoch 180/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0080 - mean_absolute_error: 0.0975\n",
      "Epoch 180: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 314ms/step - loss: 0.0080 - mean_absolute_error: 0.0975 - val_loss: 0.0067 - val_mean_absolute_error: 0.0920\n",
      "Epoch 181/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0073 - mean_absolute_error: 0.0926\n",
      "Epoch 181: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 329ms/step - loss: 0.0073 - mean_absolute_error: 0.0926 - val_loss: 0.0065 - val_mean_absolute_error: 0.0907\n",
      "Epoch 182/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0075 - mean_absolute_error: 0.0948\n",
      "Epoch 182: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 365ms/step - loss: 0.0075 - mean_absolute_error: 0.0948 - val_loss: 0.0065 - val_mean_absolute_error: 0.0928\n",
      "Epoch 183/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0077 - mean_absolute_error: 0.0955\n",
      "Epoch 183: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 334ms/step - loss: 0.0077 - mean_absolute_error: 0.0955 - val_loss: 0.0074 - val_mean_absolute_error: 0.1004\n",
      "Epoch 184/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0083 - mean_absolute_error: 0.0999\n",
      "Epoch 184: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 321ms/step - loss: 0.0083 - mean_absolute_error: 0.0999 - val_loss: 0.0066 - val_mean_absolute_error: 0.0918\n",
      "Epoch 185/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0079 - mean_absolute_error: 0.0968\n",
      "Epoch 185: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 348ms/step - loss: 0.0079 - mean_absolute_error: 0.0968 - val_loss: 0.0069 - val_mean_absolute_error: 0.0906\n",
      "Epoch 186/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0079 - mean_absolute_error: 0.0976\n",
      "Epoch 186: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 326ms/step - loss: 0.0079 - mean_absolute_error: 0.0976 - val_loss: 0.0066 - val_mean_absolute_error: 0.0930\n",
      "Epoch 187/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0075 - mean_absolute_error: 0.0949\n",
      "Epoch 187: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 370ms/step - loss: 0.0075 - mean_absolute_error: 0.0949 - val_loss: 0.0064 - val_mean_absolute_error: 0.0889\n",
      "Epoch 188/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0076 - mean_absolute_error: 0.0941\n",
      "Epoch 188: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 328ms/step - loss: 0.0076 - mean_absolute_error: 0.0941 - val_loss: 0.0062 - val_mean_absolute_error: 0.0904\n",
      "Epoch 189/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0073 - mean_absolute_error: 0.0927\n",
      "Epoch 189: val_loss did not improve from 0.00611\n",
      "9/9 [==============================] - 3s 378ms/step - loss: 0.0073 - mean_absolute_error: 0.0927 - val_loss: 0.0062 - val_mean_absolute_error: 0.0893\n",
      "Epoch 190/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0075 - mean_absolute_error: 0.0947\n",
      "Epoch 190: val_loss improved from 0.00611 to 0.00596, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 353ms/step - loss: 0.0075 - mean_absolute_error: 0.0947 - val_loss: 0.0060 - val_mean_absolute_error: 0.0875\n",
      "Epoch 191/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0074 - mean_absolute_error: 0.0916\n",
      "Epoch 191: val_loss did not improve from 0.00596\n",
      "9/9 [==============================] - 3s 307ms/step - loss: 0.0074 - mean_absolute_error: 0.0916 - val_loss: 0.0061 - val_mean_absolute_error: 0.0884\n",
      "Epoch 192/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0079 - mean_absolute_error: 0.0962\n",
      "Epoch 192: val_loss did not improve from 0.00596\n",
      "9/9 [==============================] - 3s 319ms/step - loss: 0.0079 - mean_absolute_error: 0.0962 - val_loss: 0.0073 - val_mean_absolute_error: 0.0922\n",
      "Epoch 193/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0080 - mean_absolute_error: 0.0973\n",
      "Epoch 193: val_loss did not improve from 0.00596\n",
      "9/9 [==============================] - 3s 324ms/step - loss: 0.0080 - mean_absolute_error: 0.0973 - val_loss: 0.0063 - val_mean_absolute_error: 0.0891\n",
      "Epoch 194/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0080 - mean_absolute_error: 0.0975\n",
      "Epoch 194: val_loss did not improve from 0.00596\n",
      "9/9 [==============================] - 3s 327ms/step - loss: 0.0080 - mean_absolute_error: 0.0975 - val_loss: 0.0081 - val_mean_absolute_error: 0.1042\n",
      "Epoch 195/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0072 - mean_absolute_error: 0.0928\n",
      "Epoch 195: val_loss did not improve from 0.00596\n",
      "9/9 [==============================] - 3s 321ms/step - loss: 0.0072 - mean_absolute_error: 0.0928 - val_loss: 0.0060 - val_mean_absolute_error: 0.0882\n",
      "Epoch 196/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0074 - mean_absolute_error: 0.0953\n",
      "Epoch 196: val_loss did not improve from 0.00596\n",
      "9/9 [==============================] - 3s 338ms/step - loss: 0.0074 - mean_absolute_error: 0.0953 - val_loss: 0.0066 - val_mean_absolute_error: 0.0884\n",
      "Epoch 197/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0074 - mean_absolute_error: 0.0923\n",
      "Epoch 197: val_loss did not improve from 0.00596\n",
      "9/9 [==============================] - 3s 336ms/step - loss: 0.0074 - mean_absolute_error: 0.0923 - val_loss: 0.0061 - val_mean_absolute_error: 0.0880\n",
      "Epoch 198/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0069 - mean_absolute_error: 0.0907\n",
      "Epoch 198: val_loss did not improve from 0.00596\n",
      "9/9 [==============================] - 3s 331ms/step - loss: 0.0069 - mean_absolute_error: 0.0907 - val_loss: 0.0061 - val_mean_absolute_error: 0.0858\n",
      "Epoch 199/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0080 - mean_absolute_error: 0.0974\n",
      "Epoch 199: val_loss did not improve from 0.00596\n",
      "9/9 [==============================] - 3s 312ms/step - loss: 0.0080 - mean_absolute_error: 0.0974 - val_loss: 0.0068 - val_mean_absolute_error: 0.0928\n",
      "Epoch 200/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0078 - mean_absolute_error: 0.0962\n",
      "Epoch 200: val_loss did not improve from 0.00596\n",
      "9/9 [==============================] - 3s 333ms/step - loss: 0.0078 - mean_absolute_error: 0.0962 - val_loss: 0.0068 - val_mean_absolute_error: 0.0929\n",
      "Epoch 201/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0074 - mean_absolute_error: 0.0945\n",
      "Epoch 201: val_loss did not improve from 0.00596\n",
      "9/9 [==============================] - 3s 309ms/step - loss: 0.0074 - mean_absolute_error: 0.0945 - val_loss: 0.0063 - val_mean_absolute_error: 0.0903\n",
      "Epoch 202/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0074 - mean_absolute_error: 0.0939\n",
      "Epoch 202: val_loss did not improve from 0.00596\n",
      "9/9 [==============================] - 3s 332ms/step - loss: 0.0074 - mean_absolute_error: 0.0939 - val_loss: 0.0062 - val_mean_absolute_error: 0.0906\n",
      "Epoch 203/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0076 - mean_absolute_error: 0.0942\n",
      "Epoch 203: val_loss did not improve from 0.00596\n",
      "9/9 [==============================] - 3s 333ms/step - loss: 0.0076 - mean_absolute_error: 0.0942 - val_loss: 0.0062 - val_mean_absolute_error: 0.0907\n",
      "Epoch 204/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0078 - mean_absolute_error: 0.0976\n",
      "Epoch 204: val_loss did not improve from 0.00596\n",
      "9/9 [==============================] - 3s 389ms/step - loss: 0.0078 - mean_absolute_error: 0.0976 - val_loss: 0.0072 - val_mean_absolute_error: 0.0912\n",
      "Epoch 205/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0080 - mean_absolute_error: 0.0961\n",
      "Epoch 205: val_loss did not improve from 0.00596\n",
      "9/9 [==============================] - 3s 384ms/step - loss: 0.0080 - mean_absolute_error: 0.0961 - val_loss: 0.0064 - val_mean_absolute_error: 0.0925\n",
      "Epoch 206/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0073 - mean_absolute_error: 0.0908\n",
      "Epoch 206: val_loss did not improve from 0.00596\n",
      "9/9 [==============================] - 3s 358ms/step - loss: 0.0073 - mean_absolute_error: 0.0908 - val_loss: 0.0060 - val_mean_absolute_error: 0.0851\n",
      "Epoch 207/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0068 - mean_absolute_error: 0.0887\n",
      "Epoch 207: val_loss did not improve from 0.00596\n",
      "9/9 [==============================] - 3s 323ms/step - loss: 0.0068 - mean_absolute_error: 0.0887 - val_loss: 0.0085 - val_mean_absolute_error: 0.1056\n",
      "Epoch 208/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0075 - mean_absolute_error: 0.0924\n",
      "Epoch 208: val_loss did not improve from 0.00596\n",
      "9/9 [==============================] - 3s 338ms/step - loss: 0.0075 - mean_absolute_error: 0.0924 - val_loss: 0.0069 - val_mean_absolute_error: 0.0929\n",
      "Epoch 209/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0079 - mean_absolute_error: 0.0974\n",
      "Epoch 209: val_loss did not improve from 0.00596\n",
      "9/9 [==============================] - 3s 332ms/step - loss: 0.0079 - mean_absolute_error: 0.0974 - val_loss: 0.0067 - val_mean_absolute_error: 0.0898\n",
      "Epoch 210/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0077 - mean_absolute_error: 0.0955\n",
      "Epoch 210: val_loss did not improve from 0.00596\n",
      "9/9 [==============================] - 3s 310ms/step - loss: 0.0077 - mean_absolute_error: 0.0955 - val_loss: 0.0064 - val_mean_absolute_error: 0.0911\n",
      "Epoch 211/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0074 - mean_absolute_error: 0.0943\n",
      "Epoch 211: val_loss did not improve from 0.00596\n",
      "9/9 [==============================] - 3s 324ms/step - loss: 0.0074 - mean_absolute_error: 0.0943 - val_loss: 0.0065 - val_mean_absolute_error: 0.0925\n",
      "Epoch 212/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0072 - mean_absolute_error: 0.0909\n",
      "Epoch 212: val_loss did not improve from 0.00596\n",
      "9/9 [==============================] - 3s 338ms/step - loss: 0.0072 - mean_absolute_error: 0.0909 - val_loss: 0.0062 - val_mean_absolute_error: 0.0887\n",
      "Epoch 213/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0074 - mean_absolute_error: 0.0940\n",
      "Epoch 213: val_loss did not improve from 0.00596\n",
      "9/9 [==============================] - 3s 334ms/step - loss: 0.0074 - mean_absolute_error: 0.0940 - val_loss: 0.0060 - val_mean_absolute_error: 0.0870\n",
      "Epoch 214/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0075 - mean_absolute_error: 0.0950\n",
      "Epoch 214: val_loss did not improve from 0.00596\n",
      "9/9 [==============================] - 3s 335ms/step - loss: 0.0075 - mean_absolute_error: 0.0950 - val_loss: 0.0061 - val_mean_absolute_error: 0.0895\n",
      "Epoch 215/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0071 - mean_absolute_error: 0.0913\n",
      "Epoch 215: val_loss improved from 0.00596 to 0.00586, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 330ms/step - loss: 0.0071 - mean_absolute_error: 0.0913 - val_loss: 0.0059 - val_mean_absolute_error: 0.0847\n",
      "Epoch 216/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0069 - mean_absolute_error: 0.0901\n",
      "Epoch 216: val_loss did not improve from 0.00586\n",
      "9/9 [==============================] - 3s 331ms/step - loss: 0.0069 - mean_absolute_error: 0.0901 - val_loss: 0.0062 - val_mean_absolute_error: 0.0882\n",
      "Epoch 217/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0073 - mean_absolute_error: 0.0926\n",
      "Epoch 217: val_loss did not improve from 0.00586\n",
      "9/9 [==============================] - 3s 320ms/step - loss: 0.0073 - mean_absolute_error: 0.0926 - val_loss: 0.0062 - val_mean_absolute_error: 0.0903\n",
      "Epoch 218/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0072 - mean_absolute_error: 0.0936\n",
      "Epoch 218: val_loss did not improve from 0.00586\n",
      "9/9 [==============================] - 3s 361ms/step - loss: 0.0072 - mean_absolute_error: 0.0936 - val_loss: 0.0063 - val_mean_absolute_error: 0.0888\n",
      "Epoch 219/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0077 - mean_absolute_error: 0.0959\n",
      "Epoch 219: val_loss did not improve from 0.00586\n",
      "9/9 [==============================] - 3s 301ms/step - loss: 0.0077 - mean_absolute_error: 0.0959 - val_loss: 0.0061 - val_mean_absolute_error: 0.0863\n",
      "Epoch 220/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0072 - mean_absolute_error: 0.0905\n",
      "Epoch 220: val_loss improved from 0.00586 to 0.00580, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 365ms/step - loss: 0.0072 - mean_absolute_error: 0.0905 - val_loss: 0.0058 - val_mean_absolute_error: 0.0838\n",
      "Epoch 221/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0078 - mean_absolute_error: 0.0955\n",
      "Epoch 221: val_loss did not improve from 0.00580\n",
      "9/9 [==============================] - 3s 324ms/step - loss: 0.0078 - mean_absolute_error: 0.0955 - val_loss: 0.0074 - val_mean_absolute_error: 0.0991\n",
      "Epoch 222/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0078 - mean_absolute_error: 0.0954\n",
      "Epoch 222: val_loss did not improve from 0.00580\n",
      "9/9 [==============================] - 3s 361ms/step - loss: 0.0078 - mean_absolute_error: 0.0954 - val_loss: 0.0071 - val_mean_absolute_error: 0.0912\n",
      "Epoch 223/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0076 - mean_absolute_error: 0.0940\n",
      "Epoch 223: val_loss did not improve from 0.00580\n",
      "9/9 [==============================] - 3s 384ms/step - loss: 0.0076 - mean_absolute_error: 0.0940 - val_loss: 0.0064 - val_mean_absolute_error: 0.0909\n",
      "Epoch 224/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0077 - mean_absolute_error: 0.0952\n",
      "Epoch 224: val_loss did not improve from 0.00580\n",
      "9/9 [==============================] - 3s 312ms/step - loss: 0.0077 - mean_absolute_error: 0.0952 - val_loss: 0.0064 - val_mean_absolute_error: 0.0899\n",
      "Epoch 225/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0073 - mean_absolute_error: 0.0926\n",
      "Epoch 225: val_loss did not improve from 0.00580\n",
      "9/9 [==============================] - 3s 316ms/step - loss: 0.0073 - mean_absolute_error: 0.0926 - val_loss: 0.0065 - val_mean_absolute_error: 0.0892\n",
      "Epoch 226/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0072 - mean_absolute_error: 0.0919\n",
      "Epoch 226: val_loss did not improve from 0.00580\n",
      "9/9 [==============================] - 3s 303ms/step - loss: 0.0072 - mean_absolute_error: 0.0919 - val_loss: 0.0072 - val_mean_absolute_error: 0.0987\n",
      "Epoch 227/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0079 - mean_absolute_error: 0.0976\n",
      "Epoch 227: val_loss did not improve from 0.00580\n",
      "9/9 [==============================] - 3s 300ms/step - loss: 0.0079 - mean_absolute_error: 0.0976 - val_loss: 0.0073 - val_mean_absolute_error: 0.1014\n",
      "Epoch 228/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0077 - mean_absolute_error: 0.0964\n",
      "Epoch 228: val_loss did not improve from 0.00580\n",
      "9/9 [==============================] - 3s 301ms/step - loss: 0.0077 - mean_absolute_error: 0.0964 - val_loss: 0.0060 - val_mean_absolute_error: 0.0853\n",
      "Epoch 229/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0079 - mean_absolute_error: 0.0992\n",
      "Epoch 229: val_loss did not improve from 0.00580\n",
      "9/9 [==============================] - 3s 302ms/step - loss: 0.0079 - mean_absolute_error: 0.0992 - val_loss: 0.0066 - val_mean_absolute_error: 0.0872\n",
      "Epoch 230/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0074 - mean_absolute_error: 0.0940\n",
      "Epoch 230: val_loss did not improve from 0.00580\n",
      "9/9 [==============================] - 3s 303ms/step - loss: 0.0074 - mean_absolute_error: 0.0940 - val_loss: 0.0062 - val_mean_absolute_error: 0.0896\n",
      "Epoch 231/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0069 - mean_absolute_error: 0.0870\n",
      "Epoch 231: val_loss did not improve from 0.00580\n",
      "9/9 [==============================] - 3s 333ms/step - loss: 0.0069 - mean_absolute_error: 0.0870 - val_loss: 0.0059 - val_mean_absolute_error: 0.0852\n",
      "Epoch 232/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0068 - mean_absolute_error: 0.0896\n",
      "Epoch 232: val_loss did not improve from 0.00580\n",
      "9/9 [==============================] - 3s 350ms/step - loss: 0.0068 - mean_absolute_error: 0.0896 - val_loss: 0.0058 - val_mean_absolute_error: 0.0837\n",
      "Epoch 233/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0074 - mean_absolute_error: 0.0922\n",
      "Epoch 233: val_loss did not improve from 0.00580\n",
      "9/9 [==============================] - 3s 331ms/step - loss: 0.0074 - mean_absolute_error: 0.0922 - val_loss: 0.0065 - val_mean_absolute_error: 0.0911\n",
      "Epoch 234/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0076 - mean_absolute_error: 0.0934\n",
      "Epoch 234: val_loss did not improve from 0.00580\n",
      "9/9 [==============================] - 3s 354ms/step - loss: 0.0076 - mean_absolute_error: 0.0934 - val_loss: 0.0064 - val_mean_absolute_error: 0.0891\n",
      "Epoch 235/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0076 - mean_absolute_error: 0.0943\n",
      "Epoch 235: val_loss did not improve from 0.00580\n",
      "9/9 [==============================] - 3s 315ms/step - loss: 0.0076 - mean_absolute_error: 0.0943 - val_loss: 0.0061 - val_mean_absolute_error: 0.0887\n",
      "Epoch 236/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0067 - mean_absolute_error: 0.0881\n",
      "Epoch 236: val_loss did not improve from 0.00580\n",
      "9/9 [==============================] - 3s 306ms/step - loss: 0.0067 - mean_absolute_error: 0.0881 - val_loss: 0.0063 - val_mean_absolute_error: 0.0913\n",
      "Epoch 237/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0067 - mean_absolute_error: 0.0897\n",
      "Epoch 237: val_loss improved from 0.00580 to 0.00560, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 335ms/step - loss: 0.0067 - mean_absolute_error: 0.0897 - val_loss: 0.0056 - val_mean_absolute_error: 0.0827\n",
      "Epoch 238/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0065 - mean_absolute_error: 0.0863\n",
      "Epoch 238: val_loss improved from 0.00560 to 0.00552, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 317ms/step - loss: 0.0065 - mean_absolute_error: 0.0863 - val_loss: 0.0055 - val_mean_absolute_error: 0.0813\n",
      "Epoch 239/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0063 - mean_absolute_error: 0.0856\n",
      "Epoch 239: val_loss improved from 0.00552 to 0.00538, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 315ms/step - loss: 0.0063 - mean_absolute_error: 0.0856 - val_loss: 0.0054 - val_mean_absolute_error: 0.0794\n",
      "Epoch 240/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0066 - mean_absolute_error: 0.0855\n",
      "Epoch 240: val_loss improved from 0.00538 to 0.00522, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 327ms/step - loss: 0.0066 - mean_absolute_error: 0.0855 - val_loss: 0.0052 - val_mean_absolute_error: 0.0779\n",
      "Epoch 241/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0058 - mean_absolute_error: 0.0808\n",
      "Epoch 241: val_loss did not improve from 0.00522\n",
      "9/9 [==============================] - 3s 295ms/step - loss: 0.0058 - mean_absolute_error: 0.0808 - val_loss: 0.0057 - val_mean_absolute_error: 0.0803\n",
      "Epoch 242/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0069 - mean_absolute_error: 0.0906\n",
      "Epoch 242: val_loss did not improve from 0.00522\n",
      "9/9 [==============================] - 3s 323ms/step - loss: 0.0069 - mean_absolute_error: 0.0906 - val_loss: 0.0058 - val_mean_absolute_error: 0.0843\n",
      "Epoch 243/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0071 - mean_absolute_error: 0.0912\n",
      "Epoch 243: val_loss did not improve from 0.00522\n",
      "9/9 [==============================] - 3s 314ms/step - loss: 0.0071 - mean_absolute_error: 0.0912 - val_loss: 0.0060 - val_mean_absolute_error: 0.0867\n",
      "Epoch 244/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0065 - mean_absolute_error: 0.0881\n",
      "Epoch 244: val_loss did not improve from 0.00522\n",
      "9/9 [==============================] - 3s 328ms/step - loss: 0.0065 - mean_absolute_error: 0.0881 - val_loss: 0.0062 - val_mean_absolute_error: 0.0898\n",
      "Epoch 245/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0059 - mean_absolute_error: 0.0842\n",
      "Epoch 245: val_loss improved from 0.00522 to 0.00496, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 354ms/step - loss: 0.0059 - mean_absolute_error: 0.0842 - val_loss: 0.0050 - val_mean_absolute_error: 0.0747\n",
      "Epoch 246/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0059 - mean_absolute_error: 0.0846\n",
      "Epoch 246: val_loss did not improve from 0.00496\n",
      "9/9 [==============================] - 3s 307ms/step - loss: 0.0059 - mean_absolute_error: 0.0846 - val_loss: 0.0057 - val_mean_absolute_error: 0.0827\n",
      "Epoch 247/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0069 - mean_absolute_error: 0.0904\n",
      "Epoch 247: val_loss did not improve from 0.00496\n",
      "9/9 [==============================] - 3s 316ms/step - loss: 0.0069 - mean_absolute_error: 0.0904 - val_loss: 0.0063 - val_mean_absolute_error: 0.0847\n",
      "Epoch 248/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0065 - mean_absolute_error: 0.0854\n",
      "Epoch 248: val_loss did not improve from 0.00496\n",
      "9/9 [==============================] - 3s 321ms/step - loss: 0.0065 - mean_absolute_error: 0.0854 - val_loss: 0.0055 - val_mean_absolute_error: 0.0818\n",
      "Epoch 249/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0061 - mean_absolute_error: 0.0863\n",
      "Epoch 249: val_loss did not improve from 0.00496\n",
      "9/9 [==============================] - 3s 324ms/step - loss: 0.0061 - mean_absolute_error: 0.0863 - val_loss: 0.0094 - val_mean_absolute_error: 0.1137\n",
      "Epoch 250/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0076 - mean_absolute_error: 0.0914\n",
      "Epoch 250: val_loss did not improve from 0.00496\n",
      "9/9 [==============================] - 3s 299ms/step - loss: 0.0076 - mean_absolute_error: 0.0914 - val_loss: 0.0075 - val_mean_absolute_error: 0.0969\n",
      "Epoch 251/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0073 - mean_absolute_error: 0.0917\n",
      "Epoch 251: val_loss did not improve from 0.00496\n",
      "9/9 [==============================] - 3s 302ms/step - loss: 0.0073 - mean_absolute_error: 0.0917 - val_loss: 0.0060 - val_mean_absolute_error: 0.0853\n",
      "Epoch 252/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0069 - mean_absolute_error: 0.0893\n",
      "Epoch 252: val_loss did not improve from 0.00496\n",
      "9/9 [==============================] - 3s 349ms/step - loss: 0.0069 - mean_absolute_error: 0.0893 - val_loss: 0.0062 - val_mean_absolute_error: 0.0890\n",
      "Epoch 253/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0075 - mean_absolute_error: 0.0934\n",
      "Epoch 253: val_loss did not improve from 0.00496\n",
      "9/9 [==============================] - 3s 317ms/step - loss: 0.0075 - mean_absolute_error: 0.0934 - val_loss: 0.0068 - val_mean_absolute_error: 0.0902\n",
      "Epoch 254/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0070 - mean_absolute_error: 0.0887\n",
      "Epoch 254: val_loss did not improve from 0.00496\n",
      "9/9 [==============================] - 3s 354ms/step - loss: 0.0070 - mean_absolute_error: 0.0887 - val_loss: 0.0063 - val_mean_absolute_error: 0.0884\n",
      "Epoch 255/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0067 - mean_absolute_error: 0.0861\n",
      "Epoch 255: val_loss did not improve from 0.00496\n",
      "9/9 [==============================] - 3s 313ms/step - loss: 0.0067 - mean_absolute_error: 0.0861 - val_loss: 0.0057 - val_mean_absolute_error: 0.0851\n",
      "Epoch 256/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0067 - mean_absolute_error: 0.0860\n",
      "Epoch 256: val_loss did not improve from 0.00496\n",
      "9/9 [==============================] - 3s 328ms/step - loss: 0.0067 - mean_absolute_error: 0.0860 - val_loss: 0.0066 - val_mean_absolute_error: 0.0922\n",
      "Epoch 257/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0065 - mean_absolute_error: 0.0881\n",
      "Epoch 257: val_loss did not improve from 0.00496\n",
      "9/9 [==============================] - 3s 327ms/step - loss: 0.0065 - mean_absolute_error: 0.0881 - val_loss: 0.0056 - val_mean_absolute_error: 0.0812\n",
      "Epoch 258/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0068 - mean_absolute_error: 0.0863\n",
      "Epoch 258: val_loss did not improve from 0.00496\n",
      "9/9 [==============================] - 3s 324ms/step - loss: 0.0068 - mean_absolute_error: 0.0863 - val_loss: 0.0059 - val_mean_absolute_error: 0.0857\n",
      "Epoch 259/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0065 - mean_absolute_error: 0.0881\n",
      "Epoch 259: val_loss did not improve from 0.00496\n",
      "9/9 [==============================] - 3s 319ms/step - loss: 0.0065 - mean_absolute_error: 0.0881 - val_loss: 0.0054 - val_mean_absolute_error: 0.0814\n",
      "Epoch 260/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0059 - mean_absolute_error: 0.0831\n",
      "Epoch 260: val_loss did not improve from 0.00496\n",
      "9/9 [==============================] - 3s 307ms/step - loss: 0.0059 - mean_absolute_error: 0.0831 - val_loss: 0.0057 - val_mean_absolute_error: 0.0808\n",
      "Epoch 261/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0062 - mean_absolute_error: 0.0841\n",
      "Epoch 261: val_loss did not improve from 0.00496\n",
      "9/9 [==============================] - 3s 302ms/step - loss: 0.0062 - mean_absolute_error: 0.0841 - val_loss: 0.0059 - val_mean_absolute_error: 0.0811\n",
      "Epoch 262/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0062 - mean_absolute_error: 0.0820\n",
      "Epoch 262: val_loss did not improve from 0.00496\n",
      "9/9 [==============================] - 3s 304ms/step - loss: 0.0062 - mean_absolute_error: 0.0820 - val_loss: 0.0053 - val_mean_absolute_error: 0.0811\n",
      "Epoch 263/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0058 - mean_absolute_error: 0.0830\n",
      "Epoch 263: val_loss did not improve from 0.00496\n",
      "9/9 [==============================] - 3s 302ms/step - loss: 0.0058 - mean_absolute_error: 0.0830 - val_loss: 0.0060 - val_mean_absolute_error: 0.0889\n",
      "Epoch 264/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0064 - mean_absolute_error: 0.0879\n",
      "Epoch 264: val_loss did not improve from 0.00496\n",
      "9/9 [==============================] - 3s 319ms/step - loss: 0.0064 - mean_absolute_error: 0.0879 - val_loss: 0.0060 - val_mean_absolute_error: 0.0886\n",
      "Epoch 265/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0055 - mean_absolute_error: 0.0800\n",
      "Epoch 265: val_loss improved from 0.00496 to 0.00470, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 320ms/step - loss: 0.0055 - mean_absolute_error: 0.0800 - val_loss: 0.0047 - val_mean_absolute_error: 0.0753\n",
      "Epoch 266/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0053 - mean_absolute_error: 0.0804\n",
      "Epoch 266: val_loss improved from 0.00470 to 0.00421, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 335ms/step - loss: 0.0053 - mean_absolute_error: 0.0804 - val_loss: 0.0042 - val_mean_absolute_error: 0.0709\n",
      "Epoch 267/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0052 - mean_absolute_error: 0.0805\n",
      "Epoch 267: val_loss improved from 0.00421 to 0.00402, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 334ms/step - loss: 0.0052 - mean_absolute_error: 0.0805 - val_loss: 0.0040 - val_mean_absolute_error: 0.0679\n",
      "Epoch 268/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0049 - mean_absolute_error: 0.0762\n",
      "Epoch 268: val_loss improved from 0.00402 to 0.00397, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 356ms/step - loss: 0.0049 - mean_absolute_error: 0.0762 - val_loss: 0.0040 - val_mean_absolute_error: 0.0707\n",
      "Epoch 269/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0049 - mean_absolute_error: 0.0750\n",
      "Epoch 269: val_loss did not improve from 0.00397\n",
      "9/9 [==============================] - 3s 311ms/step - loss: 0.0049 - mean_absolute_error: 0.0750 - val_loss: 0.0046 - val_mean_absolute_error: 0.0768\n",
      "Epoch 270/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0050 - mean_absolute_error: 0.0766\n",
      "Epoch 270: val_loss did not improve from 0.00397\n",
      "9/9 [==============================] - 3s 301ms/step - loss: 0.0050 - mean_absolute_error: 0.0766 - val_loss: 0.0043 - val_mean_absolute_error: 0.0723\n",
      "Epoch 271/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0051 - mean_absolute_error: 0.0801\n",
      "Epoch 271: val_loss improved from 0.00397 to 0.00397, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 336ms/step - loss: 0.0051 - mean_absolute_error: 0.0801 - val_loss: 0.0040 - val_mean_absolute_error: 0.0723\n",
      "Epoch 272/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0051 - mean_absolute_error: 0.0776\n",
      "Epoch 272: val_loss did not improve from 0.00397\n",
      "9/9 [==============================] - 3s 333ms/step - loss: 0.0051 - mean_absolute_error: 0.0776 - val_loss: 0.0054 - val_mean_absolute_error: 0.0756\n",
      "Epoch 273/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0065 - mean_absolute_error: 0.0873\n",
      "Epoch 273: val_loss did not improve from 0.00397\n",
      "9/9 [==============================] - 3s 299ms/step - loss: 0.0065 - mean_absolute_error: 0.0873 - val_loss: 0.0058 - val_mean_absolute_error: 0.0853\n",
      "Epoch 274/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0065 - mean_absolute_error: 0.0867\n",
      "Epoch 274: val_loss did not improve from 0.00397\n",
      "9/9 [==============================] - 3s 305ms/step - loss: 0.0065 - mean_absolute_error: 0.0867 - val_loss: 0.0055 - val_mean_absolute_error: 0.0788\n",
      "Epoch 275/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0060 - mean_absolute_error: 0.0827\n",
      "Epoch 275: val_loss did not improve from 0.00397\n",
      "9/9 [==============================] - 3s 325ms/step - loss: 0.0060 - mean_absolute_error: 0.0827 - val_loss: 0.0057 - val_mean_absolute_error: 0.0819\n",
      "Epoch 276/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0059 - mean_absolute_error: 0.0814\n",
      "Epoch 276: val_loss did not improve from 0.00397\n",
      "9/9 [==============================] - 3s 336ms/step - loss: 0.0059 - mean_absolute_error: 0.0814 - val_loss: 0.0057 - val_mean_absolute_error: 0.0796\n",
      "Epoch 277/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0065 - mean_absolute_error: 0.0842\n",
      "Epoch 277: val_loss did not improve from 0.00397\n",
      "9/9 [==============================] - 3s 340ms/step - loss: 0.0065 - mean_absolute_error: 0.0842 - val_loss: 0.0058 - val_mean_absolute_error: 0.0849\n",
      "Epoch 278/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0057 - mean_absolute_error: 0.0804\n",
      "Epoch 278: val_loss did not improve from 0.00397\n",
      "9/9 [==============================] - 3s 311ms/step - loss: 0.0057 - mean_absolute_error: 0.0804 - val_loss: 0.0053 - val_mean_absolute_error: 0.0778\n",
      "Epoch 279/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0061 - mean_absolute_error: 0.0807\n",
      "Epoch 279: val_loss did not improve from 0.00397\n",
      "9/9 [==============================] - 3s 315ms/step - loss: 0.0061 - mean_absolute_error: 0.0807 - val_loss: 0.0049 - val_mean_absolute_error: 0.0757\n",
      "Epoch 280/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0054 - mean_absolute_error: 0.0781\n",
      "Epoch 280: val_loss did not improve from 0.00397\n",
      "9/9 [==============================] - 3s 310ms/step - loss: 0.0054 - mean_absolute_error: 0.0781 - val_loss: 0.0049 - val_mean_absolute_error: 0.0777\n",
      "Epoch 281/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0055 - mean_absolute_error: 0.0788\n",
      "Epoch 281: val_loss did not improve from 0.00397\n",
      "9/9 [==============================] - 3s 326ms/step - loss: 0.0055 - mean_absolute_error: 0.0788 - val_loss: 0.0048 - val_mean_absolute_error: 0.0777\n",
      "Epoch 282/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0059 - mean_absolute_error: 0.0830\n",
      "Epoch 282: val_loss did not improve from 0.00397\n",
      "9/9 [==============================] - 3s 334ms/step - loss: 0.0059 - mean_absolute_error: 0.0830 - val_loss: 0.0043 - val_mean_absolute_error: 0.0727\n",
      "Epoch 283/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0049 - mean_absolute_error: 0.0749\n",
      "Epoch 283: val_loss did not improve from 0.00397\n",
      "9/9 [==============================] - 3s 351ms/step - loss: 0.0049 - mean_absolute_error: 0.0749 - val_loss: 0.0045 - val_mean_absolute_error: 0.0742\n",
      "Epoch 284/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0045 - mean_absolute_error: 0.0730\n",
      "Epoch 284: val_loss improved from 0.00397 to 0.00389, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 328ms/step - loss: 0.0045 - mean_absolute_error: 0.0730 - val_loss: 0.0039 - val_mean_absolute_error: 0.0710\n",
      "Epoch 285/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0044 - mean_absolute_error: 0.0727\n",
      "Epoch 285: val_loss did not improve from 0.00389\n",
      "9/9 [==============================] - 3s 324ms/step - loss: 0.0044 - mean_absolute_error: 0.0727 - val_loss: 0.0045 - val_mean_absolute_error: 0.0772\n",
      "Epoch 286/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0045 - mean_absolute_error: 0.0745\n",
      "Epoch 286: val_loss improved from 0.00389 to 0.00370, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 378ms/step - loss: 0.0045 - mean_absolute_error: 0.0745 - val_loss: 0.0037 - val_mean_absolute_error: 0.0703\n",
      "Epoch 287/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0043 - mean_absolute_error: 0.0738\n",
      "Epoch 287: val_loss did not improve from 0.00370\n",
      "9/9 [==============================] - 3s 305ms/step - loss: 0.0043 - mean_absolute_error: 0.0738 - val_loss: 0.0058 - val_mean_absolute_error: 0.0872\n",
      "Epoch 288/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0047 - mean_absolute_error: 0.0755\n",
      "Epoch 288: val_loss improved from 0.00370 to 0.00322, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 313ms/step - loss: 0.0047 - mean_absolute_error: 0.0755 - val_loss: 0.0032 - val_mean_absolute_error: 0.0613\n",
      "Epoch 289/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0040 - mean_absolute_error: 0.0688\n",
      "Epoch 289: val_loss did not improve from 0.00322\n",
      "9/9 [==============================] - 3s 300ms/step - loss: 0.0040 - mean_absolute_error: 0.0688 - val_loss: 0.0042 - val_mean_absolute_error: 0.0753\n",
      "Epoch 290/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0048 - mean_absolute_error: 0.0777\n",
      "Epoch 290: val_loss improved from 0.00322 to 0.00301, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 322ms/step - loss: 0.0048 - mean_absolute_error: 0.0777 - val_loss: 0.0030 - val_mean_absolute_error: 0.0610\n",
      "Epoch 291/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0043 - mean_absolute_error: 0.0733\n",
      "Epoch 291: val_loss did not improve from 0.00301\n",
      "9/9 [==============================] - 3s 310ms/step - loss: 0.0043 - mean_absolute_error: 0.0733 - val_loss: 0.0038 - val_mean_absolute_error: 0.0650\n",
      "Epoch 292/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0040 - mean_absolute_error: 0.0695\n",
      "Epoch 292: val_loss did not improve from 0.00301\n",
      "9/9 [==============================] - 3s 303ms/step - loss: 0.0040 - mean_absolute_error: 0.0695 - val_loss: 0.0033 - val_mean_absolute_error: 0.0629\n",
      "Epoch 293/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0038 - mean_absolute_error: 0.0678\n",
      "Epoch 293: val_loss did not improve from 0.00301\n",
      "9/9 [==============================] - 3s 313ms/step - loss: 0.0038 - mean_absolute_error: 0.0678 - val_loss: 0.0038 - val_mean_absolute_error: 0.0673\n",
      "Epoch 294/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0038 - mean_absolute_error: 0.0678\n",
      "Epoch 294: val_loss did not improve from 0.00301\n",
      "9/9 [==============================] - 3s 303ms/step - loss: 0.0038 - mean_absolute_error: 0.0678 - val_loss: 0.0033 - val_mean_absolute_error: 0.0598\n",
      "Epoch 295/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0037 - mean_absolute_error: 0.0676\n",
      "Epoch 295: val_loss did not improve from 0.00301\n",
      "9/9 [==============================] - 3s 300ms/step - loss: 0.0037 - mean_absolute_error: 0.0676 - val_loss: 0.0030 - val_mean_absolute_error: 0.0594\n",
      "Epoch 296/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0037 - mean_absolute_error: 0.0663\n",
      "Epoch 296: val_loss improved from 0.00301 to 0.00292, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 314ms/step - loss: 0.0037 - mean_absolute_error: 0.0663 - val_loss: 0.0029 - val_mean_absolute_error: 0.0570\n",
      "Epoch 297/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0040 - mean_absolute_error: 0.0703\n",
      "Epoch 297: val_loss did not improve from 0.00292\n",
      "9/9 [==============================] - 3s 299ms/step - loss: 0.0040 - mean_absolute_error: 0.0703 - val_loss: 0.0033 - val_mean_absolute_error: 0.0639\n",
      "Epoch 298/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0037 - mean_absolute_error: 0.0666\n",
      "Epoch 298: val_loss did not improve from 0.00292\n",
      "9/9 [==============================] - 3s 296ms/step - loss: 0.0037 - mean_absolute_error: 0.0666 - val_loss: 0.0031 - val_mean_absolute_error: 0.0574\n",
      "Epoch 299/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0033 - mean_absolute_error: 0.0629\n",
      "Epoch 299: val_loss improved from 0.00292 to 0.00255, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 321ms/step - loss: 0.0033 - mean_absolute_error: 0.0629 - val_loss: 0.0025 - val_mean_absolute_error: 0.0551\n",
      "Epoch 300/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0031 - mean_absolute_error: 0.0617\n",
      "Epoch 300: val_loss did not improve from 0.00255\n",
      "9/9 [==============================] - 3s 328ms/step - loss: 0.0031 - mean_absolute_error: 0.0617 - val_loss: 0.0031 - val_mean_absolute_error: 0.0584\n",
      "Epoch 301/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0029 - mean_absolute_error: 0.0589\n",
      "Epoch 301: val_loss did not improve from 0.00255\n",
      "9/9 [==============================] - 3s 323ms/step - loss: 0.0029 - mean_absolute_error: 0.0589 - val_loss: 0.0041 - val_mean_absolute_error: 0.0684\n",
      "Epoch 302/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0039 - mean_absolute_error: 0.0677\n",
      "Epoch 302: val_loss did not improve from 0.00255\n",
      "9/9 [==============================] - 3s 355ms/step - loss: 0.0039 - mean_absolute_error: 0.0677 - val_loss: 0.0040 - val_mean_absolute_error: 0.0676\n",
      "Epoch 303/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0046 - mean_absolute_error: 0.0735\n",
      "Epoch 303: val_loss did not improve from 0.00255\n",
      "9/9 [==============================] - 3s 316ms/step - loss: 0.0046 - mean_absolute_error: 0.0735 - val_loss: 0.0034 - val_mean_absolute_error: 0.0649\n",
      "Epoch 304/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0035 - mean_absolute_error: 0.0648\n",
      "Epoch 304: val_loss did not improve from 0.00255\n",
      "9/9 [==============================] - 3s 315ms/step - loss: 0.0035 - mean_absolute_error: 0.0648 - val_loss: 0.0031 - val_mean_absolute_error: 0.0628\n",
      "Epoch 305/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0033 - mean_absolute_error: 0.0618\n",
      "Epoch 305: val_loss did not improve from 0.00255\n",
      "9/9 [==============================] - 3s 318ms/step - loss: 0.0033 - mean_absolute_error: 0.0618 - val_loss: 0.0033 - val_mean_absolute_error: 0.0601\n",
      "Epoch 306/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0048 - mean_absolute_error: 0.0736\n",
      "Epoch 306: val_loss did not improve from 0.00255\n",
      "9/9 [==============================] - 3s 318ms/step - loss: 0.0048 - mean_absolute_error: 0.0736 - val_loss: 0.0054 - val_mean_absolute_error: 0.0767\n",
      "Epoch 307/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0044 - mean_absolute_error: 0.0730\n",
      "Epoch 307: val_loss did not improve from 0.00255\n",
      "9/9 [==============================] - 3s 306ms/step - loss: 0.0044 - mean_absolute_error: 0.0730 - val_loss: 0.0037 - val_mean_absolute_error: 0.0648\n",
      "Epoch 308/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0042 - mean_absolute_error: 0.0701\n",
      "Epoch 308: val_loss did not improve from 0.00255\n",
      "9/9 [==============================] - 3s 316ms/step - loss: 0.0042 - mean_absolute_error: 0.0701 - val_loss: 0.0030 - val_mean_absolute_error: 0.0584\n",
      "Epoch 309/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0038 - mean_absolute_error: 0.0658\n",
      "Epoch 309: val_loss did not improve from 0.00255\n",
      "9/9 [==============================] - 3s 311ms/step - loss: 0.0038 - mean_absolute_error: 0.0658 - val_loss: 0.0033 - val_mean_absolute_error: 0.0653\n",
      "Epoch 310/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0031 - mean_absolute_error: 0.0622\n",
      "Epoch 310: val_loss did not improve from 0.00255\n",
      "9/9 [==============================] - 3s 305ms/step - loss: 0.0031 - mean_absolute_error: 0.0622 - val_loss: 0.0029 - val_mean_absolute_error: 0.0589\n",
      "Epoch 311/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0033 - mean_absolute_error: 0.0628\n",
      "Epoch 311: val_loss did not improve from 0.00255\n",
      "9/9 [==============================] - 3s 308ms/step - loss: 0.0033 - mean_absolute_error: 0.0628 - val_loss: 0.0027 - val_mean_absolute_error: 0.0555\n",
      "Epoch 312/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0032 - mean_absolute_error: 0.0604\n",
      "Epoch 312: val_loss did not improve from 0.00255\n",
      "9/9 [==============================] - 3s 327ms/step - loss: 0.0032 - mean_absolute_error: 0.0604 - val_loss: 0.0026 - val_mean_absolute_error: 0.0528\n",
      "Epoch 313/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0033 - mean_absolute_error: 0.0623\n",
      "Epoch 313: val_loss did not improve from 0.00255\n",
      "9/9 [==============================] - 3s 367ms/step - loss: 0.0033 - mean_absolute_error: 0.0623 - val_loss: 0.0028 - val_mean_absolute_error: 0.0558\n",
      "Epoch 314/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0035 - mean_absolute_error: 0.0636\n",
      "Epoch 314: val_loss did not improve from 0.00255\n",
      "9/9 [==============================] - 3s 304ms/step - loss: 0.0035 - mean_absolute_error: 0.0636 - val_loss: 0.0026 - val_mean_absolute_error: 0.0552\n",
      "Epoch 315/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0028 - mean_absolute_error: 0.0573\n",
      "Epoch 315: val_loss did not improve from 0.00255\n",
      "9/9 [==============================] - 3s 307ms/step - loss: 0.0028 - mean_absolute_error: 0.0573 - val_loss: 0.0026 - val_mean_absolute_error: 0.0560\n",
      "Epoch 316/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0026 - mean_absolute_error: 0.0569\n",
      "Epoch 316: val_loss improved from 0.00255 to 0.00252, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 318ms/step - loss: 0.0026 - mean_absolute_error: 0.0569 - val_loss: 0.0025 - val_mean_absolute_error: 0.0553\n",
      "Epoch 317/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0028 - mean_absolute_error: 0.0564\n",
      "Epoch 317: val_loss improved from 0.00252 to 0.00233, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 357ms/step - loss: 0.0028 - mean_absolute_error: 0.0564 - val_loss: 0.0023 - val_mean_absolute_error: 0.0519\n",
      "Epoch 318/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0026 - mean_absolute_error: 0.0558\n",
      "Epoch 318: val_loss did not improve from 0.00233\n",
      "9/9 [==============================] - 3s 359ms/step - loss: 0.0026 - mean_absolute_error: 0.0558 - val_loss: 0.0026 - val_mean_absolute_error: 0.0539\n",
      "Epoch 319/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0026 - mean_absolute_error: 0.0569\n",
      "Epoch 319: val_loss improved from 0.00233 to 0.00228, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 335ms/step - loss: 0.0026 - mean_absolute_error: 0.0569 - val_loss: 0.0023 - val_mean_absolute_error: 0.0493\n",
      "Epoch 320/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.0553\n",
      "Epoch 320: val_loss did not improve from 0.00228\n",
      "9/9 [==============================] - 3s 310ms/step - loss: 0.0025 - mean_absolute_error: 0.0553 - val_loss: 0.0026 - val_mean_absolute_error: 0.0578\n",
      "Epoch 321/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0028 - mean_absolute_error: 0.0582\n",
      "Epoch 321: val_loss did not improve from 0.00228\n",
      "9/9 [==============================] - 3s 376ms/step - loss: 0.0028 - mean_absolute_error: 0.0582 - val_loss: 0.0023 - val_mean_absolute_error: 0.0527\n",
      "Epoch 322/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0031 - mean_absolute_error: 0.0599\n",
      "Epoch 322: val_loss did not improve from 0.00228\n",
      "9/9 [==============================] - 3s 334ms/step - loss: 0.0031 - mean_absolute_error: 0.0599 - val_loss: 0.0028 - val_mean_absolute_error: 0.0566\n",
      "Epoch 323/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0026 - mean_absolute_error: 0.0564\n",
      "Epoch 323: val_loss did not improve from 0.00228\n",
      "9/9 [==============================] - 3s 300ms/step - loss: 0.0026 - mean_absolute_error: 0.0564 - val_loss: 0.0025 - val_mean_absolute_error: 0.0545\n",
      "Epoch 324/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0023 - mean_absolute_error: 0.0519\n",
      "Epoch 324: val_loss did not improve from 0.00228\n",
      "9/9 [==============================] - 3s 320ms/step - loss: 0.0023 - mean_absolute_error: 0.0519 - val_loss: 0.0025 - val_mean_absolute_error: 0.0563\n",
      "Epoch 325/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0026 - mean_absolute_error: 0.0537\n",
      "Epoch 325: val_loss did not improve from 0.00228\n",
      "9/9 [==============================] - 3s 332ms/step - loss: 0.0026 - mean_absolute_error: 0.0537 - val_loss: 0.0027 - val_mean_absolute_error: 0.0555\n",
      "Epoch 326/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0023 - mean_absolute_error: 0.0533\n",
      "Epoch 326: val_loss improved from 0.00228 to 0.00188, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 4s 423ms/step - loss: 0.0023 - mean_absolute_error: 0.0533 - val_loss: 0.0019 - val_mean_absolute_error: 0.0476\n",
      "Epoch 327/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0026 - mean_absolute_error: 0.0563\n",
      "Epoch 327: val_loss did not improve from 0.00188\n",
      "9/9 [==============================] - 3s 336ms/step - loss: 0.0026 - mean_absolute_error: 0.0563 - val_loss: 0.0022 - val_mean_absolute_error: 0.0490\n",
      "Epoch 328/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0027 - mean_absolute_error: 0.0558\n",
      "Epoch 328: val_loss did not improve from 0.00188\n",
      "9/9 [==============================] - 3s 344ms/step - loss: 0.0027 - mean_absolute_error: 0.0558 - val_loss: 0.0028 - val_mean_absolute_error: 0.0584\n",
      "Epoch 329/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0028 - mean_absolute_error: 0.0580\n",
      "Epoch 329: val_loss did not improve from 0.00188\n",
      "9/9 [==============================] - 3s 318ms/step - loss: 0.0028 - mean_absolute_error: 0.0580 - val_loss: 0.0021 - val_mean_absolute_error: 0.0506\n",
      "Epoch 330/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0024 - mean_absolute_error: 0.0535\n",
      "Epoch 330: val_loss did not improve from 0.00188\n",
      "9/9 [==============================] - 3s 314ms/step - loss: 0.0024 - mean_absolute_error: 0.0535 - val_loss: 0.0020 - val_mean_absolute_error: 0.0491\n",
      "Epoch 331/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0024 - mean_absolute_error: 0.0534\n",
      "Epoch 331: val_loss did not improve from 0.00188\n",
      "9/9 [==============================] - 3s 302ms/step - loss: 0.0024 - mean_absolute_error: 0.0534 - val_loss: 0.0021 - val_mean_absolute_error: 0.0476\n",
      "Epoch 332/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0522\n",
      "Epoch 332: val_loss did not improve from 0.00188\n",
      "9/9 [==============================] - 3s 313ms/step - loss: 0.0022 - mean_absolute_error: 0.0522 - val_loss: 0.0020 - val_mean_absolute_error: 0.0490\n",
      "Epoch 333/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0502\n",
      "Epoch 333: val_loss did not improve from 0.00188\n",
      "9/9 [==============================] - 3s 300ms/step - loss: 0.0021 - mean_absolute_error: 0.0502 - val_loss: 0.0020 - val_mean_absolute_error: 0.0475\n",
      "Epoch 334/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0024 - mean_absolute_error: 0.0539\n",
      "Epoch 334: val_loss improved from 0.00188 to 0.00186, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 325ms/step - loss: 0.0024 - mean_absolute_error: 0.0539 - val_loss: 0.0019 - val_mean_absolute_error: 0.0472\n",
      "Epoch 335/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0023 - mean_absolute_error: 0.0527\n",
      "Epoch 335: val_loss improved from 0.00186 to 0.00169, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 319ms/step - loss: 0.0023 - mean_absolute_error: 0.0527 - val_loss: 0.0017 - val_mean_absolute_error: 0.0441\n",
      "Epoch 336/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0494\n",
      "Epoch 336: val_loss did not improve from 0.00169\n",
      "9/9 [==============================] - 3s 303ms/step - loss: 0.0021 - mean_absolute_error: 0.0494 - val_loss: 0.0017 - val_mean_absolute_error: 0.0451\n",
      "Epoch 337/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0487\n",
      "Epoch 337: val_loss improved from 0.00169 to 0.00160, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 314ms/step - loss: 0.0019 - mean_absolute_error: 0.0487 - val_loss: 0.0016 - val_mean_absolute_error: 0.0427\n",
      "Epoch 338/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0501\n",
      "Epoch 338: val_loss did not improve from 0.00160\n",
      "9/9 [==============================] - 3s 307ms/step - loss: 0.0021 - mean_absolute_error: 0.0501 - val_loss: 0.0018 - val_mean_absolute_error: 0.0451\n",
      "Epoch 339/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0513\n",
      "Epoch 339: val_loss did not improve from 0.00160\n",
      "9/9 [==============================] - 3s 300ms/step - loss: 0.0022 - mean_absolute_error: 0.0513 - val_loss: 0.0017 - val_mean_absolute_error: 0.0461\n",
      "Epoch 340/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0498\n",
      "Epoch 340: val_loss did not improve from 0.00160\n",
      "9/9 [==============================] - 3s 300ms/step - loss: 0.0021 - mean_absolute_error: 0.0498 - val_loss: 0.0025 - val_mean_absolute_error: 0.0543\n",
      "Epoch 341/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0026 - mean_absolute_error: 0.0547\n",
      "Epoch 341: val_loss did not improve from 0.00160\n",
      "9/9 [==============================] - 3s 306ms/step - loss: 0.0026 - mean_absolute_error: 0.0547 - val_loss: 0.0020 - val_mean_absolute_error: 0.0468\n",
      "Epoch 342/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0026 - mean_absolute_error: 0.0550\n",
      "Epoch 342: val_loss did not improve from 0.00160\n",
      "9/9 [==============================] - 3s 298ms/step - loss: 0.0026 - mean_absolute_error: 0.0550 - val_loss: 0.0024 - val_mean_absolute_error: 0.0506\n",
      "Epoch 343/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0026 - mean_absolute_error: 0.0557\n",
      "Epoch 343: val_loss did not improve from 0.00160\n",
      "9/9 [==============================] - 3s 316ms/step - loss: 0.0026 - mean_absolute_error: 0.0557 - val_loss: 0.0018 - val_mean_absolute_error: 0.0459\n",
      "Epoch 344/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0474\n",
      "Epoch 344: val_loss did not improve from 0.00160\n",
      "9/9 [==============================] - 3s 298ms/step - loss: 0.0019 - mean_absolute_error: 0.0474 - val_loss: 0.0021 - val_mean_absolute_error: 0.0500\n",
      "Epoch 345/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0469\n",
      "Epoch 345: val_loss did not improve from 0.00160\n",
      "9/9 [==============================] - 3s 301ms/step - loss: 0.0019 - mean_absolute_error: 0.0469 - val_loss: 0.0020 - val_mean_absolute_error: 0.0477\n",
      "Epoch 346/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0498\n",
      "Epoch 346: val_loss improved from 0.00160 to 0.00159, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 331ms/step - loss: 0.0021 - mean_absolute_error: 0.0498 - val_loss: 0.0016 - val_mean_absolute_error: 0.0431\n",
      "Epoch 347/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0481\n",
      "Epoch 347: val_loss improved from 0.00159 to 0.00141, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 362ms/step - loss: 0.0020 - mean_absolute_error: 0.0481 - val_loss: 0.0014 - val_mean_absolute_error: 0.0415\n",
      "Epoch 348/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0501\n",
      "Epoch 348: val_loss did not improve from 0.00141\n",
      "9/9 [==============================] - 3s 327ms/step - loss: 0.0021 - mean_absolute_error: 0.0501 - val_loss: 0.0019 - val_mean_absolute_error: 0.0461\n",
      "Epoch 349/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0460\n",
      "Epoch 349: val_loss did not improve from 0.00141\n",
      "9/9 [==============================] - 3s 332ms/step - loss: 0.0018 - mean_absolute_error: 0.0460 - val_loss: 0.0018 - val_mean_absolute_error: 0.0469\n",
      "Epoch 350/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0489\n",
      "Epoch 350: val_loss did not improve from 0.00141\n",
      "9/9 [==============================] - 3s 298ms/step - loss: 0.0020 - mean_absolute_error: 0.0489 - val_loss: 0.0018 - val_mean_absolute_error: 0.0463\n",
      "Epoch 351/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0487\n",
      "Epoch 351: val_loss did not improve from 0.00141\n",
      "9/9 [==============================] - 3s 298ms/step - loss: 0.0020 - mean_absolute_error: 0.0487 - val_loss: 0.0016 - val_mean_absolute_error: 0.0442\n",
      "Epoch 352/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0488\n",
      "Epoch 352: val_loss did not improve from 0.00141\n",
      "9/9 [==============================] - 3s 302ms/step - loss: 0.0020 - mean_absolute_error: 0.0488 - val_loss: 0.0019 - val_mean_absolute_error: 0.0491\n",
      "Epoch 353/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.0546\n",
      "Epoch 353: val_loss did not improve from 0.00141\n",
      "9/9 [==============================] - 3s 300ms/step - loss: 0.0025 - mean_absolute_error: 0.0546 - val_loss: 0.0020 - val_mean_absolute_error: 0.0503\n",
      "Epoch 354/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0024 - mean_absolute_error: 0.0522\n",
      "Epoch 354: val_loss did not improve from 0.00141\n",
      "9/9 [==============================] - 3s 305ms/step - loss: 0.0024 - mean_absolute_error: 0.0522 - val_loss: 0.0020 - val_mean_absolute_error: 0.0457\n",
      "Epoch 355/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0500\n",
      "Epoch 355: val_loss did not improve from 0.00141\n",
      "9/9 [==============================] - 3s 301ms/step - loss: 0.0021 - mean_absolute_error: 0.0500 - val_loss: 0.0017 - val_mean_absolute_error: 0.0470\n",
      "Epoch 356/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0505\n",
      "Epoch 356: val_loss did not improve from 0.00141\n",
      "9/9 [==============================] - 3s 303ms/step - loss: 0.0021 - mean_absolute_error: 0.0505 - val_loss: 0.0021 - val_mean_absolute_error: 0.0509\n",
      "Epoch 357/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0470\n",
      "Epoch 357: val_loss did not improve from 0.00141\n",
      "9/9 [==============================] - 3s 326ms/step - loss: 0.0020 - mean_absolute_error: 0.0470 - val_loss: 0.0023 - val_mean_absolute_error: 0.0526\n",
      "Epoch 358/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.0546\n",
      "Epoch 358: val_loss did not improve from 0.00141\n",
      "9/9 [==============================] - 3s 309ms/step - loss: 0.0025 - mean_absolute_error: 0.0546 - val_loss: 0.0020 - val_mean_absolute_error: 0.0448\n",
      "Epoch 359/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0026 - mean_absolute_error: 0.0557\n",
      "Epoch 359: val_loss did not improve from 0.00141\n",
      "9/9 [==============================] - 3s 333ms/step - loss: 0.0026 - mean_absolute_error: 0.0557 - val_loss: 0.0021 - val_mean_absolute_error: 0.0507\n",
      "Epoch 360/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0023 - mean_absolute_error: 0.0522\n",
      "Epoch 360: val_loss did not improve from 0.00141\n",
      "9/9 [==============================] - 3s 310ms/step - loss: 0.0023 - mean_absolute_error: 0.0522 - val_loss: 0.0022 - val_mean_absolute_error: 0.0514\n",
      "Epoch 361/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0026 - mean_absolute_error: 0.0563\n",
      "Epoch 361: val_loss did not improve from 0.00141\n",
      "9/9 [==============================] - 3s 319ms/step - loss: 0.0026 - mean_absolute_error: 0.0563 - val_loss: 0.0020 - val_mean_absolute_error: 0.0494\n",
      "Epoch 362/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0509\n",
      "Epoch 362: val_loss improved from 0.00141 to 0.00139, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 320ms/step - loss: 0.0021 - mean_absolute_error: 0.0509 - val_loss: 0.0014 - val_mean_absolute_error: 0.0412\n",
      "Epoch 363/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0482\n",
      "Epoch 363: val_loss did not improve from 0.00139\n",
      "9/9 [==============================] - 3s 315ms/step - loss: 0.0019 - mean_absolute_error: 0.0482 - val_loss: 0.0016 - val_mean_absolute_error: 0.0426\n",
      "Epoch 364/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0500\n",
      "Epoch 364: val_loss did not improve from 0.00139\n",
      "9/9 [==============================] - 3s 307ms/step - loss: 0.0022 - mean_absolute_error: 0.0500 - val_loss: 0.0023 - val_mean_absolute_error: 0.0519\n",
      "Epoch 365/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0494\n",
      "Epoch 365: val_loss did not improve from 0.00139\n",
      "9/9 [==============================] - 3s 318ms/step - loss: 0.0021 - mean_absolute_error: 0.0494 - val_loss: 0.0022 - val_mean_absolute_error: 0.0512\n",
      "Epoch 366/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0495\n",
      "Epoch 366: val_loss did not improve from 0.00139\n",
      "9/9 [==============================] - 3s 310ms/step - loss: 0.0020 - mean_absolute_error: 0.0495 - val_loss: 0.0014 - val_mean_absolute_error: 0.0401\n",
      "Epoch 367/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0459\n",
      "Epoch 367: val_loss did not improve from 0.00139\n",
      "9/9 [==============================] - 3s 344ms/step - loss: 0.0018 - mean_absolute_error: 0.0459 - val_loss: 0.0015 - val_mean_absolute_error: 0.0417\n",
      "Epoch 368/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0455\n",
      "Epoch 368: val_loss did not improve from 0.00139\n",
      "9/9 [==============================] - 3s 310ms/step - loss: 0.0017 - mean_absolute_error: 0.0455 - val_loss: 0.0020 - val_mean_absolute_error: 0.0462\n",
      "Epoch 369/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0488\n",
      "Epoch 369: val_loss did not improve from 0.00139\n",
      "9/9 [==============================] - 3s 309ms/step - loss: 0.0020 - mean_absolute_error: 0.0488 - val_loss: 0.0017 - val_mean_absolute_error: 0.0444\n",
      "Epoch 370/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0491\n",
      "Epoch 370: val_loss did not improve from 0.00139\n",
      "9/9 [==============================] - 3s 305ms/step - loss: 0.0020 - mean_absolute_error: 0.0491 - val_loss: 0.0014 - val_mean_absolute_error: 0.0410\n",
      "Epoch 371/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0500\n",
      "Epoch 371: val_loss did not improve from 0.00139\n",
      "9/9 [==============================] - 3s 321ms/step - loss: 0.0021 - mean_absolute_error: 0.0500 - val_loss: 0.0017 - val_mean_absolute_error: 0.0464\n",
      "Epoch 372/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0493\n",
      "Epoch 372: val_loss did not improve from 0.00139\n",
      "9/9 [==============================] - 3s 318ms/step - loss: 0.0020 - mean_absolute_error: 0.0493 - val_loss: 0.0022 - val_mean_absolute_error: 0.0468\n",
      "Epoch 373/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0029 - mean_absolute_error: 0.0572\n",
      "Epoch 373: val_loss did not improve from 0.00139\n",
      "9/9 [==============================] - 3s 328ms/step - loss: 0.0029 - mean_absolute_error: 0.0572 - val_loss: 0.0031 - val_mean_absolute_error: 0.0579\n",
      "Epoch 374/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0029 - mean_absolute_error: 0.0581\n",
      "Epoch 374: val_loss did not improve from 0.00139\n",
      "9/9 [==============================] - 3s 346ms/step - loss: 0.0029 - mean_absolute_error: 0.0581 - val_loss: 0.0024 - val_mean_absolute_error: 0.0525\n",
      "Epoch 375/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0024 - mean_absolute_error: 0.0535\n",
      "Epoch 375: val_loss did not improve from 0.00139\n",
      "9/9 [==============================] - 3s 344ms/step - loss: 0.0024 - mean_absolute_error: 0.0535 - val_loss: 0.0023 - val_mean_absolute_error: 0.0531\n",
      "Epoch 376/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.0545\n",
      "Epoch 376: val_loss did not improve from 0.00139\n",
      "9/9 [==============================] - 3s 323ms/step - loss: 0.0025 - mean_absolute_error: 0.0545 - val_loss: 0.0018 - val_mean_absolute_error: 0.0455\n",
      "Epoch 377/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0497\n",
      "Epoch 377: val_loss did not improve from 0.00139\n",
      "9/9 [==============================] - 3s 353ms/step - loss: 0.0021 - mean_absolute_error: 0.0497 - val_loss: 0.0022 - val_mean_absolute_error: 0.0505\n",
      "Epoch 378/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0497\n",
      "Epoch 378: val_loss did not improve from 0.00139\n",
      "9/9 [==============================] - 3s 313ms/step - loss: 0.0021 - mean_absolute_error: 0.0497 - val_loss: 0.0018 - val_mean_absolute_error: 0.0477\n",
      "Epoch 379/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0492\n",
      "Epoch 379: val_loss did not improve from 0.00139\n",
      "9/9 [==============================] - 3s 320ms/step - loss: 0.0021 - mean_absolute_error: 0.0492 - val_loss: 0.0014 - val_mean_absolute_error: 0.0401\n",
      "Epoch 380/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0451\n",
      "Epoch 380: val_loss did not improve from 0.00139\n",
      "9/9 [==============================] - 3s 342ms/step - loss: 0.0018 - mean_absolute_error: 0.0451 - val_loss: 0.0015 - val_mean_absolute_error: 0.0424\n",
      "Epoch 381/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0461\n",
      "Epoch 381: val_loss improved from 0.00139 to 0.00134, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 315ms/step - loss: 0.0018 - mean_absolute_error: 0.0461 - val_loss: 0.0013 - val_mean_absolute_error: 0.0399\n",
      "Epoch 382/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0443\n",
      "Epoch 382: val_loss did not improve from 0.00134\n",
      "9/9 [==============================] - 3s 306ms/step - loss: 0.0016 - mean_absolute_error: 0.0443 - val_loss: 0.0015 - val_mean_absolute_error: 0.0417\n",
      "Epoch 383/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0450\n",
      "Epoch 383: val_loss did not improve from 0.00134\n",
      "9/9 [==============================] - 3s 319ms/step - loss: 0.0018 - mean_absolute_error: 0.0450 - val_loss: 0.0022 - val_mean_absolute_error: 0.0514\n",
      "Epoch 384/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0492\n",
      "Epoch 384: val_loss did not improve from 0.00134\n",
      "9/9 [==============================] - 3s 331ms/step - loss: 0.0020 - mean_absolute_error: 0.0492 - val_loss: 0.0016 - val_mean_absolute_error: 0.0437\n",
      "Epoch 385/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0449\n",
      "Epoch 385: val_loss did not improve from 0.00134\n",
      "9/9 [==============================] - 3s 316ms/step - loss: 0.0017 - mean_absolute_error: 0.0449 - val_loss: 0.0014 - val_mean_absolute_error: 0.0399\n",
      "Epoch 386/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0447\n",
      "Epoch 386: val_loss improved from 0.00134 to 0.00132, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 324ms/step - loss: 0.0016 - mean_absolute_error: 0.0447 - val_loss: 0.0013 - val_mean_absolute_error: 0.0393\n",
      "Epoch 387/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0439\n",
      "Epoch 387: val_loss did not improve from 0.00132\n",
      "9/9 [==============================] - 3s 305ms/step - loss: 0.0016 - mean_absolute_error: 0.0439 - val_loss: 0.0015 - val_mean_absolute_error: 0.0415\n",
      "Epoch 388/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0447\n",
      "Epoch 388: val_loss did not improve from 0.00132\n",
      "9/9 [==============================] - 3s 302ms/step - loss: 0.0017 - mean_absolute_error: 0.0447 - val_loss: 0.0016 - val_mean_absolute_error: 0.0431\n",
      "Epoch 389/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0454\n",
      "Epoch 389: val_loss did not improve from 0.00132\n",
      "9/9 [==============================] - 3s 309ms/step - loss: 0.0017 - mean_absolute_error: 0.0454 - val_loss: 0.0015 - val_mean_absolute_error: 0.0452\n",
      "Epoch 390/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0453\n",
      "Epoch 390: val_loss improved from 0.00132 to 0.00111, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 326ms/step - loss: 0.0017 - mean_absolute_error: 0.0453 - val_loss: 0.0011 - val_mean_absolute_error: 0.0346\n",
      "Epoch 391/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0435\n",
      "Epoch 391: val_loss did not improve from 0.00111\n",
      "9/9 [==============================] - 3s 300ms/step - loss: 0.0016 - mean_absolute_error: 0.0435 - val_loss: 0.0013 - val_mean_absolute_error: 0.0382\n",
      "Epoch 392/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0434\n",
      "Epoch 392: val_loss did not improve from 0.00111\n",
      "9/9 [==============================] - 3s 302ms/step - loss: 0.0017 - mean_absolute_error: 0.0434 - val_loss: 0.0012 - val_mean_absolute_error: 0.0376\n",
      "Epoch 393/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0445\n",
      "Epoch 393: val_loss improved from 0.00111 to 0.00111, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 326ms/step - loss: 0.0016 - mean_absolute_error: 0.0445 - val_loss: 0.0011 - val_mean_absolute_error: 0.0366\n",
      "Epoch 394/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0400\n",
      "Epoch 394: val_loss did not improve from 0.00111\n",
      "9/9 [==============================] - 3s 348ms/step - loss: 0.0013 - mean_absolute_error: 0.0400 - val_loss: 0.0011 - val_mean_absolute_error: 0.0352\n",
      "Epoch 395/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0390\n",
      "Epoch 395: val_loss did not improve from 0.00111\n",
      "9/9 [==============================] - 3s 316ms/step - loss: 0.0012 - mean_absolute_error: 0.0390 - val_loss: 0.0012 - val_mean_absolute_error: 0.0387\n",
      "Epoch 396/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0400\n",
      "Epoch 396: val_loss improved from 0.00111 to 0.00096, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 346ms/step - loss: 0.0013 - mean_absolute_error: 0.0400 - val_loss: 9.6102e-04 - val_mean_absolute_error: 0.0340\n",
      "Epoch 397/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0400\n",
      "Epoch 397: val_loss did not improve from 0.00096\n",
      "9/9 [==============================] - 3s 313ms/step - loss: 0.0014 - mean_absolute_error: 0.0400 - val_loss: 0.0024 - val_mean_absolute_error: 0.0488\n",
      "Epoch 398/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0441\n",
      "Epoch 398: val_loss did not improve from 0.00096\n",
      "9/9 [==============================] - 3s 313ms/step - loss: 0.0015 - mean_absolute_error: 0.0441 - val_loss: 0.0013 - val_mean_absolute_error: 0.0393\n",
      "Epoch 399/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0440\n",
      "Epoch 399: val_loss did not improve from 0.00096\n",
      "9/9 [==============================] - 3s 322ms/step - loss: 0.0016 - mean_absolute_error: 0.0440 - val_loss: 0.0011 - val_mean_absolute_error: 0.0367\n",
      "Epoch 400/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0405\n",
      "Epoch 400: val_loss did not improve from 0.00096\n",
      "9/9 [==============================] - 3s 315ms/step - loss: 0.0013 - mean_absolute_error: 0.0405 - val_loss: 0.0021 - val_mean_absolute_error: 0.0495\n",
      "Epoch 401/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0472\n",
      "Epoch 401: val_loss did not improve from 0.00096\n",
      "9/9 [==============================] - 3s 377ms/step - loss: 0.0021 - mean_absolute_error: 0.0472 - val_loss: 0.0017 - val_mean_absolute_error: 0.0439\n",
      "Epoch 402/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0464\n",
      "Epoch 402: val_loss did not improve from 0.00096\n",
      "9/9 [==============================] - 3s 372ms/step - loss: 0.0018 - mean_absolute_error: 0.0464 - val_loss: 0.0015 - val_mean_absolute_error: 0.0415\n",
      "Epoch 403/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0469\n",
      "Epoch 403: val_loss did not improve from 0.00096\n",
      "9/9 [==============================] - 3s 299ms/step - loss: 0.0018 - mean_absolute_error: 0.0469 - val_loss: 0.0019 - val_mean_absolute_error: 0.0463\n",
      "Epoch 404/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0457\n",
      "Epoch 404: val_loss did not improve from 0.00096\n",
      "9/9 [==============================] - 3s 319ms/step - loss: 0.0017 - mean_absolute_error: 0.0457 - val_loss: 0.0017 - val_mean_absolute_error: 0.0444\n",
      "Epoch 405/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0464\n",
      "Epoch 405: val_loss did not improve from 0.00096\n",
      "9/9 [==============================] - 3s 318ms/step - loss: 0.0018 - mean_absolute_error: 0.0464 - val_loss: 0.0016 - val_mean_absolute_error: 0.0420\n",
      "Epoch 406/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0434\n",
      "Epoch 406: val_loss did not improve from 0.00096\n",
      "9/9 [==============================] - 3s 328ms/step - loss: 0.0015 - mean_absolute_error: 0.0434 - val_loss: 0.0013 - val_mean_absolute_error: 0.0400\n",
      "Epoch 407/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0435\n",
      "Epoch 407: val_loss did not improve from 0.00096\n",
      "9/9 [==============================] - 3s 354ms/step - loss: 0.0015 - mean_absolute_error: 0.0435 - val_loss: 0.0017 - val_mean_absolute_error: 0.0454\n",
      "Epoch 408/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0467\n",
      "Epoch 408: val_loss did not improve from 0.00096\n",
      "9/9 [==============================] - 3s 336ms/step - loss: 0.0017 - mean_absolute_error: 0.0467 - val_loss: 0.0013 - val_mean_absolute_error: 0.0415\n",
      "Epoch 409/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0405\n",
      "Epoch 409: val_loss did not improve from 0.00096\n",
      "9/9 [==============================] - 3s 319ms/step - loss: 0.0013 - mean_absolute_error: 0.0405 - val_loss: 0.0014 - val_mean_absolute_error: 0.0409\n",
      "Epoch 410/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0404\n",
      "Epoch 410: val_loss did not improve from 0.00096\n",
      "9/9 [==============================] - 3s 319ms/step - loss: 0.0013 - mean_absolute_error: 0.0404 - val_loss: 0.0012 - val_mean_absolute_error: 0.0387\n",
      "Epoch 411/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0409\n",
      "Epoch 411: val_loss did not improve from 0.00096\n",
      "9/9 [==============================] - 3s 310ms/step - loss: 0.0013 - mean_absolute_error: 0.0409 - val_loss: 0.0012 - val_mean_absolute_error: 0.0353\n",
      "Epoch 412/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0405\n",
      "Epoch 412: val_loss did not improve from 0.00096\n",
      "9/9 [==============================] - 3s 302ms/step - loss: 0.0013 - mean_absolute_error: 0.0405 - val_loss: 0.0016 - val_mean_absolute_error: 0.0427\n",
      "Epoch 413/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0410\n",
      "Epoch 413: val_loss did not improve from 0.00096\n",
      "9/9 [==============================] - 3s 328ms/step - loss: 0.0014 - mean_absolute_error: 0.0410 - val_loss: 0.0015 - val_mean_absolute_error: 0.0404\n",
      "Epoch 414/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0416\n",
      "Epoch 414: val_loss did not improve from 0.00096\n",
      "9/9 [==============================] - 3s 315ms/step - loss: 0.0015 - mean_absolute_error: 0.0416 - val_loss: 0.0011 - val_mean_absolute_error: 0.0358\n",
      "Epoch 415/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0426\n",
      "Epoch 415: val_loss did not improve from 0.00096\n",
      "9/9 [==============================] - 3s 332ms/step - loss: 0.0015 - mean_absolute_error: 0.0426 - val_loss: 0.0013 - val_mean_absolute_error: 0.0387\n",
      "Epoch 416/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0432\n",
      "Epoch 416: val_loss did not improve from 0.00096\n",
      "9/9 [==============================] - 3s 354ms/step - loss: 0.0014 - mean_absolute_error: 0.0432 - val_loss: 0.0010 - val_mean_absolute_error: 0.0357\n",
      "Epoch 417/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0380\n",
      "Epoch 417: val_loss did not improve from 0.00096\n",
      "9/9 [==============================] - 3s 305ms/step - loss: 0.0011 - mean_absolute_error: 0.0380 - val_loss: 0.0011 - val_mean_absolute_error: 0.0360\n",
      "Epoch 418/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0370 \n",
      "Epoch 418: val_loss improved from 0.00096 to 0.00083, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 327ms/step - loss: 0.0011 - mean_absolute_error: 0.0370 - val_loss: 8.2982e-04 - val_mean_absolute_error: 0.0316\n",
      "Epoch 419/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0364\n",
      "Epoch 419: val_loss did not improve from 0.00083\n",
      "9/9 [==============================] - 3s 325ms/step - loss: 0.0011 - mean_absolute_error: 0.0364 - val_loss: 9.6491e-04 - val_mean_absolute_error: 0.0342\n",
      "Epoch 420/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0375\n",
      "Epoch 420: val_loss did not improve from 0.00083\n",
      "9/9 [==============================] - 3s 309ms/step - loss: 0.0011 - mean_absolute_error: 0.0375 - val_loss: 0.0012 - val_mean_absolute_error: 0.0356\n",
      "Epoch 421/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0366\n",
      "Epoch 421: val_loss did not improve from 0.00083\n",
      "9/9 [==============================] - 3s 321ms/step - loss: 0.0010 - mean_absolute_error: 0.0366 - val_loss: 9.0996e-04 - val_mean_absolute_error: 0.0325\n",
      "Epoch 422/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0358\n",
      "Epoch 422: val_loss improved from 0.00083 to 0.00076, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 337ms/step - loss: 0.0010 - mean_absolute_error: 0.0358 - val_loss: 7.5801e-04 - val_mean_absolute_error: 0.0300\n",
      "Epoch 423/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0368\n",
      "Epoch 423: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 296ms/step - loss: 0.0011 - mean_absolute_error: 0.0368 - val_loss: 0.0015 - val_mean_absolute_error: 0.0397\n",
      "Epoch 424/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0388\n",
      "Epoch 424: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 319ms/step - loss: 0.0013 - mean_absolute_error: 0.0388 - val_loss: 0.0018 - val_mean_absolute_error: 0.0460\n",
      "Epoch 425/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0429\n",
      "Epoch 425: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 304ms/step - loss: 0.0015 - mean_absolute_error: 0.0429 - val_loss: 0.0018 - val_mean_absolute_error: 0.0471\n",
      "Epoch 426/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0465\n",
      "Epoch 426: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 298ms/step - loss: 0.0018 - mean_absolute_error: 0.0465 - val_loss: 0.0020 - val_mean_absolute_error: 0.0471\n",
      "Epoch 427/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0433\n",
      "Epoch 427: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 307ms/step - loss: 0.0016 - mean_absolute_error: 0.0433 - val_loss: 0.0021 - val_mean_absolute_error: 0.0514\n",
      "Epoch 428/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0454\n",
      "Epoch 428: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 338ms/step - loss: 0.0017 - mean_absolute_error: 0.0454 - val_loss: 0.0013 - val_mean_absolute_error: 0.0396\n",
      "Epoch 429/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0412\n",
      "Epoch 429: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 338ms/step - loss: 0.0013 - mean_absolute_error: 0.0412 - val_loss: 0.0014 - val_mean_absolute_error: 0.0399\n",
      "Epoch 430/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0390\n",
      "Epoch 430: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 316ms/step - loss: 0.0013 - mean_absolute_error: 0.0390 - val_loss: 0.0015 - val_mean_absolute_error: 0.0405\n",
      "Epoch 431/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0372\n",
      "Epoch 431: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 298ms/step - loss: 0.0010 - mean_absolute_error: 0.0372 - val_loss: 9.3819e-04 - val_mean_absolute_error: 0.0338\n",
      "Epoch 432/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0373\n",
      "Epoch 432: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 302ms/step - loss: 0.0011 - mean_absolute_error: 0.0373 - val_loss: 0.0016 - val_mean_absolute_error: 0.0425\n",
      "Epoch 433/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0460\n",
      "Epoch 433: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 307ms/step - loss: 0.0020 - mean_absolute_error: 0.0460 - val_loss: 0.0017 - val_mean_absolute_error: 0.0436\n",
      "Epoch 434/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0451\n",
      "Epoch 434: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 302ms/step - loss: 0.0017 - mean_absolute_error: 0.0451 - val_loss: 0.0019 - val_mean_absolute_error: 0.0469\n",
      "Epoch 435/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0433\n",
      "Epoch 435: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 298ms/step - loss: 0.0015 - mean_absolute_error: 0.0433 - val_loss: 0.0012 - val_mean_absolute_error: 0.0380\n",
      "Epoch 436/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0413\n",
      "Epoch 436: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 299ms/step - loss: 0.0013 - mean_absolute_error: 0.0413 - val_loss: 0.0016 - val_mean_absolute_error: 0.0441\n",
      "Epoch 437/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0433\n",
      "Epoch 437: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 296ms/step - loss: 0.0015 - mean_absolute_error: 0.0433 - val_loss: 0.0017 - val_mean_absolute_error: 0.0455\n",
      "Epoch 438/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0398\n",
      "Epoch 438: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 300ms/step - loss: 0.0013 - mean_absolute_error: 0.0398 - val_loss: 9.8727e-04 - val_mean_absolute_error: 0.0340\n",
      "Epoch 439/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0379\n",
      "Epoch 439: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 300ms/step - loss: 0.0012 - mean_absolute_error: 0.0379 - val_loss: 7.6958e-04 - val_mean_absolute_error: 0.0304\n",
      "Epoch 440/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 9.5059e-04 - mean_absolute_error: 0.0350\n",
      "Epoch 440: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 303ms/step - loss: 9.5059e-04 - mean_absolute_error: 0.0350 - val_loss: 0.0011 - val_mean_absolute_error: 0.0353\n",
      "Epoch 441/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0374\n",
      "Epoch 441: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 296ms/step - loss: 0.0011 - mean_absolute_error: 0.0374 - val_loss: 8.7643e-04 - val_mean_absolute_error: 0.0298\n",
      "Epoch 442/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0349   \n",
      "Epoch 442: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 297ms/step - loss: 0.0010 - mean_absolute_error: 0.0349 - val_loss: 7.9663e-04 - val_mean_absolute_error: 0.0299\n",
      "Epoch 443/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 9.7578e-04 - mean_absolute_error: 0.0348\n",
      "Epoch 443: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 300ms/step - loss: 9.7578e-04 - mean_absolute_error: 0.0348 - val_loss: 8.6400e-04 - val_mean_absolute_error: 0.0330\n",
      "Epoch 444/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 9.6404e-04 - mean_absolute_error: 0.0344\n",
      "Epoch 444: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 300ms/step - loss: 9.6404e-04 - mean_absolute_error: 0.0344 - val_loss: 8.3806e-04 - val_mean_absolute_error: 0.0309\n",
      "Epoch 445/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 8.4121e-04 - mean_absolute_error: 0.0322\n",
      "Epoch 445: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 298ms/step - loss: 8.4121e-04 - mean_absolute_error: 0.0322 - val_loss: 9.6966e-04 - val_mean_absolute_error: 0.0341\n",
      "Epoch 446/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0363   \n",
      "Epoch 446: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 295ms/step - loss: 0.0010 - mean_absolute_error: 0.0363 - val_loss: 0.0012 - val_mean_absolute_error: 0.0357\n",
      "Epoch 447/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0377\n",
      "Epoch 447: val_loss did not improve from 0.00076\n",
      "9/9 [==============================] - 3s 297ms/step - loss: 0.0011 - mean_absolute_error: 0.0377 - val_loss: 0.0022 - val_mean_absolute_error: 0.0463\n",
      "Epoch 448/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0363\n",
      "Epoch 448: val_loss improved from 0.00076 to 0.00072, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 335ms/step - loss: 0.0011 - mean_absolute_error: 0.0363 - val_loss: 7.2377e-04 - val_mean_absolute_error: 0.0297\n",
      "Epoch 449/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0354   \n",
      "Epoch 449: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 298ms/step - loss: 0.0010 - mean_absolute_error: 0.0354 - val_loss: 0.0010 - val_mean_absolute_error: 0.0349\n",
      "Epoch 450/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 9.0938e-04 - mean_absolute_error: 0.0335\n",
      "Epoch 450: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 321ms/step - loss: 9.0938e-04 - mean_absolute_error: 0.0335 - val_loss: 7.8799e-04 - val_mean_absolute_error: 0.0299\n",
      "Epoch 451/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0359   \n",
      "Epoch 451: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 353ms/step - loss: 0.0010 - mean_absolute_error: 0.0359 - val_loss: 8.7310e-04 - val_mean_absolute_error: 0.0306\n",
      "Epoch 452/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0346\n",
      "Epoch 452: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 326ms/step - loss: 0.0010 - mean_absolute_error: 0.0346 - val_loss: 7.5079e-04 - val_mean_absolute_error: 0.0279\n",
      "Epoch 453/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 9.1790e-04 - mean_absolute_error: 0.0334\n",
      "Epoch 453: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 338ms/step - loss: 9.1790e-04 - mean_absolute_error: 0.0334 - val_loss: 7.8401e-04 - val_mean_absolute_error: 0.0297\n",
      "Epoch 454/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0396\n",
      "Epoch 454: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 326ms/step - loss: 0.0013 - mean_absolute_error: 0.0396 - val_loss: 8.2025e-04 - val_mean_absolute_error: 0.0321\n",
      "Epoch 455/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0418\n",
      "Epoch 455: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 313ms/step - loss: 0.0014 - mean_absolute_error: 0.0418 - val_loss: 0.0013 - val_mean_absolute_error: 0.0395\n",
      "Epoch 456/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0428\n",
      "Epoch 456: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 332ms/step - loss: 0.0015 - mean_absolute_error: 0.0428 - val_loss: 0.0012 - val_mean_absolute_error: 0.0367\n",
      "Epoch 457/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0406\n",
      "Epoch 457: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 304ms/step - loss: 0.0013 - mean_absolute_error: 0.0406 - val_loss: 0.0012 - val_mean_absolute_error: 0.0385\n",
      "Epoch 458/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0391\n",
      "Epoch 458: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 303ms/step - loss: 0.0012 - mean_absolute_error: 0.0391 - val_loss: 0.0010 - val_mean_absolute_error: 0.0336\n",
      "Epoch 459/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0365\n",
      "Epoch 459: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 320ms/step - loss: 0.0011 - mean_absolute_error: 0.0365 - val_loss: 0.0010 - val_mean_absolute_error: 0.0348\n",
      "Epoch 460/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 9.8008e-04 - mean_absolute_error: 0.0345\n",
      "Epoch 460: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 334ms/step - loss: 9.8008e-04 - mean_absolute_error: 0.0345 - val_loss: 0.0011 - val_mean_absolute_error: 0.0339\n",
      "Epoch 461/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0368\n",
      "Epoch 461: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 317ms/step - loss: 0.0011 - mean_absolute_error: 0.0368 - val_loss: 0.0015 - val_mean_absolute_error: 0.0419\n",
      "Epoch 462/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0413\n",
      "Epoch 462: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 305ms/step - loss: 0.0014 - mean_absolute_error: 0.0413 - val_loss: 0.0014 - val_mean_absolute_error: 0.0422\n",
      "Epoch 463/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0369\n",
      "Epoch 463: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 298ms/step - loss: 0.0011 - mean_absolute_error: 0.0369 - val_loss: 0.0012 - val_mean_absolute_error: 0.0380\n",
      "Epoch 464/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0368\n",
      "Epoch 464: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 341ms/step - loss: 0.0011 - mean_absolute_error: 0.0368 - val_loss: 0.0014 - val_mean_absolute_error: 0.0402\n",
      "Epoch 465/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0361  \n",
      "Epoch 465: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 297ms/step - loss: 0.0010 - mean_absolute_error: 0.0361 - val_loss: 8.7037e-04 - val_mean_absolute_error: 0.0310\n",
      "Epoch 466/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0358\n",
      "Epoch 466: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 309ms/step - loss: 0.0010 - mean_absolute_error: 0.0358 - val_loss: 0.0010 - val_mean_absolute_error: 0.0352\n",
      "Epoch 467/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 9.9932e-04 - mean_absolute_error: 0.0353\n",
      "Epoch 467: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 308ms/step - loss: 9.9932e-04 - mean_absolute_error: 0.0353 - val_loss: 7.6866e-04 - val_mean_absolute_error: 0.0291\n",
      "Epoch 468/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 9.6812e-04 - mean_absolute_error: 0.0351\n",
      "Epoch 468: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 298ms/step - loss: 9.6812e-04 - mean_absolute_error: 0.0351 - val_loss: 7.2767e-04 - val_mean_absolute_error: 0.0291\n",
      "Epoch 469/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 9.7475e-04 - mean_absolute_error: 0.0346\n",
      "Epoch 469: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 304ms/step - loss: 9.7475e-04 - mean_absolute_error: 0.0346 - val_loss: 7.9880e-04 - val_mean_absolute_error: 0.0300\n",
      "Epoch 470/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0354  \n",
      "Epoch 470: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 305ms/step - loss: 0.0010 - mean_absolute_error: 0.0354 - val_loss: 8.4221e-04 - val_mean_absolute_error: 0.0313\n",
      "Epoch 471/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 9.8882e-04 - mean_absolute_error: 0.0355\n",
      "Epoch 471: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 300ms/step - loss: 9.8882e-04 - mean_absolute_error: 0.0355 - val_loss: 9.5409e-04 - val_mean_absolute_error: 0.0320\n",
      "Epoch 472/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0369\n",
      "Epoch 472: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 297ms/step - loss: 0.0011 - mean_absolute_error: 0.0369 - val_loss: 8.6329e-04 - val_mean_absolute_error: 0.0312\n",
      "Epoch 473/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0376\n",
      "Epoch 473: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 306ms/step - loss: 0.0011 - mean_absolute_error: 0.0376 - val_loss: 0.0013 - val_mean_absolute_error: 0.0375\n",
      "Epoch 474/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0355   \n",
      "Epoch 474: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 295ms/step - loss: 0.0010 - mean_absolute_error: 0.0355 - val_loss: 8.7610e-04 - val_mean_absolute_error: 0.0320\n",
      "Epoch 475/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0414\n",
      "Epoch 475: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 299ms/step - loss: 0.0015 - mean_absolute_error: 0.0414 - val_loss: 0.0014 - val_mean_absolute_error: 0.0384\n",
      "Epoch 476/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0430\n",
      "Epoch 476: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 298ms/step - loss: 0.0016 - mean_absolute_error: 0.0430 - val_loss: 0.0016 - val_mean_absolute_error: 0.0434\n",
      "Epoch 477/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0404\n",
      "Epoch 477: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 310ms/step - loss: 0.0014 - mean_absolute_error: 0.0404 - val_loss: 0.0014 - val_mean_absolute_error: 0.0401\n",
      "Epoch 478/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0382\n",
      "Epoch 478: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 316ms/step - loss: 0.0011 - mean_absolute_error: 0.0382 - val_loss: 0.0012 - val_mean_absolute_error: 0.0362\n",
      "Epoch 479/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0393\n",
      "Epoch 479: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 303ms/step - loss: 0.0013 - mean_absolute_error: 0.0393 - val_loss: 9.6856e-04 - val_mean_absolute_error: 0.0341\n",
      "Epoch 480/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0372\n",
      "Epoch 480: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 303ms/step - loss: 0.0011 - mean_absolute_error: 0.0372 - val_loss: 0.0013 - val_mean_absolute_error: 0.0380\n",
      "Epoch 481/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0346    \n",
      "Epoch 481: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 303ms/step - loss: 0.0010 - mean_absolute_error: 0.0346 - val_loss: 8.4570e-04 - val_mean_absolute_error: 0.0316\n",
      "Epoch 482/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 9.7161e-04 - mean_absolute_error: 0.0342\n",
      "Epoch 482: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 300ms/step - loss: 9.7161e-04 - mean_absolute_error: 0.0342 - val_loss: 8.3576e-04 - val_mean_absolute_error: 0.0313\n",
      "Epoch 483/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 9.5436e-04 - mean_absolute_error: 0.0343\n",
      "Epoch 483: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 305ms/step - loss: 9.5436e-04 - mean_absolute_error: 0.0343 - val_loss: 0.0016 - val_mean_absolute_error: 0.0402\n",
      "Epoch 484/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0381\n",
      "Epoch 484: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 298ms/step - loss: 0.0012 - mean_absolute_error: 0.0381 - val_loss: 9.2134e-04 - val_mean_absolute_error: 0.0323\n",
      "Epoch 485/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0358\n",
      "Epoch 485: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 302ms/step - loss: 0.0010 - mean_absolute_error: 0.0358 - val_loss: 9.2784e-04 - val_mean_absolute_error: 0.0311\n",
      "Epoch 486/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 8.9138e-04 - mean_absolute_error: 0.0333\n",
      "Epoch 486: val_loss did not improve from 0.00072\n",
      "9/9 [==============================] - 3s 298ms/step - loss: 8.9138e-04 - mean_absolute_error: 0.0333 - val_loss: 9.7470e-04 - val_mean_absolute_error: 0.0354\n",
      "Epoch 487/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 9.1526e-04 - mean_absolute_error: 0.0342\n",
      "Epoch 487: val_loss improved from 0.00072 to 0.00070, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 317ms/step - loss: 9.1526e-04 - mean_absolute_error: 0.0342 - val_loss: 6.9986e-04 - val_mean_absolute_error: 0.0280\n",
      "Epoch 488/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 8.9101e-04 - mean_absolute_error: 0.0332\n",
      "Epoch 488: val_loss did not improve from 0.00070\n",
      "9/9 [==============================] - 3s 300ms/step - loss: 8.9101e-04 - mean_absolute_error: 0.0332 - val_loss: 7.7172e-04 - val_mean_absolute_error: 0.0293\n",
      "Epoch 489/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 8.2603e-04 - mean_absolute_error: 0.0321\n",
      "Epoch 489: val_loss did not improve from 0.00070\n",
      "9/9 [==============================] - 3s 296ms/step - loss: 8.2603e-04 - mean_absolute_error: 0.0321 - val_loss: 7.1935e-04 - val_mean_absolute_error: 0.0277\n",
      "Epoch 490/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 8.8738e-04 - mean_absolute_error: 0.0333\n",
      "Epoch 490: val_loss did not improve from 0.00070\n",
      "9/9 [==============================] - 3s 322ms/step - loss: 8.8738e-04 - mean_absolute_error: 0.0333 - val_loss: 0.0011 - val_mean_absolute_error: 0.0337\n",
      "Epoch 491/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 9.6407e-04 - mean_absolute_error: 0.0356\n",
      "Epoch 491: val_loss did not improve from 0.00070\n",
      "9/9 [==============================] - 3s 312ms/step - loss: 9.6407e-04 - mean_absolute_error: 0.0356 - val_loss: 7.3397e-04 - val_mean_absolute_error: 0.0305\n",
      "Epoch 492/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0394\n",
      "Epoch 492: val_loss did not improve from 0.00070\n",
      "9/9 [==============================] - 3s 299ms/step - loss: 0.0014 - mean_absolute_error: 0.0394 - val_loss: 0.0010 - val_mean_absolute_error: 0.0342\n",
      "Epoch 493/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0383\n",
      "Epoch 493: val_loss did not improve from 0.00070\n",
      "9/9 [==============================] - 3s 314ms/step - loss: 0.0012 - mean_absolute_error: 0.0383 - val_loss: 0.0012 - val_mean_absolute_error: 0.0341\n",
      "Epoch 494/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0370\n",
      "Epoch 494: val_loss did not improve from 0.00070\n",
      "9/9 [==============================] - 3s 308ms/step - loss: 0.0011 - mean_absolute_error: 0.0370 - val_loss: 8.2027e-04 - val_mean_absolute_error: 0.0300\n",
      "Epoch 495/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 8.3126e-04 - mean_absolute_error: 0.0325\n",
      "Epoch 495: val_loss did not improve from 0.00070\n",
      "9/9 [==============================] - 3s 303ms/step - loss: 8.3126e-04 - mean_absolute_error: 0.0325 - val_loss: 7.4683e-04 - val_mean_absolute_error: 0.0302\n",
      "Epoch 496/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 9.0387e-04 - mean_absolute_error: 0.0337\n",
      "Epoch 496: val_loss did not improve from 0.00070\n",
      "9/9 [==============================] - 3s 301ms/step - loss: 9.0387e-04 - mean_absolute_error: 0.0337 - val_loss: 8.2771e-04 - val_mean_absolute_error: 0.0315\n",
      "Epoch 497/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 8.1162e-04 - mean_absolute_error: 0.0318\n",
      "Epoch 497: val_loss did not improve from 0.00070\n",
      "9/9 [==============================] - 3s 298ms/step - loss: 8.1162e-04 - mean_absolute_error: 0.0318 - val_loss: 0.0010 - val_mean_absolute_error: 0.0341\n",
      "Epoch 498/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 7.8992e-04 - mean_absolute_error: 0.0316\n",
      "Epoch 498: val_loss did not improve from 0.00070\n",
      "9/9 [==============================] - 3s 303ms/step - loss: 7.8992e-04 - mean_absolute_error: 0.0316 - val_loss: 7.5177e-04 - val_mean_absolute_error: 0.0295\n",
      "Epoch 499/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 8.3868e-04 - mean_absolute_error: 0.0319\n",
      "Epoch 499: val_loss improved from 0.00070 to 0.00069, saving model to results\\2022-11-27_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 3s 312ms/step - loss: 8.3868e-04 - mean_absolute_error: 0.0319 - val_loss: 6.9048e-04 - val_mean_absolute_error: 0.0280\n",
      "Epoch 500/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 7.6328e-04 - mean_absolute_error: 0.0313\n",
      "Epoch 500: val_loss did not improve from 0.00069\n",
      "9/9 [==============================] - 3s 308ms/step - loss: 7.6328e-04 - mean_absolute_error: 0.0313 - val_loss: 8.4810e-04 - val_mean_absolute_error: 0.0295\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)\n",
    "# save the dataframe\n",
    "data[\"df\"].to_csv(ticker_data_filename)\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "# train the model and save the weights whenever we see \n",
    "# a new optimal model using ModelCheckpoint\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    \"\"\"\n",
    "    This function plots true close price along with predicted close price\n",
    "    with blue and red colors respectively\n",
    "    \"\"\"\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(model, data):\n",
    "    \"\"\"\n",
    "    This function takes the `model` and `data` dict to \n",
    "    construct a final dataframe that includes the features along \n",
    "    with true and predicted prices of the testing dataset\n",
    "    \"\"\"\n",
    "    # if predicted future price is higher than the current, \n",
    "    # then calculate the true future price minus the current price, to get the buy profit\n",
    "    buy_profit  = lambda current, pred_future, true_future: true_future - current if pred_future > current else 0\n",
    "    # if the predicted future price is lower than the current price,\n",
    "    # then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, pred_future, true_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    # add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load optimal model weights from results folder\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "# calculate the mean absolute error (inverse scaling)\n",
    "if SCALE:\n",
    "    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
    "else:\n",
    "    mean_absolute_error = mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 70ms/step\n"
     ]
    }
   ],
   "source": [
    "# get the final dataframe for the testing set\n",
    "final_df = get_final_df(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "# predict the future price\n",
    "future_price = predict(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we calculate the accuracy by counting the number of positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future price after 15 days is 122.60$\n",
      "huber_loss loss: 0.0006904807523824275\n",
      "Mean Absolute Error: 86.70716246528174\n",
      "Accuracy score: 0.9318181818181818\n",
      "Total buy profit: 591.1139450073242\n",
      "Total sell profit: 687.8069534301758\n",
      "Total profit: 1278.9208984375\n",
      "Profit per trade: 9.688794685132576\n"
     ]
    }
   ],
   "source": [
    "# printing metrics\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
    "print(f\"{LOSS} loss:\", loss)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
    "print(\"Accuracy score:\", accuracy_score)\n",
    "print(\"Total buy profit:\", total_buy_profit)\n",
    "print(\"Total sell profit:\", total_sell_profit)\n",
    "print(\"Total profit:\", total_profit)\n",
    "print(\"Profit per trade:\", profit_per_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot true/pred prices graph\n",
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  open        high         low       close    adjclose  \\\n",
      "2022-09-09  130.910004  133.690002  130.759995  133.270004  133.270004   \n",
      "2022-09-26  113.300003  117.339996  113.129997  115.150002  115.150002   \n",
      "2022-10-03  113.580002  116.910004  112.449997  115.879997  115.879997   \n",
      "2022-10-04  119.889999  123.000000  119.790001  121.089996  121.089996   \n",
      "2022-10-05  118.580002  121.750000  117.690002  120.949997  120.949997   \n",
      "2022-10-07  118.000000  118.169998  113.879997  114.559998  114.559998   \n",
      "2022-10-10  115.099998  116.250000  112.430000  113.669998  113.669998   \n",
      "2022-10-12  112.489998  113.830002  111.400002  112.900002  112.900002   \n",
      "2022-10-14  114.099998  114.959999  106.599998  106.900002  106.900002   \n",
      "2022-10-17  110.110001  114.190002  110.089996  113.790001  113.790001   \n",
      "\n",
      "              volume ticker  adjclose_15  true_adjclose_15  buy_profit  \\\n",
      "2022-09-09  49387600   AMZN   117.379837        113.000000    0.000000   \n",
      "2022-09-26  62723300   AMZN   111.506058        113.790001    0.000000   \n",
      "2022-10-03  50941900   AMZN   116.445770        119.820000    3.940002   \n",
      "2022-10-04  62812600   AMZN   115.972939        120.599998    0.000000   \n",
      "2022-10-05  48217500   AMZN   114.467415        115.660004    0.000000   \n",
      "2022-10-07  54678000   AMZN   108.219299        103.410004    0.000000   \n",
      "2022-10-10  42339700   AMZN   102.215340        102.440002    0.000000   \n",
      "2022-10-12  45728700   AMZN    93.535194         92.120003    0.000000   \n",
      "2022-10-14  67737300   AMZN    87.897552         90.980003    0.000000   \n",
      "2022-10-17  62782000   AMZN    87.179619         90.529999    0.000000   \n",
      "\n",
      "            sell_profit  \n",
      "2022-09-09    20.270004  \n",
      "2022-09-26     1.360001  \n",
      "2022-10-03     0.000000  \n",
      "2022-10-04     0.489998  \n",
      "2022-10-05     5.289993  \n",
      "2022-10-07    11.149994  \n",
      "2022-10-10    11.229996  \n",
      "2022-10-12    20.779999  \n",
      "2022-10-14    15.919998  \n",
      "2022-10-17    23.260002  \n"
     ]
    }
   ],
   "source": [
    "print(final_df.tail(10))\n",
    "# save the final dataframe to csv-results folder\n",
    "csv_results_folder = \"csv-results\"\n",
    "if not os.path.isdir(csv_results_folder):\n",
    "    os.mkdir(csv_results_folder)\n",
    "csv_filename = os.path.join(csv_results_folder, model_name + \".csv\")\n",
    "final_df.to_csv(csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 50, 256)           268288    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 50, 256)           0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 793,857\n",
      "Trainable params: 793,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "training = history\n",
    "# plot\n",
    "metrics = [k for k in training.history.keys() if (\"loss\" not in k) and (\"val\" not in k)]    \n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(15,3))\n",
    "       \n",
    "## training    \n",
    "ax[0].set(title=\"Training\")    \n",
    "ax11 = ax[0].twinx()    \n",
    "ax[0].plot(training.history['loss'], color='black')\n",
    "\n",
    "ax[0].set_xlabel('Epochs')\n",
    "\n",
    "ax[0].set_ylabel('Loss', color='black')    \n",
    "for metric in metrics:        \n",
    "    ax11.plot(training.history[metric], label=metric)\n",
    "    ax11.set_ylabel(\"Score\", color='steelblue')    \n",
    "ax11.legend()\n",
    "        \n",
    "## validation    \n",
    "ax[1].set(title=\"Validation\")    \n",
    "ax22 = ax[1].twinx()    \n",
    "ax[1].plot(training.history['val_loss'], color='black')\n",
    "\n",
    "ax[1].set_xlabel('Epochs')\n",
    "\n",
    "ax[1].set_ylabel('Loss', color='black')    \n",
    "for metric in metrics:          \n",
    "    ax22.plot(training.history['val_'+metric], label=metric)\n",
    "    ax22.set_ylabel(\"Score\", color=\"steelblue\")    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "395aabf3641156dfc28b3451977f22b72ac157dbab4b72e0460d42cfc7a164ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
