{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "To make sure that all the libraries have been installed, use the following command when in the virual enviroment\n",
    "\n",
    "pip install tensorflow pandas numpy matplotlib yahoo_fin sklearn scikit-learn\n",
    "NEED TO FIGURE OUT WHICH ONE OF THE TWO ACUTALLY WORKS, SECOND ONE SEEMS TO ACTUALLY WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed, so we can get the same results after rerunning several times\n",
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This whole part of data processing needs to be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "    \"\"\"\n",
    "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
    "    Params:\n",
    "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
    "            to False will split datasets in a random way\n",
    "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "    \"\"\"\n",
    "    # Set the start and end date\n",
    "    start_date = '2020-01-01'\n",
    "    end_date = '2022-11-12'\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yahoo_fin library\n",
    "        df = si.get_data(ticker, start_date, end_date)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        # split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "                                                                                \n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove duplicated dates in the testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "    # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next state the model is generated\n",
    "### Generate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model, and create it usign the above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 15\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True # true\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 500\n",
    "# Amazon stock market\n",
    "ticker = \"AMZN\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to create folders if they don't exist in the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create these folders if they does not exist\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to train the model (500 epoch took 210 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMZN 50 False False True 15 0.2 ['adjclose', 'volume', 'open', 'high', 'low']\n",
      "dict_keys(['df', 'last_sequence', 'X_train', 'X_test', 'y_train', 'y_test', 'test_df'])\n"
     ]
    }
   ],
   "source": [
    "print(ticker, N_STEPS, SCALE, SPLIT_BY_DATE, SHUFFLE, LOOKUP_STEP, TEST_SIZE, FEATURE_COLUMNS)\n",
    "# load the data\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)\n",
    "# save the dataframe\n",
    "data[\"df\"].to_csv(ticker_data_filename)\n",
    "\n",
    "print(data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 50, 256)           268288    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 50, 256)           0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 793,857\n",
      "Trainable params: 793,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# construct the model\n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 16:27:27.100840: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-27 16:27:27.311873: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-27 16:27:27.449162: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-27 16:27:27.816909: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-27 16:27:28.005301: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - ETA: 0s - loss: 142.0975 - mean_absolute_error: 142.5975"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 16:27:29.780520: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-27 16:27:29.862777: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-27 16:27:29.957515: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 135.15317, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 5s 219ms/step - loss: 142.0975 - mean_absolute_error: 142.5975 - val_loss: 135.1532 - val_mean_absolute_error: 135.6532\n",
      "Epoch 2/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 130.4580 - mean_absolute_error: 130.9580\n",
      "Epoch 2: val_loss improved from 135.15317 to 127.49981, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 130.4580 - mean_absolute_error: 130.9580 - val_loss: 127.4998 - val_mean_absolute_error: 127.9998\n",
      "Epoch 3/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 124.8882 - mean_absolute_error: 125.3882\n",
      "Epoch 3: val_loss improved from 127.49981 to 124.07625, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 124.8882 - mean_absolute_error: 125.3882 - val_loss: 124.0762 - val_mean_absolute_error: 124.5762\n",
      "Epoch 4/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 121.8246 - mean_absolute_error: 122.3246\n",
      "Epoch 4: val_loss improved from 124.07625 to 121.30148, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 121.8246 - mean_absolute_error: 122.3246 - val_loss: 121.3015 - val_mean_absolute_error: 121.8015\n",
      "Epoch 5/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 119.1293 - mean_absolute_error: 119.6293\n",
      "Epoch 5: val_loss improved from 121.30148 to 118.70238, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 119.1293 - mean_absolute_error: 119.6293 - val_loss: 118.7024 - val_mean_absolute_error: 119.2024\n",
      "Epoch 6/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 116.5478 - mean_absolute_error: 117.0478\n",
      "Epoch 6: val_loss improved from 118.70238 to 116.16560, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 116.5478 - mean_absolute_error: 117.0478 - val_loss: 116.1656 - val_mean_absolute_error: 116.6656\n",
      "Epoch 7/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 114.0177 - mean_absolute_error: 114.5177\n",
      "Epoch 7: val_loss improved from 116.16560 to 113.66783, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 114.0177 - mean_absolute_error: 114.5177 - val_loss: 113.6678 - val_mean_absolute_error: 114.1678\n",
      "Epoch 8/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 111.5160 - mean_absolute_error: 112.0160\n",
      "Epoch 8: val_loss improved from 113.66783 to 111.14540, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 111.5160 - mean_absolute_error: 112.0160 - val_loss: 111.1454 - val_mean_absolute_error: 111.6454\n",
      "Epoch 9/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 108.9688 - mean_absolute_error: 109.4688\n",
      "Epoch 9: val_loss improved from 111.14540 to 108.64942, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 108.9688 - mean_absolute_error: 109.4688 - val_loss: 108.6494 - val_mean_absolute_error: 109.1494\n",
      "Epoch 10/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 106.4968 - mean_absolute_error: 106.9968\n",
      "Epoch 10: val_loss improved from 108.64942 to 106.20966, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 106.4968 - mean_absolute_error: 106.9968 - val_loss: 106.2097 - val_mean_absolute_error: 106.7097\n",
      "Epoch 11/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 104.0543 - mean_absolute_error: 104.5543\n",
      "Epoch 11: val_loss improved from 106.20966 to 103.78697, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 104.0543 - mean_absolute_error: 104.5543 - val_loss: 103.7870 - val_mean_absolute_error: 104.2870\n",
      "Epoch 12/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 101.6277 - mean_absolute_error: 102.1277\n",
      "Epoch 12: val_loss improved from 103.78697 to 101.37844, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 101.6277 - mean_absolute_error: 102.1277 - val_loss: 101.3784 - val_mean_absolute_error: 101.8784\n",
      "Epoch 13/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 99.2143 - mean_absolute_error: 99.7143 \n",
      "Epoch 13: val_loss improved from 101.37844 to 98.98174, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 99.2143 - mean_absolute_error: 99.7143 - val_loss: 98.9817 - val_mean_absolute_error: 99.4817\n",
      "Epoch 14/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 96.8119 - mean_absolute_error: 97.3119\n",
      "Epoch 14: val_loss improved from 98.98174 to 96.59495, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 96.8119 - mean_absolute_error: 97.3119 - val_loss: 96.5949 - val_mean_absolute_error: 97.0949\n",
      "Epoch 15/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 94.4188 - mean_absolute_error: 94.9188\n",
      "Epoch 15: val_loss improved from 96.59495 to 94.21656, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 94.4188 - mean_absolute_error: 94.9188 - val_loss: 94.2166 - val_mean_absolute_error: 94.7166\n",
      "Epoch 16/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 92.0336 - mean_absolute_error: 92.5336\n",
      "Epoch 16: val_loss improved from 94.21656 to 91.84540, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 92.0336 - mean_absolute_error: 92.5336 - val_loss: 91.8454 - val_mean_absolute_error: 92.3454\n",
      "Epoch 17/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 89.6552 - mean_absolute_error: 90.1552\n",
      "Epoch 17: val_loss improved from 91.84540 to 89.48048, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 89.6552 - mean_absolute_error: 90.1552 - val_loss: 89.4805 - val_mean_absolute_error: 89.9805\n",
      "Epoch 18/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 87.2828 - mean_absolute_error: 87.7828\n",
      "Epoch 18: val_loss improved from 89.48048 to 87.12103, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 87.2828 - mean_absolute_error: 87.7828 - val_loss: 87.1210 - val_mean_absolute_error: 87.6210\n",
      "Epoch 19/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 84.9155 - mean_absolute_error: 85.4155\n",
      "Epoch 19: val_loss improved from 87.12103 to 84.76638, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 84.9155 - mean_absolute_error: 85.4155 - val_loss: 84.7664 - val_mean_absolute_error: 85.2664\n",
      "Epoch 20/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 82.5529 - mean_absolute_error: 83.0529\n",
      "Epoch 20: val_loss improved from 84.76638 to 82.41599, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 82.5529 - mean_absolute_error: 83.0529 - val_loss: 82.4160 - val_mean_absolute_error: 82.9160\n",
      "Epoch 21/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 80.1942 - mean_absolute_error: 80.6942\n",
      "Epoch 21: val_loss improved from 82.41599 to 80.06897, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 80.1942 - mean_absolute_error: 80.6942 - val_loss: 80.0690 - val_mean_absolute_error: 80.5690\n",
      "Epoch 22/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 77.8368 - mean_absolute_error: 78.3368\n",
      "Epoch 22: val_loss improved from 80.06897 to 77.71616, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 77.8368 - mean_absolute_error: 78.3368 - val_loss: 77.7162 - val_mean_absolute_error: 78.2162\n",
      "Epoch 23/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 75.4679 - mean_absolute_error: 75.9679\n",
      "Epoch 23: val_loss improved from 77.71616 to 75.35619, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 75.4679 - mean_absolute_error: 75.9679 - val_loss: 75.3562 - val_mean_absolute_error: 75.8562\n",
      "Epoch 24/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 73.0963 - mean_absolute_error: 73.5963\n",
      "Epoch 24: val_loss improved from 75.35619 to 72.99713, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 73.0963 - mean_absolute_error: 73.5963 - val_loss: 72.9971 - val_mean_absolute_error: 73.4971\n",
      "Epoch 25/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 70.7264 - mean_absolute_error: 71.2264\n",
      "Epoch 25: val_loss improved from 72.99713 to 70.64119, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 70.7264 - mean_absolute_error: 71.2264 - val_loss: 70.6412 - val_mean_absolute_error: 71.1412\n",
      "Epoch 26/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 68.3601 - mean_absolute_error: 68.8601\n",
      "Epoch 26: val_loss improved from 70.64119 to 68.28899, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 68.3601 - mean_absolute_error: 68.8601 - val_loss: 68.2890 - val_mean_absolute_error: 68.7890\n",
      "Epoch 27/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 65.9977 - mean_absolute_error: 66.4977\n",
      "Epoch 27: val_loss improved from 68.28899 to 65.94032, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 65.9977 - mean_absolute_error: 66.4977 - val_loss: 65.9403 - val_mean_absolute_error: 66.4403\n",
      "Epoch 28/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 63.6388 - mean_absolute_error: 64.1388\n",
      "Epoch 28: val_loss improved from 65.94032 to 63.59482, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 63.6388 - mean_absolute_error: 64.1388 - val_loss: 63.5948 - val_mean_absolute_error: 64.0948\n",
      "Epoch 29/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 61.2864 - mean_absolute_error: 61.7860\n",
      "Epoch 29: val_loss improved from 63.59482 to 61.25584, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 61.2864 - mean_absolute_error: 61.7860 - val_loss: 61.2558 - val_mean_absolute_error: 61.7558\n",
      "Epoch 30/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 58.9771 - mean_absolute_error: 59.4769\n",
      "Epoch 30: val_loss improved from 61.25584 to 58.93727, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 58.9771 - mean_absolute_error: 59.4769 - val_loss: 58.9373 - val_mean_absolute_error: 59.4327\n",
      "Epoch 31/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 56.6652 - mean_absolute_error: 57.1652\n",
      "Epoch 31: val_loss improved from 58.93727 to 56.69411, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 56.6652 - mean_absolute_error: 57.1652 - val_loss: 56.6941 - val_mean_absolute_error: 57.1941\n",
      "Epoch 32/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 54.4249 - mean_absolute_error: 54.9249\n",
      "Epoch 32: val_loss improved from 56.69411 to 54.47997, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 54.4249 - mean_absolute_error: 54.9249 - val_loss: 54.4800 - val_mean_absolute_error: 54.9800\n",
      "Epoch 33/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 52.0367 - mean_absolute_error: 52.5367\n",
      "Epoch 33: val_loss improved from 54.47997 to 52.27348, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 52.0367 - mean_absolute_error: 52.5367 - val_loss: 52.2735 - val_mean_absolute_error: 52.7735\n",
      "Epoch 34/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 49.7459 - mean_absolute_error: 50.2450\n",
      "Epoch 34: val_loss improved from 52.27348 to 50.07012, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 49.7459 - mean_absolute_error: 50.2450 - val_loss: 50.0701 - val_mean_absolute_error: 50.5693\n",
      "Epoch 35/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 47.5391 - mean_absolute_error: 48.0385\n",
      "Epoch 35: val_loss improved from 50.07012 to 47.90914, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 47.5391 - mean_absolute_error: 48.0385 - val_loss: 47.9091 - val_mean_absolute_error: 48.4061\n",
      "Epoch 36/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 45.4753 - mean_absolute_error: 45.9725\n",
      "Epoch 36: val_loss improved from 47.90914 to 45.87864, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 45.4753 - mean_absolute_error: 45.9725 - val_loss: 45.8786 - val_mean_absolute_error: 46.3775\n",
      "Epoch 37/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 43.3079 - mean_absolute_error: 43.8051\n",
      "Epoch 37: val_loss improved from 45.87864 to 43.95933, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 43.3079 - mean_absolute_error: 43.8051 - val_loss: 43.9593 - val_mean_absolute_error: 44.4557\n",
      "Epoch 38/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 41.3726 - mean_absolute_error: 41.8714\n",
      "Epoch 38: val_loss improved from 43.95933 to 42.08183, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 41.3726 - mean_absolute_error: 41.8714 - val_loss: 42.0818 - val_mean_absolute_error: 42.5786\n",
      "Epoch 39/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 39.5740 - mean_absolute_error: 40.0718\n",
      "Epoch 39: val_loss improved from 42.08183 to 40.31606, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 39.5740 - mean_absolute_error: 40.0718 - val_loss: 40.3161 - val_mean_absolute_error: 40.8161\n",
      "Epoch 40/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 37.5821 - mean_absolute_error: 38.0771\n",
      "Epoch 40: val_loss improved from 40.31606 to 38.61779, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 37.5821 - mean_absolute_error: 38.0771 - val_loss: 38.6178 - val_mean_absolute_error: 39.1139\n",
      "Epoch 41/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 36.1281 - mean_absolute_error: 36.6231\n",
      "Epoch 41: val_loss improved from 38.61779 to 36.99607, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 36.1281 - mean_absolute_error: 36.6231 - val_loss: 36.9961 - val_mean_absolute_error: 37.4905\n",
      "Epoch 42/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 34.4705 - mean_absolute_error: 34.9666\n",
      "Epoch 42: val_loss improved from 36.99607 to 35.52199, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 34.4705 - mean_absolute_error: 34.9666 - val_loss: 35.5220 - val_mean_absolute_error: 36.0201\n",
      "Epoch 43/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 33.3447 - mean_absolute_error: 33.8400\n",
      "Epoch 43: val_loss improved from 35.52199 to 34.16437, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 33.3447 - mean_absolute_error: 33.8400 - val_loss: 34.1644 - val_mean_absolute_error: 34.6636\n",
      "Epoch 44/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 32.1012 - mean_absolute_error: 32.5959\n",
      "Epoch 44: val_loss improved from 34.16437 to 32.96949, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 32.1012 - mean_absolute_error: 32.5959 - val_loss: 32.9695 - val_mean_absolute_error: 33.4598\n",
      "Epoch 45/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 31.2386 - mean_absolute_error: 31.7369\n",
      "Epoch 45: val_loss improved from 32.96949 to 31.92233, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 31.2386 - mean_absolute_error: 31.7369 - val_loss: 31.9223 - val_mean_absolute_error: 32.4202\n",
      "Epoch 46/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 29.9749 - mean_absolute_error: 30.4738\n",
      "Epoch 46: val_loss improved from 31.92233 to 30.97709, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 29.9749 - mean_absolute_error: 30.4738 - val_loss: 30.9771 - val_mean_absolute_error: 31.4736\n",
      "Epoch 47/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 29.1814 - mean_absolute_error: 29.6792\n",
      "Epoch 47: val_loss improved from 30.97709 to 30.12222, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 29.1814 - mean_absolute_error: 29.6792 - val_loss: 30.1222 - val_mean_absolute_error: 30.6214\n",
      "Epoch 48/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 28.2694 - mean_absolute_error: 28.7692\n",
      "Epoch 48: val_loss improved from 30.12222 to 29.31224, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 28.2694 - mean_absolute_error: 28.7692 - val_loss: 29.3122 - val_mean_absolute_error: 29.8106\n",
      "Epoch 49/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 27.3681 - mean_absolute_error: 27.8657\n",
      "Epoch 49: val_loss improved from 29.31224 to 28.54023, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 27.3681 - mean_absolute_error: 27.8657 - val_loss: 28.5402 - val_mean_absolute_error: 29.0402\n",
      "Epoch 50/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 26.7908 - mean_absolute_error: 27.2882\n",
      "Epoch 50: val_loss improved from 28.54023 to 27.78988, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 26.7908 - mean_absolute_error: 27.2882 - val_loss: 27.7899 - val_mean_absolute_error: 28.2877\n",
      "Epoch 51/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 25.7195 - mean_absolute_error: 26.2191\n",
      "Epoch 51: val_loss improved from 27.78988 to 27.06130, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 25.7195 - mean_absolute_error: 26.2191 - val_loss: 27.0613 - val_mean_absolute_error: 27.5608\n",
      "Epoch 52/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 25.3677 - mean_absolute_error: 25.8649\n",
      "Epoch 52: val_loss improved from 27.06130 to 26.37554, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 25.3677 - mean_absolute_error: 25.8649 - val_loss: 26.3755 - val_mean_absolute_error: 26.8755\n",
      "Epoch 53/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 24.6179 - mean_absolute_error: 25.1144\n",
      "Epoch 53: val_loss improved from 26.37554 to 25.74130, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 24.6179 - mean_absolute_error: 25.1144 - val_loss: 25.7413 - val_mean_absolute_error: 26.2381\n",
      "Epoch 54/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 24.3812 - mean_absolute_error: 24.8793\n",
      "Epoch 54: val_loss improved from 25.74130 to 25.17009, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 24.3812 - mean_absolute_error: 24.8793 - val_loss: 25.1701 - val_mean_absolute_error: 25.6655\n",
      "Epoch 55/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 23.5918 - mean_absolute_error: 24.0898\n",
      "Epoch 55: val_loss improved from 25.17009 to 24.64157, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 23.5918 - mean_absolute_error: 24.0898 - val_loss: 24.6416 - val_mean_absolute_error: 25.1379\n",
      "Epoch 56/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 23.1422 - mean_absolute_error: 23.6400\n",
      "Epoch 56: val_loss improved from 24.64157 to 24.12362, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 23.1422 - mean_absolute_error: 23.6400 - val_loss: 24.1236 - val_mean_absolute_error: 24.6210\n",
      "Epoch 57/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 22.7349 - mean_absolute_error: 23.2330\n",
      "Epoch 57: val_loss improved from 24.12362 to 23.62164, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 22.7349 - mean_absolute_error: 23.2330 - val_loss: 23.6216 - val_mean_absolute_error: 24.1204\n",
      "Epoch 58/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 21.8827 - mean_absolute_error: 22.3798\n",
      "Epoch 58: val_loss improved from 23.62164 to 23.13361, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 21.8827 - mean_absolute_error: 22.3798 - val_loss: 23.1336 - val_mean_absolute_error: 23.6297\n",
      "Epoch 59/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 21.7102 - mean_absolute_error: 22.2078\n",
      "Epoch 59: val_loss improved from 23.13361 to 22.70890, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 21.7102 - mean_absolute_error: 22.2078 - val_loss: 22.7089 - val_mean_absolute_error: 23.2081\n",
      "Epoch 60/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 20.9516 - mean_absolute_error: 21.4494\n",
      "Epoch 60: val_loss improved from 22.70890 to 22.29284, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 20.9516 - mean_absolute_error: 21.4494 - val_loss: 22.2928 - val_mean_absolute_error: 22.7928\n",
      "Epoch 61/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 20.7332 - mean_absolute_error: 21.2296\n",
      "Epoch 61: val_loss improved from 22.29284 to 21.89217, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 20.7332 - mean_absolute_error: 21.2296 - val_loss: 21.8922 - val_mean_absolute_error: 22.3922\n",
      "Epoch 62/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 20.3752 - mean_absolute_error: 20.8698\n",
      "Epoch 62: val_loss improved from 21.89217 to 21.49383, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 20.3752 - mean_absolute_error: 20.8698 - val_loss: 21.4938 - val_mean_absolute_error: 21.9905\n",
      "Epoch 63/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 20.1080 - mean_absolute_error: 20.6030\n",
      "Epoch 63: val_loss improved from 21.49383 to 21.16269, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 20.1080 - mean_absolute_error: 20.6030 - val_loss: 21.1627 - val_mean_absolute_error: 21.6605\n",
      "Epoch 64/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 20.0997 - mean_absolute_error: 20.5965\n",
      "Epoch 64: val_loss improved from 21.16269 to 20.85024, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 20.0997 - mean_absolute_error: 20.5965 - val_loss: 20.8502 - val_mean_absolute_error: 21.3502\n",
      "Epoch 65/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 19.6248 - mean_absolute_error: 20.1202\n",
      "Epoch 65: val_loss improved from 20.85024 to 20.54553, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 19.6248 - mean_absolute_error: 20.1202 - val_loss: 20.5455 - val_mean_absolute_error: 21.0455\n",
      "Epoch 66/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 19.0385 - mean_absolute_error: 19.5333\n",
      "Epoch 66: val_loss improved from 20.54553 to 20.25773, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 19.0385 - mean_absolute_error: 19.5333 - val_loss: 20.2577 - val_mean_absolute_error: 20.7577\n",
      "Epoch 67/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 19.1333 - mean_absolute_error: 19.6281\n",
      "Epoch 67: val_loss improved from 20.25773 to 19.98783, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 19.1333 - mean_absolute_error: 19.6281 - val_loss: 19.9878 - val_mean_absolute_error: 20.4848\n",
      "Epoch 68/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.5324 - mean_absolute_error: 19.0263\n",
      "Epoch 68: val_loss improved from 19.98783 to 19.78073, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 18.5324 - mean_absolute_error: 19.0263 - val_loss: 19.7807 - val_mean_absolute_error: 20.2765\n",
      "Epoch 69/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.9451 - mean_absolute_error: 18.4375\n",
      "Epoch 69: val_loss improved from 19.78073 to 19.59739, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.9451 - mean_absolute_error: 18.4375 - val_loss: 19.5974 - val_mean_absolute_error: 20.0963\n",
      "Epoch 70/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.9764 - mean_absolute_error: 19.4669\n",
      "Epoch 70: val_loss improved from 19.59739 to 19.41438, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 18.9764 - mean_absolute_error: 19.4669 - val_loss: 19.4144 - val_mean_absolute_error: 19.9139\n",
      "Epoch 71/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.7272 - mean_absolute_error: 19.2188\n",
      "Epoch 71: val_loss improved from 19.41438 to 19.23756, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 18.7272 - mean_absolute_error: 19.2188 - val_loss: 19.2376 - val_mean_absolute_error: 19.7344\n",
      "Epoch 72/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.9623 - mean_absolute_error: 18.4556\n",
      "Epoch 72: val_loss improved from 19.23756 to 19.07842, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.9623 - mean_absolute_error: 18.4556 - val_loss: 19.0784 - val_mean_absolute_error: 19.5772\n",
      "Epoch 73/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.6847 - mean_absolute_error: 19.1764\n",
      "Epoch 73: val_loss improved from 19.07842 to 18.94902, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 18.6847 - mean_absolute_error: 19.1764 - val_loss: 18.9490 - val_mean_absolute_error: 19.4489\n",
      "Epoch 74/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.3726 - mean_absolute_error: 18.8683\n",
      "Epoch 74: val_loss improved from 18.94902 to 18.84423, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 18.3726 - mean_absolute_error: 18.8683 - val_loss: 18.8442 - val_mean_absolute_error: 19.3442\n",
      "Epoch 75/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.4191 - mean_absolute_error: 18.9123\n",
      "Epoch 75: val_loss improved from 18.84423 to 18.74902, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 18.4191 - mean_absolute_error: 18.9123 - val_loss: 18.7490 - val_mean_absolute_error: 19.2490\n",
      "Epoch 76/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7681 - mean_absolute_error: 18.2589\n",
      "Epoch 76: val_loss improved from 18.74902 to 18.67803, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 17.7681 - mean_absolute_error: 18.2589 - val_loss: 18.6780 - val_mean_absolute_error: 19.1780\n",
      "Epoch 77/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5074 - mean_absolute_error: 18.0002\n",
      "Epoch 77: val_loss improved from 18.67803 to 18.60758, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 17.5074 - mean_absolute_error: 18.0002 - val_loss: 18.6076 - val_mean_absolute_error: 19.1069\n",
      "Epoch 78/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7765 - mean_absolute_error: 18.2704\n",
      "Epoch 78: val_loss improved from 18.60758 to 18.55910, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 17.7765 - mean_absolute_error: 18.2704 - val_loss: 18.5591 - val_mean_absolute_error: 19.0576\n",
      "Epoch 79/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.0807 - mean_absolute_error: 18.5736\n",
      "Epoch 79: val_loss improved from 18.55910 to 18.53308, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 18.0807 - mean_absolute_error: 18.5736 - val_loss: 18.5331 - val_mean_absolute_error: 19.0309\n",
      "Epoch 80/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.7814 - mean_absolute_error: 19.2715\n",
      "Epoch 80: val_loss improved from 18.53308 to 18.49329, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 18.7814 - mean_absolute_error: 19.2715 - val_loss: 18.4933 - val_mean_absolute_error: 18.9899\n",
      "Epoch 81/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.7729 - mean_absolute_error: 19.2669\n",
      "Epoch 81: val_loss improved from 18.49329 to 18.45496, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 18.7729 - mean_absolute_error: 19.2669 - val_loss: 18.4550 - val_mean_absolute_error: 18.9500\n",
      "Epoch 82/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.5665 - mean_absolute_error: 19.0589\n",
      "Epoch 82: val_loss improved from 18.45496 to 18.40985, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 18.5665 - mean_absolute_error: 19.0589 - val_loss: 18.4098 - val_mean_absolute_error: 18.9031\n",
      "Epoch 83/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.9664 - mean_absolute_error: 18.4616\n",
      "Epoch 83: val_loss improved from 18.40985 to 18.39503, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.9664 - mean_absolute_error: 18.4616 - val_loss: 18.3950 - val_mean_absolute_error: 18.8882\n",
      "Epoch 84/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.4475 - mean_absolute_error: 18.9438\n",
      "Epoch 84: val_loss improved from 18.39503 to 18.37274, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 18.4475 - mean_absolute_error: 18.9438 - val_loss: 18.3727 - val_mean_absolute_error: 18.8656\n",
      "Epoch 85/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.2098 - mean_absolute_error: 18.7053\n",
      "Epoch 85: val_loss improved from 18.37274 to 18.34612, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 18.2098 - mean_absolute_error: 18.7053 - val_loss: 18.3461 - val_mean_absolute_error: 18.8396\n",
      "Epoch 86/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.9351 - mean_absolute_error: 18.4254\n",
      "Epoch 86: val_loss improved from 18.34612 to 18.32647, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.9351 - mean_absolute_error: 18.4254 - val_loss: 18.3265 - val_mean_absolute_error: 18.8204\n",
      "Epoch 87/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.1042 - mean_absolute_error: 18.5999\n",
      "Epoch 87: val_loss improved from 18.32647 to 18.26455, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 18.1042 - mean_absolute_error: 18.5999 - val_loss: 18.2646 - val_mean_absolute_error: 18.7587\n",
      "Epoch 88/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.0616 - mean_absolute_error: 18.5563\n",
      "Epoch 88: val_loss did not improve from 18.26455\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 18.0616 - mean_absolute_error: 18.5563 - val_loss: 18.2731 - val_mean_absolute_error: 18.7674\n",
      "Epoch 89/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.9803 - mean_absolute_error: 18.4746\n",
      "Epoch 89: val_loss did not improve from 18.26455\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.9803 - mean_absolute_error: 18.4746 - val_loss: 18.2820 - val_mean_absolute_error: 18.7763\n",
      "Epoch 90/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.1930 - mean_absolute_error: 18.6868\n",
      "Epoch 90: val_loss did not improve from 18.26455\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 18.1930 - mean_absolute_error: 18.6868 - val_loss: 18.2725 - val_mean_absolute_error: 18.7667\n",
      "Epoch 91/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3642 - mean_absolute_error: 17.8562\n",
      "Epoch 91: val_loss improved from 18.26455 to 18.25273, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 17.3642 - mean_absolute_error: 17.8562 - val_loss: 18.2527 - val_mean_absolute_error: 18.7467\n",
      "Epoch 92/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.8779 - mean_absolute_error: 18.3722\n",
      "Epoch 92: val_loss improved from 18.25273 to 18.23783, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 17.8779 - mean_absolute_error: 18.3722 - val_loss: 18.2378 - val_mean_absolute_error: 18.7315\n",
      "Epoch 93/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.0296 - mean_absolute_error: 18.5205\n",
      "Epoch 93: val_loss improved from 18.23783 to 18.21449, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 18.0296 - mean_absolute_error: 18.5205 - val_loss: 18.2145 - val_mean_absolute_error: 18.7083\n",
      "Epoch 94/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.9318 - mean_absolute_error: 18.4278\n",
      "Epoch 94: val_loss improved from 18.21449 to 18.18411, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 17.9318 - mean_absolute_error: 18.4278 - val_loss: 18.1841 - val_mean_absolute_error: 18.6783\n",
      "Epoch 95/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.2259 - mean_absolute_error: 18.7188\n",
      "Epoch 95: val_loss improved from 18.18411 to 18.17940, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 18.2259 - mean_absolute_error: 18.7188 - val_loss: 18.1794 - val_mean_absolute_error: 18.6736\n",
      "Epoch 96/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.5561 - mean_absolute_error: 19.0492\n",
      "Epoch 96: val_loss did not improve from 18.17940\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 18.5561 - mean_absolute_error: 19.0492 - val_loss: 18.1827 - val_mean_absolute_error: 18.6769\n",
      "Epoch 97/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.3956 - mean_absolute_error: 18.8890\n",
      "Epoch 97: val_loss did not improve from 18.17940\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 18.3956 - mean_absolute_error: 18.8890 - val_loss: 18.1919 - val_mean_absolute_error: 18.6861\n",
      "Epoch 98/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.4039 - mean_absolute_error: 18.8959\n",
      "Epoch 98: val_loss did not improve from 18.17940\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 18.4039 - mean_absolute_error: 18.8959 - val_loss: 18.1824 - val_mean_absolute_error: 18.6765\n",
      "Epoch 99/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.0433 - mean_absolute_error: 18.5360\n",
      "Epoch 99: val_loss did not improve from 18.17940\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 18.0433 - mean_absolute_error: 18.5360 - val_loss: 18.2087 - val_mean_absolute_error: 18.7026\n",
      "Epoch 100/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.1765 - mean_absolute_error: 18.6696\n",
      "Epoch 100: val_loss did not improve from 18.17940\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 18.1765 - mean_absolute_error: 18.6696 - val_loss: 18.2131 - val_mean_absolute_error: 18.7070\n",
      "Epoch 101/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.8079 - mean_absolute_error: 18.3029\n",
      "Epoch 101: val_loss did not improve from 18.17940\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.8079 - mean_absolute_error: 18.3029 - val_loss: 18.1841 - val_mean_absolute_error: 18.6782\n",
      "Epoch 102/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3778 - mean_absolute_error: 17.8695\n",
      "Epoch 102: val_loss did not improve from 18.17940\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.3778 - mean_absolute_error: 17.8695 - val_loss: 18.1890 - val_mean_absolute_error: 18.6831\n",
      "Epoch 103/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.0205 - mean_absolute_error: 18.5140\n",
      "Epoch 103: val_loss improved from 18.17940 to 18.16859, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 18.0205 - mean_absolute_error: 18.5140 - val_loss: 18.1686 - val_mean_absolute_error: 18.6627\n",
      "Epoch 104/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.8365 - mean_absolute_error: 18.3306\n",
      "Epoch 104: val_loss improved from 18.16859 to 18.15892, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 17.8365 - mean_absolute_error: 18.3306 - val_loss: 18.1589 - val_mean_absolute_error: 18.6529\n",
      "Epoch 105/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7086 - mean_absolute_error: 18.2005\n",
      "Epoch 105: val_loss did not improve from 18.15892\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.7086 - mean_absolute_error: 18.2005 - val_loss: 18.1792 - val_mean_absolute_error: 18.6733\n",
      "Epoch 106/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.0189 - mean_absolute_error: 18.5120\n",
      "Epoch 106: val_loss did not improve from 18.15892\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 18.0189 - mean_absolute_error: 18.5120 - val_loss: 18.1618 - val_mean_absolute_error: 18.6558\n",
      "Epoch 107/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7728 - mean_absolute_error: 18.2658\n",
      "Epoch 107: val_loss did not improve from 18.15892\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 17.7728 - mean_absolute_error: 18.2658 - val_loss: 18.1840 - val_mean_absolute_error: 18.6782\n",
      "Epoch 108/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.3879 - mean_absolute_error: 18.8813\n",
      "Epoch 108: val_loss did not improve from 18.15892\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 18.3879 - mean_absolute_error: 18.8813 - val_loss: 18.2062 - val_mean_absolute_error: 18.7001\n",
      "Epoch 109/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.1325 - mean_absolute_error: 18.6263\n",
      "Epoch 109: val_loss did not improve from 18.15892\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 18.1325 - mean_absolute_error: 18.6263 - val_loss: 18.1955 - val_mean_absolute_error: 18.6896\n",
      "Epoch 110/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7347 - mean_absolute_error: 18.2280\n",
      "Epoch 110: val_loss did not improve from 18.15892\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.7347 - mean_absolute_error: 18.2280 - val_loss: 18.1937 - val_mean_absolute_error: 18.6878\n",
      "Epoch 111/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3473 - mean_absolute_error: 17.8377\n",
      "Epoch 111: val_loss did not improve from 18.15892\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.3473 - mean_absolute_error: 17.8377 - val_loss: 18.2027 - val_mean_absolute_error: 18.6968\n",
      "Epoch 112/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.6793 - mean_absolute_error: 18.1713\n",
      "Epoch 112: val_loss did not improve from 18.15892\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.6793 - mean_absolute_error: 18.1713 - val_loss: 18.1805 - val_mean_absolute_error: 18.6747\n",
      "Epoch 113/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.1379 - mean_absolute_error: 18.6287\n",
      "Epoch 113: val_loss improved from 18.15892 to 18.13835, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 18.1379 - mean_absolute_error: 18.6287 - val_loss: 18.1383 - val_mean_absolute_error: 18.6319\n",
      "Epoch 114/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.8791 - mean_absolute_error: 18.3737\n",
      "Epoch 114: val_loss improved from 18.13835 to 18.12334, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 17.8791 - mean_absolute_error: 18.3737 - val_loss: 18.1233 - val_mean_absolute_error: 18.6164\n",
      "Epoch 115/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.9752 - mean_absolute_error: 18.4687\n",
      "Epoch 115: val_loss did not improve from 18.12334\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.9752 - mean_absolute_error: 18.4687 - val_loss: 18.1408 - val_mean_absolute_error: 18.6344\n",
      "Epoch 116/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.9435 - mean_absolute_error: 18.4383\n",
      "Epoch 116: val_loss did not improve from 18.12334\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.9435 - mean_absolute_error: 18.4383 - val_loss: 18.1443 - val_mean_absolute_error: 18.6381\n",
      "Epoch 117/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7642 - mean_absolute_error: 18.2601\n",
      "Epoch 117: val_loss did not improve from 18.12334\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.7642 - mean_absolute_error: 18.2601 - val_loss: 18.1358 - val_mean_absolute_error: 18.6292\n",
      "Epoch 118/500\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 17.9899 - mean_absolute_error: 18.4843\n",
      "Epoch 118: val_loss did not improve from 18.12334\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 18.0987 - mean_absolute_error: 18.5933 - val_loss: 18.1572 - val_mean_absolute_error: 18.6512\n",
      "Epoch 119/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4879 - mean_absolute_error: 17.9781\n",
      "Epoch 119: val_loss did not improve from 18.12334\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.4879 - mean_absolute_error: 17.9781 - val_loss: 18.1641 - val_mean_absolute_error: 18.6582\n",
      "Epoch 120/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.9001 - mean_absolute_error: 18.3896\n",
      "Epoch 120: val_loss did not improve from 18.12334\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 17.9001 - mean_absolute_error: 18.3896 - val_loss: 18.1894 - val_mean_absolute_error: 18.6836\n",
      "Epoch 121/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.6649 - mean_absolute_error: 18.1633\n",
      "Epoch 121: val_loss did not improve from 18.12334\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.6649 - mean_absolute_error: 18.1633 - val_loss: 18.1575 - val_mean_absolute_error: 18.6514\n",
      "Epoch 122/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.8940 - mean_absolute_error: 18.3891\n",
      "Epoch 122: val_loss improved from 18.12334 to 18.12326, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 17.8940 - mean_absolute_error: 18.3891 - val_loss: 18.1233 - val_mean_absolute_error: 18.6163\n",
      "Epoch 123/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.9379 - mean_absolute_error: 18.4317\n",
      "Epoch 123: val_loss improved from 18.12326 to 18.11140, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.9379 - mean_absolute_error: 18.4317 - val_loss: 18.1114 - val_mean_absolute_error: 18.6041\n",
      "Epoch 124/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.2712 - mean_absolute_error: 18.7642\n",
      "Epoch 124: val_loss improved from 18.11140 to 18.10232, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 18.2712 - mean_absolute_error: 18.7642 - val_loss: 18.1023 - val_mean_absolute_error: 18.5951\n",
      "Epoch 125/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.6729 - mean_absolute_error: 18.1647\n",
      "Epoch 125: val_loss did not improve from 18.10232\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.6729 - mean_absolute_error: 18.1647 - val_loss: 18.1227 - val_mean_absolute_error: 18.6158\n",
      "Epoch 126/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.0098 - mean_absolute_error: 18.5069\n",
      "Epoch 126: val_loss did not improve from 18.10232\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 18.0098 - mean_absolute_error: 18.5069 - val_loss: 18.1219 - val_mean_absolute_error: 18.6149\n",
      "Epoch 127/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.5687 - mean_absolute_error: 19.0633\n",
      "Epoch 127: val_loss improved from 18.10232 to 18.09941, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 18.5687 - mean_absolute_error: 19.0633 - val_loss: 18.0994 - val_mean_absolute_error: 18.5922\n",
      "Epoch 128/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.9181 - mean_absolute_error: 18.4091\n",
      "Epoch 128: val_loss did not improve from 18.09941\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.9181 - mean_absolute_error: 18.4091 - val_loss: 18.1175 - val_mean_absolute_error: 18.6104\n",
      "Epoch 129/500\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 17.8495 - mean_absolute_error: 18.3442\n",
      "Epoch 129: val_loss did not improve from 18.09941\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 17.7672 - mean_absolute_error: 18.2620 - val_loss: 18.1168 - val_mean_absolute_error: 18.6096\n",
      "Epoch 130/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7000 - mean_absolute_error: 18.1942\n",
      "Epoch 130: val_loss did not improve from 18.09941\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.7000 - mean_absolute_error: 18.1942 - val_loss: 18.1316 - val_mean_absolute_error: 18.6249\n",
      "Epoch 131/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.8946 - mean_absolute_error: 18.3849\n",
      "Epoch 131: val_loss did not improve from 18.09941\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.8946 - mean_absolute_error: 18.3849 - val_loss: 18.1293 - val_mean_absolute_error: 18.6225\n",
      "Epoch 132/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.1257 - mean_absolute_error: 18.6206\n",
      "Epoch 132: val_loss did not improve from 18.09941\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 18.1257 - mean_absolute_error: 18.6206 - val_loss: 18.1627 - val_mean_absolute_error: 18.6568\n",
      "Epoch 133/500\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 17.5685 - mean_absolute_error: 18.0593\n",
      "Epoch 133: val_loss did not improve from 18.09941\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 17.5922 - mean_absolute_error: 18.0833 - val_loss: 18.1730 - val_mean_absolute_error: 18.6672\n",
      "Epoch 134/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.0613 - mean_absolute_error: 18.5580\n",
      "Epoch 134: val_loss did not improve from 18.09941\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 18.0613 - mean_absolute_error: 18.5580 - val_loss: 18.1807 - val_mean_absolute_error: 18.6749\n",
      "Epoch 135/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7851 - mean_absolute_error: 18.2799\n",
      "Epoch 135: val_loss did not improve from 18.09941\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.7851 - mean_absolute_error: 18.2799 - val_loss: 18.1536 - val_mean_absolute_error: 18.6476\n",
      "Epoch 136/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.8693 - mean_absolute_error: 18.3617\n",
      "Epoch 136: val_loss did not improve from 18.09941\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.8693 - mean_absolute_error: 18.3617 - val_loss: 18.1025 - val_mean_absolute_error: 18.5953\n",
      "Epoch 137/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3680 - mean_absolute_error: 17.8587\n",
      "Epoch 137: val_loss improved from 18.09941 to 18.08869, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.3680 - mean_absolute_error: 17.8587 - val_loss: 18.0887 - val_mean_absolute_error: 18.5815\n",
      "Epoch 138/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.8817 - mean_absolute_error: 18.3778\n",
      "Epoch 138: val_loss improved from 18.08869 to 18.08093, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.8817 - mean_absolute_error: 18.3778 - val_loss: 18.0809 - val_mean_absolute_error: 18.5737\n",
      "Epoch 139/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3810 - mean_absolute_error: 17.8721\n",
      "Epoch 139: val_loss did not improve from 18.08093\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 17.3810 - mean_absolute_error: 17.8721 - val_loss: 18.0949 - val_mean_absolute_error: 18.5878\n",
      "Epoch 140/500\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 17.6698 - mean_absolute_error: 18.1629\n",
      "Epoch 140: val_loss did not improve from 18.08093\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 17.9067 - mean_absolute_error: 18.4000 - val_loss: 18.1395 - val_mean_absolute_error: 18.6331\n",
      "Epoch 141/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.1510 - mean_absolute_error: 18.6466\n",
      "Epoch 141: val_loss did not improve from 18.08093\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 18.1510 - mean_absolute_error: 18.6466 - val_loss: 18.1610 - val_mean_absolute_error: 18.6551\n",
      "Epoch 142/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.9361 - mean_absolute_error: 18.4283\n",
      "Epoch 142: val_loss did not improve from 18.08093\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 17.9361 - mean_absolute_error: 18.4283 - val_loss: 18.1644 - val_mean_absolute_error: 18.6584\n",
      "Epoch 143/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.1207 - mean_absolute_error: 18.6119\n",
      "Epoch 143: val_loss did not improve from 18.08093\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 18.1207 - mean_absolute_error: 18.6119 - val_loss: 18.1717 - val_mean_absolute_error: 18.6658\n",
      "Epoch 144/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5733 - mean_absolute_error: 18.0659\n",
      "Epoch 144: val_loss did not improve from 18.08093\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 17.5733 - mean_absolute_error: 18.0659 - val_loss: 18.1445 - val_mean_absolute_error: 18.6382\n",
      "Epoch 145/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.9688 - mean_absolute_error: 18.4616\n",
      "Epoch 145: val_loss did not improve from 18.08093\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.9688 - mean_absolute_error: 18.4616 - val_loss: 18.1073 - val_mean_absolute_error: 18.6000\n",
      "Epoch 146/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7571 - mean_absolute_error: 18.2517\n",
      "Epoch 146: val_loss did not improve from 18.08093\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.7571 - mean_absolute_error: 18.2517 - val_loss: 18.1044 - val_mean_absolute_error: 18.5971\n",
      "Epoch 147/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7385 - mean_absolute_error: 18.2343\n",
      "Epoch 147: val_loss did not improve from 18.08093\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.7385 - mean_absolute_error: 18.2343 - val_loss: 18.0926 - val_mean_absolute_error: 18.5855\n",
      "Epoch 148/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.9442 - mean_absolute_error: 18.4401\n",
      "Epoch 148: val_loss improved from 18.08093 to 18.06360, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.9442 - mean_absolute_error: 18.4401 - val_loss: 18.0636 - val_mean_absolute_error: 18.5562\n",
      "Epoch 149/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4362 - mean_absolute_error: 17.9310\n",
      "Epoch 149: val_loss improved from 18.06360 to 18.04648, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 17.4362 - mean_absolute_error: 17.9310 - val_loss: 18.0465 - val_mean_absolute_error: 18.5391\n",
      "Epoch 150/500\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 17.9233 - mean_absolute_error: 18.4179\n",
      "Epoch 150: val_loss improved from 18.04648 to 18.03885, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 17.9036 - mean_absolute_error: 18.3976 - val_loss: 18.0388 - val_mean_absolute_error: 18.5317\n",
      "Epoch 151/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5450 - mean_absolute_error: 18.0396\n",
      "Epoch 151: val_loss did not improve from 18.03885\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.5450 - mean_absolute_error: 18.0396 - val_loss: 18.0438 - val_mean_absolute_error: 18.5365\n",
      "Epoch 152/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.9192 - mean_absolute_error: 18.4136\n",
      "Epoch 152: val_loss did not improve from 18.03885\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.9192 - mean_absolute_error: 18.4136 - val_loss: 18.0414 - val_mean_absolute_error: 18.5342\n",
      "Epoch 153/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4284 - mean_absolute_error: 17.9221\n",
      "Epoch 153: val_loss improved from 18.03885 to 18.02788, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.4284 - mean_absolute_error: 17.9221 - val_loss: 18.0279 - val_mean_absolute_error: 18.5210\n",
      "Epoch 154/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7082 - mean_absolute_error: 18.2031\n",
      "Epoch 154: val_loss did not improve from 18.02788\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 17.7082 - mean_absolute_error: 18.2031 - val_loss: 18.0420 - val_mean_absolute_error: 18.5348\n",
      "Epoch 155/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.3771 - mean_absolute_error: 18.8698\n",
      "Epoch 155: val_loss did not improve from 18.02788\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 18.3771 - mean_absolute_error: 18.8698 - val_loss: 18.0280 - val_mean_absolute_error: 18.5211\n",
      "Epoch 156/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.8965 - mean_absolute_error: 18.3864\n",
      "Epoch 156: val_loss did not improve from 18.02788\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.8965 - mean_absolute_error: 18.3864 - val_loss: 18.0288 - val_mean_absolute_error: 18.5219\n",
      "Epoch 157/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2760 - mean_absolute_error: 17.7697\n",
      "Epoch 157: val_loss improved from 18.02788 to 18.00864, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.2760 - mean_absolute_error: 17.7697 - val_loss: 18.0086 - val_mean_absolute_error: 18.5021\n",
      "Epoch 158/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.6138 - mean_absolute_error: 18.1081\n",
      "Epoch 158: val_loss improved from 18.00864 to 17.98431, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.6138 - mean_absolute_error: 18.1081 - val_loss: 17.9843 - val_mean_absolute_error: 18.4777\n",
      "Epoch 159/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.9225 - mean_absolute_error: 18.4189\n",
      "Epoch 159: val_loss improved from 17.98431 to 17.95942, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.9225 - mean_absolute_error: 18.4189 - val_loss: 17.9594 - val_mean_absolute_error: 18.4523\n",
      "Epoch 160/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.1593 - mean_absolute_error: 18.6501\n",
      "Epoch 160: val_loss improved from 17.95942 to 17.92229, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 18.1593 - mean_absolute_error: 18.6501 - val_loss: 17.9223 - val_mean_absolute_error: 18.4149\n",
      "Epoch 161/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.9351 - mean_absolute_error: 18.4294\n",
      "Epoch 161: val_loss improved from 17.92229 to 17.91154, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 17.9351 - mean_absolute_error: 18.4294 - val_loss: 17.9115 - val_mean_absolute_error: 18.4042\n",
      "Epoch 162/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1997 - mean_absolute_error: 17.6935\n",
      "Epoch 162: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 17.1997 - mean_absolute_error: 17.6935 - val_loss: 17.9227 - val_mean_absolute_error: 18.4153\n",
      "Epoch 163/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3759 - mean_absolute_error: 17.8655\n",
      "Epoch 163: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.3759 - mean_absolute_error: 17.8655 - val_loss: 17.9591 - val_mean_absolute_error: 18.4519\n",
      "Epoch 164/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7668 - mean_absolute_error: 18.2628\n",
      "Epoch 164: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 17.7668 - mean_absolute_error: 18.2628 - val_loss: 17.9960 - val_mean_absolute_error: 18.4895\n",
      "Epoch 165/500\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 17.7989 - mean_absolute_error: 18.2915\n",
      "Epoch 165: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 17.7945 - mean_absolute_error: 18.2873 - val_loss: 18.0356 - val_mean_absolute_error: 18.5286\n",
      "Epoch 166/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7963 - mean_absolute_error: 18.2883\n",
      "Epoch 166: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 17.7963 - mean_absolute_error: 18.2883 - val_loss: 18.0348 - val_mean_absolute_error: 18.5278\n",
      "Epoch 167/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7365 - mean_absolute_error: 18.2304\n",
      "Epoch 167: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.7365 - mean_absolute_error: 18.2304 - val_loss: 18.0372 - val_mean_absolute_error: 18.5302\n",
      "Epoch 168/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5683 - mean_absolute_error: 18.0616\n",
      "Epoch 168: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.5683 - mean_absolute_error: 18.0616 - val_loss: 18.0476 - val_mean_absolute_error: 18.5402\n",
      "Epoch 169/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2175 - mean_absolute_error: 17.7107\n",
      "Epoch 169: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.2175 - mean_absolute_error: 17.7107 - val_loss: 18.0818 - val_mean_absolute_error: 18.5746\n",
      "Epoch 170/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.6898 - mean_absolute_error: 18.1844\n",
      "Epoch 170: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.6898 - mean_absolute_error: 18.1844 - val_loss: 18.0508 - val_mean_absolute_error: 18.5433\n",
      "Epoch 171/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.1163 - mean_absolute_error: 18.6073\n",
      "Epoch 171: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 18.1163 - mean_absolute_error: 18.6073 - val_loss: 18.0755 - val_mean_absolute_error: 18.5683\n",
      "Epoch 172/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4020 - mean_absolute_error: 17.8936\n",
      "Epoch 172: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.4020 - mean_absolute_error: 17.8936 - val_loss: 18.1246 - val_mean_absolute_error: 18.6178\n",
      "Epoch 173/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2829 - mean_absolute_error: 17.7756\n",
      "Epoch 173: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.2829 - mean_absolute_error: 17.7756 - val_loss: 18.1121 - val_mean_absolute_error: 18.6048\n",
      "Epoch 174/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7782 - mean_absolute_error: 18.2729\n",
      "Epoch 174: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.7782 - mean_absolute_error: 18.2729 - val_loss: 18.0891 - val_mean_absolute_error: 18.5820\n",
      "Epoch 175/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3090 - mean_absolute_error: 17.8024\n",
      "Epoch 175: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.3090 - mean_absolute_error: 17.8024 - val_loss: 18.0928 - val_mean_absolute_error: 18.5857\n",
      "Epoch 176/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7269 - mean_absolute_error: 18.2195\n",
      "Epoch 176: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.7269 - mean_absolute_error: 18.2195 - val_loss: 18.0704 - val_mean_absolute_error: 18.5631\n",
      "Epoch 177/500\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 17.5135 - mean_absolute_error: 18.0093\n",
      "Epoch 177: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 17.6924 - mean_absolute_error: 18.1882 - val_loss: 18.0464 - val_mean_absolute_error: 18.5390\n",
      "Epoch 178/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7498 - mean_absolute_error: 18.2426\n",
      "Epoch 178: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 17.7498 - mean_absolute_error: 18.2426 - val_loss: 18.0618 - val_mean_absolute_error: 18.5544\n",
      "Epoch 179/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.9356 - mean_absolute_error: 18.4282\n",
      "Epoch 179: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.9356 - mean_absolute_error: 18.4282 - val_loss: 18.0910 - val_mean_absolute_error: 18.5839\n",
      "Epoch 180/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5896 - mean_absolute_error: 18.0819\n",
      "Epoch 180: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.5896 - mean_absolute_error: 18.0819 - val_loss: 18.1032 - val_mean_absolute_error: 18.5960\n",
      "Epoch 181/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.0693 - mean_absolute_error: 18.5646\n",
      "Epoch 181: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 18.0693 - mean_absolute_error: 18.5646 - val_loss: 18.1016 - val_mean_absolute_error: 18.5944\n",
      "Epoch 182/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5114 - mean_absolute_error: 18.0056\n",
      "Epoch 182: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 17.5114 - mean_absolute_error: 18.0056 - val_loss: 18.0881 - val_mean_absolute_error: 18.5810\n",
      "Epoch 183/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.1189 - mean_absolute_error: 18.6123\n",
      "Epoch 183: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 18.1189 - mean_absolute_error: 18.6123 - val_loss: 18.0505 - val_mean_absolute_error: 18.5430\n",
      "Epoch 184/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.9245 - mean_absolute_error: 18.4184\n",
      "Epoch 184: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.9245 - mean_absolute_error: 18.4184 - val_loss: 18.0572 - val_mean_absolute_error: 18.5497\n",
      "Epoch 185/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2661 - mean_absolute_error: 17.7589\n",
      "Epoch 185: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 17.2661 - mean_absolute_error: 17.7589 - val_loss: 18.0174 - val_mean_absolute_error: 18.5107\n",
      "Epoch 186/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3275 - mean_absolute_error: 17.8208\n",
      "Epoch 186: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 17.3275 - mean_absolute_error: 17.8208 - val_loss: 17.9976 - val_mean_absolute_error: 18.4912\n",
      "Epoch 187/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.6900 - mean_absolute_error: 18.1824\n",
      "Epoch 187: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.6900 - mean_absolute_error: 18.1824 - val_loss: 18.0158 - val_mean_absolute_error: 18.5091\n",
      "Epoch 188/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5494 - mean_absolute_error: 18.0447\n",
      "Epoch 188: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.5494 - mean_absolute_error: 18.0447 - val_loss: 17.9990 - val_mean_absolute_error: 18.4925\n",
      "Epoch 189/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.8809 - mean_absolute_error: 18.3726\n",
      "Epoch 189: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.8809 - mean_absolute_error: 18.3726 - val_loss: 18.0064 - val_mean_absolute_error: 18.4999\n",
      "Epoch 190/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7867 - mean_absolute_error: 18.2773\n",
      "Epoch 190: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.7867 - mean_absolute_error: 18.2773 - val_loss: 18.0212 - val_mean_absolute_error: 18.5145\n",
      "Epoch 191/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5656 - mean_absolute_error: 18.0564\n",
      "Epoch 191: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.5656 - mean_absolute_error: 18.0564 - val_loss: 18.0421 - val_mean_absolute_error: 18.5349\n",
      "Epoch 192/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4371 - mean_absolute_error: 17.9310\n",
      "Epoch 192: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.4371 - mean_absolute_error: 17.9310 - val_loss: 18.0464 - val_mean_absolute_error: 18.5391\n",
      "Epoch 193/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 18.0535 - mean_absolute_error: 18.5445\n",
      "Epoch 193: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 18.0535 - mean_absolute_error: 18.5445 - val_loss: 18.0188 - val_mean_absolute_error: 18.5121\n",
      "Epoch 194/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.6169 - mean_absolute_error: 18.1103\n",
      "Epoch 194: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.6169 - mean_absolute_error: 18.1103 - val_loss: 18.0345 - val_mean_absolute_error: 18.5275\n",
      "Epoch 195/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.6258 - mean_absolute_error: 18.1187\n",
      "Epoch 195: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 17.6258 - mean_absolute_error: 18.1187 - val_loss: 18.0754 - val_mean_absolute_error: 18.5682\n",
      "Epoch 196/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7524 - mean_absolute_error: 18.2422\n",
      "Epoch 196: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.7524 - mean_absolute_error: 18.2422 - val_loss: 18.0983 - val_mean_absolute_error: 18.5911\n",
      "Epoch 197/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.9529 - mean_absolute_error: 18.4460\n",
      "Epoch 197: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.9529 - mean_absolute_error: 18.4460 - val_loss: 18.1234 - val_mean_absolute_error: 18.6164\n",
      "Epoch 198/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.8956 - mean_absolute_error: 18.3876\n",
      "Epoch 198: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.8956 - mean_absolute_error: 18.3876 - val_loss: 18.0981 - val_mean_absolute_error: 18.5909\n",
      "Epoch 199/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3683 - mean_absolute_error: 17.8605\n",
      "Epoch 199: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.3683 - mean_absolute_error: 17.8605 - val_loss: 18.0497 - val_mean_absolute_error: 18.5422\n",
      "Epoch 200/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4357 - mean_absolute_error: 17.9308\n",
      "Epoch 200: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.4357 - mean_absolute_error: 17.9308 - val_loss: 18.0041 - val_mean_absolute_error: 18.4976\n",
      "Epoch 201/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4762 - mean_absolute_error: 17.9648\n",
      "Epoch 201: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.4762 - mean_absolute_error: 17.9648 - val_loss: 18.0400 - val_mean_absolute_error: 18.5329\n",
      "Epoch 202/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.9163 - mean_absolute_error: 18.4085\n",
      "Epoch 202: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.9163 - mean_absolute_error: 18.4085 - val_loss: 18.0678 - val_mean_absolute_error: 18.5605\n",
      "Epoch 203/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3742 - mean_absolute_error: 17.8648\n",
      "Epoch 203: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.3742 - mean_absolute_error: 17.8648 - val_loss: 18.1054 - val_mean_absolute_error: 18.5981\n",
      "Epoch 204/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.8730 - mean_absolute_error: 18.3677\n",
      "Epoch 204: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.8730 - mean_absolute_error: 18.3677 - val_loss: 18.1254 - val_mean_absolute_error: 18.6185\n",
      "Epoch 205/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5251 - mean_absolute_error: 18.0167\n",
      "Epoch 205: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.5251 - mean_absolute_error: 18.0167 - val_loss: 18.0899 - val_mean_absolute_error: 18.5827\n",
      "Epoch 206/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7350 - mean_absolute_error: 18.2287\n",
      "Epoch 206: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.7350 - mean_absolute_error: 18.2287 - val_loss: 18.0451 - val_mean_absolute_error: 18.5378\n",
      "Epoch 207/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5709 - mean_absolute_error: 18.0624\n",
      "Epoch 207: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.5709 - mean_absolute_error: 18.0624 - val_loss: 18.0357 - val_mean_absolute_error: 18.5287\n",
      "Epoch 208/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3827 - mean_absolute_error: 17.8773\n",
      "Epoch 208: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.3827 - mean_absolute_error: 17.8773 - val_loss: 18.0339 - val_mean_absolute_error: 18.5270\n",
      "Epoch 209/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4344 - mean_absolute_error: 17.9289\n",
      "Epoch 209: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.4344 - mean_absolute_error: 17.9289 - val_loss: 17.9912 - val_mean_absolute_error: 18.4847\n",
      "Epoch 210/500\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 17.5546 - mean_absolute_error: 18.0446\n",
      "Epoch 210: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 17.6262 - mean_absolute_error: 18.1165 - val_loss: 17.9424 - val_mean_absolute_error: 18.4347\n",
      "Epoch 211/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2138 - mean_absolute_error: 17.7039\n",
      "Epoch 211: val_loss did not improve from 17.91154\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.2138 - mean_absolute_error: 17.7039 - val_loss: 17.9127 - val_mean_absolute_error: 18.4054\n",
      "Epoch 212/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1579 - mean_absolute_error: 17.6513\n",
      "Epoch 212: val_loss improved from 17.91154 to 17.87155, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.1579 - mean_absolute_error: 17.6513 - val_loss: 17.8716 - val_mean_absolute_error: 18.3652\n",
      "Epoch 213/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7129 - mean_absolute_error: 18.2041\n",
      "Epoch 213: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.7129 - mean_absolute_error: 18.2041 - val_loss: 17.8879 - val_mean_absolute_error: 18.3808\n",
      "Epoch 214/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.6376 - mean_absolute_error: 18.1285\n",
      "Epoch 214: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 17.6376 - mean_absolute_error: 18.1285 - val_loss: 17.9291 - val_mean_absolute_error: 18.4217\n",
      "Epoch 215/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4802 - mean_absolute_error: 17.9749\n",
      "Epoch 215: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.4802 - mean_absolute_error: 17.9749 - val_loss: 17.9336 - val_mean_absolute_error: 18.4261\n",
      "Epoch 216/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5021 - mean_absolute_error: 17.9958\n",
      "Epoch 216: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.5021 - mean_absolute_error: 17.9958 - val_loss: 17.9620 - val_mean_absolute_error: 18.4549\n",
      "Epoch 217/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7327 - mean_absolute_error: 18.2290\n",
      "Epoch 217: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.7327 - mean_absolute_error: 18.2290 - val_loss: 17.9817 - val_mean_absolute_error: 18.4751\n",
      "Epoch 218/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.9024 - mean_absolute_error: 18.3945\n",
      "Epoch 218: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.9024 - mean_absolute_error: 18.3945 - val_loss: 17.9505 - val_mean_absolute_error: 18.4430\n",
      "Epoch 219/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4866 - mean_absolute_error: 17.9831\n",
      "Epoch 219: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.4866 - mean_absolute_error: 17.9831 - val_loss: 17.9146 - val_mean_absolute_error: 18.4072\n",
      "Epoch 220/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.8253 - mean_absolute_error: 18.3204\n",
      "Epoch 220: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.8253 - mean_absolute_error: 18.3204 - val_loss: 17.9198 - val_mean_absolute_error: 18.4125\n",
      "Epoch 221/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3740 - mean_absolute_error: 17.8667\n",
      "Epoch 221: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.3740 - mean_absolute_error: 17.8667 - val_loss: 17.9087 - val_mean_absolute_error: 18.4014\n",
      "Epoch 222/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3653 - mean_absolute_error: 17.8571\n",
      "Epoch 222: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.3653 - mean_absolute_error: 17.8571 - val_loss: 17.9189 - val_mean_absolute_error: 18.4116\n",
      "Epoch 223/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2418 - mean_absolute_error: 17.7330\n",
      "Epoch 223: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.2418 - mean_absolute_error: 17.7330 - val_loss: 17.9317 - val_mean_absolute_error: 18.4242\n",
      "Epoch 224/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2776 - mean_absolute_error: 17.7703\n",
      "Epoch 224: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.2776 - mean_absolute_error: 17.7703 - val_loss: 17.9614 - val_mean_absolute_error: 18.4543\n",
      "Epoch 225/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3163 - mean_absolute_error: 17.8065\n",
      "Epoch 225: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.3163 - mean_absolute_error: 17.8065 - val_loss: 17.9507 - val_mean_absolute_error: 18.4432\n",
      "Epoch 226/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4005 - mean_absolute_error: 17.8906\n",
      "Epoch 226: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.4005 - mean_absolute_error: 17.8906 - val_loss: 17.9447 - val_mean_absolute_error: 18.4370\n",
      "Epoch 227/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4676 - mean_absolute_error: 17.9628\n",
      "Epoch 227: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.4676 - mean_absolute_error: 17.9628 - val_loss: 18.0019 - val_mean_absolute_error: 18.4954\n",
      "Epoch 228/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2833 - mean_absolute_error: 17.7760\n",
      "Epoch 228: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 17.2833 - mean_absolute_error: 17.7760 - val_loss: 18.0306 - val_mean_absolute_error: 18.5237\n",
      "Epoch 229/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2918 - mean_absolute_error: 17.7835\n",
      "Epoch 229: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 17.2918 - mean_absolute_error: 17.7835 - val_loss: 18.0939 - val_mean_absolute_error: 18.5867\n",
      "Epoch 230/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5976 - mean_absolute_error: 18.0878\n",
      "Epoch 230: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.5976 - mean_absolute_error: 18.0878 - val_loss: 18.1079 - val_mean_absolute_error: 18.6006\n",
      "Epoch 231/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3027 - mean_absolute_error: 17.7963\n",
      "Epoch 231: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.3027 - mean_absolute_error: 17.7963 - val_loss: 18.0836 - val_mean_absolute_error: 18.5764\n",
      "Epoch 232/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.6873 - mean_absolute_error: 18.1828\n",
      "Epoch 232: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 17.6873 - mean_absolute_error: 18.1828 - val_loss: 18.0289 - val_mean_absolute_error: 18.5220\n",
      "Epoch 233/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3947 - mean_absolute_error: 17.8898\n",
      "Epoch 233: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.3947 - mean_absolute_error: 17.8898 - val_loss: 17.9476 - val_mean_absolute_error: 18.4400\n",
      "Epoch 234/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5290 - mean_absolute_error: 18.0218\n",
      "Epoch 234: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 17.5290 - mean_absolute_error: 18.0218 - val_loss: 17.9497 - val_mean_absolute_error: 18.4422\n",
      "Epoch 235/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4766 - mean_absolute_error: 17.9682\n",
      "Epoch 235: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.4766 - mean_absolute_error: 17.9682 - val_loss: 17.9182 - val_mean_absolute_error: 18.4108\n",
      "Epoch 236/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5827 - mean_absolute_error: 18.0720\n",
      "Epoch 236: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.5827 - mean_absolute_error: 18.0720 - val_loss: 17.9004 - val_mean_absolute_error: 18.3930\n",
      "Epoch 237/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5456 - mean_absolute_error: 18.0407\n",
      "Epoch 237: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.5456 - mean_absolute_error: 18.0407 - val_loss: 17.9214 - val_mean_absolute_error: 18.4140\n",
      "Epoch 238/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.6521 - mean_absolute_error: 18.1498\n",
      "Epoch 238: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.6521 - mean_absolute_error: 18.1498 - val_loss: 17.9066 - val_mean_absolute_error: 18.3993\n",
      "Epoch 239/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5784 - mean_absolute_error: 18.0711\n",
      "Epoch 239: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.5784 - mean_absolute_error: 18.0711 - val_loss: 17.9127 - val_mean_absolute_error: 18.4054\n",
      "Epoch 240/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4699 - mean_absolute_error: 17.9598\n",
      "Epoch 240: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.4699 - mean_absolute_error: 17.9598 - val_loss: 17.9098 - val_mean_absolute_error: 18.4025\n",
      "Epoch 241/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1570 - mean_absolute_error: 17.6502\n",
      "Epoch 241: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.1570 - mean_absolute_error: 17.6502 - val_loss: 17.9248 - val_mean_absolute_error: 18.4174\n",
      "Epoch 242/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4431 - mean_absolute_error: 17.9338\n",
      "Epoch 242: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.4431 - mean_absolute_error: 17.9338 - val_loss: 17.9090 - val_mean_absolute_error: 18.4017\n",
      "Epoch 243/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.6401 - mean_absolute_error: 18.1350\n",
      "Epoch 243: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.6401 - mean_absolute_error: 18.1350 - val_loss: 17.9439 - val_mean_absolute_error: 18.4362\n",
      "Epoch 244/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5914 - mean_absolute_error: 18.0819\n",
      "Epoch 244: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.5914 - mean_absolute_error: 18.0819 - val_loss: 17.9569 - val_mean_absolute_error: 18.4497\n",
      "Epoch 245/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7073 - mean_absolute_error: 18.2016\n",
      "Epoch 245: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.7073 - mean_absolute_error: 18.2016 - val_loss: 18.0152 - val_mean_absolute_error: 18.5086\n",
      "Epoch 246/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9495 - mean_absolute_error: 17.4403\n",
      "Epoch 246: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.9495 - mean_absolute_error: 17.4403 - val_loss: 18.0495 - val_mean_absolute_error: 18.5420\n",
      "Epoch 247/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1216 - mean_absolute_error: 17.6148\n",
      "Epoch 247: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.1216 - mean_absolute_error: 17.6148 - val_loss: 18.0404 - val_mean_absolute_error: 18.5332\n",
      "Epoch 248/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3599 - mean_absolute_error: 17.8471\n",
      "Epoch 248: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.3599 - mean_absolute_error: 17.8471 - val_loss: 18.0284 - val_mean_absolute_error: 18.5216\n",
      "Epoch 249/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2755 - mean_absolute_error: 17.7659\n",
      "Epoch 249: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.2755 - mean_absolute_error: 17.7659 - val_loss: 18.0604 - val_mean_absolute_error: 18.5530\n",
      "Epoch 250/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.6496 - mean_absolute_error: 18.1406\n",
      "Epoch 250: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.6496 - mean_absolute_error: 18.1406 - val_loss: 18.0365 - val_mean_absolute_error: 18.5295\n",
      "Epoch 251/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1185 - mean_absolute_error: 17.6080\n",
      "Epoch 251: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.1185 - mean_absolute_error: 17.6080 - val_loss: 18.0683 - val_mean_absolute_error: 18.5610\n",
      "Epoch 252/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5190 - mean_absolute_error: 18.0123\n",
      "Epoch 252: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.5190 - mean_absolute_error: 18.0123 - val_loss: 18.0288 - val_mean_absolute_error: 18.5219\n",
      "Epoch 253/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4968 - mean_absolute_error: 17.9907\n",
      "Epoch 253: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.4968 - mean_absolute_error: 17.9907 - val_loss: 18.0072 - val_mean_absolute_error: 18.5007\n",
      "Epoch 254/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4596 - mean_absolute_error: 17.9505\n",
      "Epoch 254: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.4596 - mean_absolute_error: 17.9505 - val_loss: 17.9599 - val_mean_absolute_error: 18.4527\n",
      "Epoch 255/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.6112 - mean_absolute_error: 18.1041\n",
      "Epoch 255: val_loss did not improve from 17.87155\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.6112 - mean_absolute_error: 18.1041 - val_loss: 17.8899 - val_mean_absolute_error: 18.3828\n",
      "Epoch 256/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5173 - mean_absolute_error: 18.0112\n",
      "Epoch 256: val_loss improved from 17.87155 to 17.86564, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.5173 - mean_absolute_error: 18.0112 - val_loss: 17.8656 - val_mean_absolute_error: 18.3595\n",
      "Epoch 257/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5009 - mean_absolute_error: 17.9930\n",
      "Epoch 257: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.5009 - mean_absolute_error: 17.9930 - val_loss: 17.8764 - val_mean_absolute_error: 18.3699\n",
      "Epoch 258/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7392 - mean_absolute_error: 18.2296\n",
      "Epoch 258: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.7392 - mean_absolute_error: 18.2296 - val_loss: 17.9365 - val_mean_absolute_error: 18.4290\n",
      "Epoch 259/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2215 - mean_absolute_error: 17.7141\n",
      "Epoch 259: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.2215 - mean_absolute_error: 17.7141 - val_loss: 17.9517 - val_mean_absolute_error: 18.4442\n",
      "Epoch 260/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1835 - mean_absolute_error: 17.6735\n",
      "Epoch 260: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.1835 - mean_absolute_error: 17.6735 - val_loss: 17.9243 - val_mean_absolute_error: 18.4169\n",
      "Epoch 261/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4084 - mean_absolute_error: 17.8976\n",
      "Epoch 261: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.4084 - mean_absolute_error: 17.8976 - val_loss: 17.9053 - val_mean_absolute_error: 18.3980\n",
      "Epoch 262/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4592 - mean_absolute_error: 17.9486\n",
      "Epoch 262: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.4592 - mean_absolute_error: 17.9486 - val_loss: 17.9025 - val_mean_absolute_error: 18.3951\n",
      "Epoch 263/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.6022 - mean_absolute_error: 18.0951\n",
      "Epoch 263: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.6022 - mean_absolute_error: 18.0951 - val_loss: 17.9140 - val_mean_absolute_error: 18.4067\n",
      "Epoch 264/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4463 - mean_absolute_error: 17.9389\n",
      "Epoch 264: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.4463 - mean_absolute_error: 17.9389 - val_loss: 17.9242 - val_mean_absolute_error: 18.4168\n",
      "Epoch 265/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4575 - mean_absolute_error: 17.9514\n",
      "Epoch 265: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 17.4575 - mean_absolute_error: 17.9514 - val_loss: 17.9154 - val_mean_absolute_error: 18.4081\n",
      "Epoch 266/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2419 - mean_absolute_error: 17.7308\n",
      "Epoch 266: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.2419 - mean_absolute_error: 17.7308 - val_loss: 17.9001 - val_mean_absolute_error: 18.3927\n",
      "Epoch 267/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5498 - mean_absolute_error: 18.0437\n",
      "Epoch 267: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.5498 - mean_absolute_error: 18.0437 - val_loss: 17.8946 - val_mean_absolute_error: 18.3872\n",
      "Epoch 268/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3370 - mean_absolute_error: 17.8294\n",
      "Epoch 268: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.3370 - mean_absolute_error: 17.8294 - val_loss: 17.8961 - val_mean_absolute_error: 18.3887\n",
      "Epoch 269/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4951 - mean_absolute_error: 17.9837\n",
      "Epoch 269: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.4951 - mean_absolute_error: 17.9837 - val_loss: 17.9019 - val_mean_absolute_error: 18.3945\n",
      "Epoch 270/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5241 - mean_absolute_error: 18.0177\n",
      "Epoch 270: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.5241 - mean_absolute_error: 18.0177 - val_loss: 17.9449 - val_mean_absolute_error: 18.4372\n",
      "Epoch 271/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3251 - mean_absolute_error: 17.8177\n",
      "Epoch 271: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.3251 - mean_absolute_error: 17.8177 - val_loss: 17.9967 - val_mean_absolute_error: 18.4903\n",
      "Epoch 272/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5268 - mean_absolute_error: 18.0198\n",
      "Epoch 272: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.5268 - mean_absolute_error: 18.0198 - val_loss: 18.0212 - val_mean_absolute_error: 18.5145\n",
      "Epoch 273/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8813 - mean_absolute_error: 17.3698\n",
      "Epoch 273: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.8813 - mean_absolute_error: 17.3698 - val_loss: 18.0257 - val_mean_absolute_error: 18.5189\n",
      "Epoch 274/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3784 - mean_absolute_error: 17.8699\n",
      "Epoch 274: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.3784 - mean_absolute_error: 17.8699 - val_loss: 18.0043 - val_mean_absolute_error: 18.4978\n",
      "Epoch 275/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5473 - mean_absolute_error: 18.0392\n",
      "Epoch 275: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 17.5473 - mean_absolute_error: 18.0392 - val_loss: 17.9763 - val_mean_absolute_error: 18.4696\n",
      "Epoch 276/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2449 - mean_absolute_error: 17.7326\n",
      "Epoch 276: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.2449 - mean_absolute_error: 17.7326 - val_loss: 17.9761 - val_mean_absolute_error: 18.4694\n",
      "Epoch 277/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7278 - mean_absolute_error: 18.2207\n",
      "Epoch 277: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.7278 - mean_absolute_error: 18.2207 - val_loss: 17.9437 - val_mean_absolute_error: 18.4360\n",
      "Epoch 278/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3221 - mean_absolute_error: 17.8133\n",
      "Epoch 278: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.3221 - mean_absolute_error: 17.8133 - val_loss: 18.0232 - val_mean_absolute_error: 18.5165\n",
      "Epoch 279/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.6176 - mean_absolute_error: 18.1084\n",
      "Epoch 279: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.6176 - mean_absolute_error: 18.1084 - val_loss: 18.0244 - val_mean_absolute_error: 18.5176\n",
      "Epoch 280/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2106 - mean_absolute_error: 17.6993\n",
      "Epoch 280: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.2106 - mean_absolute_error: 17.6993 - val_loss: 18.0398 - val_mean_absolute_error: 18.5327\n",
      "Epoch 281/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1367 - mean_absolute_error: 17.6297\n",
      "Epoch 281: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.1367 - mean_absolute_error: 17.6297 - val_loss: 18.0638 - val_mean_absolute_error: 18.5564\n",
      "Epoch 282/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4044 - mean_absolute_error: 17.8977\n",
      "Epoch 282: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.4044 - mean_absolute_error: 17.8977 - val_loss: 18.0325 - val_mean_absolute_error: 18.5256\n",
      "Epoch 283/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3658 - mean_absolute_error: 17.8581\n",
      "Epoch 283: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.3658 - mean_absolute_error: 17.8581 - val_loss: 18.0064 - val_mean_absolute_error: 18.4999\n",
      "Epoch 284/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4129 - mean_absolute_error: 17.9084\n",
      "Epoch 284: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.4129 - mean_absolute_error: 17.9084 - val_loss: 17.9954 - val_mean_absolute_error: 18.4890\n",
      "Epoch 285/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0980 - mean_absolute_error: 17.5901\n",
      "Epoch 285: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 17.0980 - mean_absolute_error: 17.5901 - val_loss: 17.9613 - val_mean_absolute_error: 18.4542\n",
      "Epoch 286/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.7775 - mean_absolute_error: 18.2693\n",
      "Epoch 286: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.7775 - mean_absolute_error: 18.2693 - val_loss: 17.9684 - val_mean_absolute_error: 18.4615\n",
      "Epoch 287/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0642 - mean_absolute_error: 17.5551\n",
      "Epoch 287: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.0642 - mean_absolute_error: 17.5551 - val_loss: 17.9840 - val_mean_absolute_error: 18.4774\n",
      "Epoch 288/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4826 - mean_absolute_error: 17.9747\n",
      "Epoch 288: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.4826 - mean_absolute_error: 17.9747 - val_loss: 18.0036 - val_mean_absolute_error: 18.4971\n",
      "Epoch 289/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2630 - mean_absolute_error: 17.7539\n",
      "Epoch 289: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.2630 - mean_absolute_error: 17.7539 - val_loss: 17.9937 - val_mean_absolute_error: 18.4872\n",
      "Epoch 290/500\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 17.2946 - mean_absolute_error: 17.7870\n",
      "Epoch 290: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 17.1758 - mean_absolute_error: 17.6685 - val_loss: 18.0630 - val_mean_absolute_error: 18.5556\n",
      "Epoch 291/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1015 - mean_absolute_error: 17.5925\n",
      "Epoch 291: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 17.1015 - mean_absolute_error: 17.5925 - val_loss: 17.9780 - val_mean_absolute_error: 18.4713\n",
      "Epoch 292/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2113 - mean_absolute_error: 17.7029\n",
      "Epoch 292: val_loss did not improve from 17.86564\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 17.2113 - mean_absolute_error: 17.7029 - val_loss: 17.9435 - val_mean_absolute_error: 18.4358\n",
      "Epoch 293/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3700 - mean_absolute_error: 17.8619\n",
      "Epoch 293: val_loss improved from 17.86564 to 17.86214, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.3700 - mean_absolute_error: 17.8619 - val_loss: 17.8621 - val_mean_absolute_error: 18.3561\n",
      "Epoch 294/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2799 - mean_absolute_error: 17.7726\n",
      "Epoch 294: val_loss improved from 17.86214 to 17.82751, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.2799 - mean_absolute_error: 17.7726 - val_loss: 17.8275 - val_mean_absolute_error: 18.3217\n",
      "Epoch 295/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3778 - mean_absolute_error: 17.8721\n",
      "Epoch 295: val_loss did not improve from 17.82751\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.3778 - mean_absolute_error: 17.8721 - val_loss: 17.8479 - val_mean_absolute_error: 18.3421\n",
      "Epoch 296/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4094 - mean_absolute_error: 17.9019\n",
      "Epoch 296: val_loss did not improve from 17.82751\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.4094 - mean_absolute_error: 17.9019 - val_loss: 17.8673 - val_mean_absolute_error: 18.3611\n",
      "Epoch 297/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1996 - mean_absolute_error: 17.6907\n",
      "Epoch 297: val_loss did not improve from 17.82751\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 17.1996 - mean_absolute_error: 17.6907 - val_loss: 17.8797 - val_mean_absolute_error: 18.3731\n",
      "Epoch 298/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9847 - mean_absolute_error: 17.4719\n",
      "Epoch 298: val_loss did not improve from 17.82751\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.9847 - mean_absolute_error: 17.4719 - val_loss: 17.8756 - val_mean_absolute_error: 18.3691\n",
      "Epoch 299/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4308 - mean_absolute_error: 17.9229\n",
      "Epoch 299: val_loss did not improve from 17.82751\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.4308 - mean_absolute_error: 17.9229 - val_loss: 17.8770 - val_mean_absolute_error: 18.3704\n",
      "Epoch 300/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1356 - mean_absolute_error: 17.6281\n",
      "Epoch 300: val_loss did not improve from 17.82751\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.1356 - mean_absolute_error: 17.6281 - val_loss: 17.9347 - val_mean_absolute_error: 18.4272\n",
      "Epoch 301/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1357 - mean_absolute_error: 17.6243\n",
      "Epoch 301: val_loss did not improve from 17.82751\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.1357 - mean_absolute_error: 17.6243 - val_loss: 17.9074 - val_mean_absolute_error: 18.4000\n",
      "Epoch 302/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1130 - mean_absolute_error: 17.6046\n",
      "Epoch 302: val_loss did not improve from 17.82751\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.1130 - mean_absolute_error: 17.6046 - val_loss: 17.9749 - val_mean_absolute_error: 18.4681\n",
      "Epoch 303/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1730 - mean_absolute_error: 17.6641\n",
      "Epoch 303: val_loss did not improve from 17.82751\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.1730 - mean_absolute_error: 17.6641 - val_loss: 18.1282 - val_mean_absolute_error: 18.6214\n",
      "Epoch 304/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2140 - mean_absolute_error: 17.7089\n",
      "Epoch 304: val_loss did not improve from 17.82751\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.2140 - mean_absolute_error: 17.7089 - val_loss: 18.0744 - val_mean_absolute_error: 18.5671\n",
      "Epoch 305/500\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 17.4274 - mean_absolute_error: 17.9170\n",
      "Epoch 305: val_loss did not improve from 17.82751\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 17.2830 - mean_absolute_error: 17.7729 - val_loss: 17.8785 - val_mean_absolute_error: 18.3719\n",
      "Epoch 306/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1689 - mean_absolute_error: 17.6627\n",
      "Epoch 306: val_loss improved from 17.82751 to 17.81305, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.1689 - mean_absolute_error: 17.6627 - val_loss: 17.8130 - val_mean_absolute_error: 18.3071\n",
      "Epoch 307/500\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 17.4803 - mean_absolute_error: 17.9741\n",
      "Epoch 307: val_loss improved from 17.81305 to 17.76111, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 17.3795 - mean_absolute_error: 17.8734 - val_loss: 17.7611 - val_mean_absolute_error: 18.2565\n",
      "Epoch 308/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3394 - mean_absolute_error: 17.8319\n",
      "Epoch 308: val_loss improved from 17.76111 to 17.75915, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.3394 - mean_absolute_error: 17.8319 - val_loss: 17.7592 - val_mean_absolute_error: 18.2546\n",
      "Epoch 309/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5086 - mean_absolute_error: 17.9987\n",
      "Epoch 309: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.5086 - mean_absolute_error: 17.9987 - val_loss: 17.7662 - val_mean_absolute_error: 18.2615\n",
      "Epoch 310/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2074 - mean_absolute_error: 17.6963\n",
      "Epoch 310: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.2074 - mean_absolute_error: 17.6963 - val_loss: 17.7735 - val_mean_absolute_error: 18.2686\n",
      "Epoch 311/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0770 - mean_absolute_error: 17.5672\n",
      "Epoch 311: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.0770 - mean_absolute_error: 17.5672 - val_loss: 17.8133 - val_mean_absolute_error: 18.3074\n",
      "Epoch 312/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2832 - mean_absolute_error: 17.7726\n",
      "Epoch 312: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.2832 - mean_absolute_error: 17.7726 - val_loss: 17.8998 - val_mean_absolute_error: 18.3923\n",
      "Epoch 313/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0617 - mean_absolute_error: 17.5499\n",
      "Epoch 313: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.0617 - mean_absolute_error: 17.5499 - val_loss: 17.9553 - val_mean_absolute_error: 18.4480\n",
      "Epoch 314/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2653 - mean_absolute_error: 17.7587\n",
      "Epoch 314: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.2653 - mean_absolute_error: 17.7587 - val_loss: 18.0067 - val_mean_absolute_error: 18.5002\n",
      "Epoch 315/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1730 - mean_absolute_error: 17.6636\n",
      "Epoch 315: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.1730 - mean_absolute_error: 17.6636 - val_loss: 17.9228 - val_mean_absolute_error: 18.4154\n",
      "Epoch 316/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2555 - mean_absolute_error: 17.7495\n",
      "Epoch 316: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.2555 - mean_absolute_error: 17.7495 - val_loss: 17.9440 - val_mean_absolute_error: 18.4363\n",
      "Epoch 317/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1461 - mean_absolute_error: 17.6344\n",
      "Epoch 317: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.1461 - mean_absolute_error: 17.6344 - val_loss: 17.8765 - val_mean_absolute_error: 18.3700\n",
      "Epoch 318/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2153 - mean_absolute_error: 17.7107\n",
      "Epoch 318: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.2153 - mean_absolute_error: 17.7107 - val_loss: 17.8767 - val_mean_absolute_error: 18.3701\n",
      "Epoch 319/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1186 - mean_absolute_error: 17.6116\n",
      "Epoch 319: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.1186 - mean_absolute_error: 17.6116 - val_loss: 17.8338 - val_mean_absolute_error: 18.3281\n",
      "Epoch 320/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2926 - mean_absolute_error: 17.7834\n",
      "Epoch 320: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.2926 - mean_absolute_error: 17.7834 - val_loss: 17.7814 - val_mean_absolute_error: 18.2762\n",
      "Epoch 321/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3239 - mean_absolute_error: 17.8155\n",
      "Epoch 321: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.3239 - mean_absolute_error: 17.8155 - val_loss: 17.8706 - val_mean_absolute_error: 18.3643\n",
      "Epoch 322/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3078 - mean_absolute_error: 17.7968\n",
      "Epoch 322: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.3078 - mean_absolute_error: 17.7968 - val_loss: 17.9066 - val_mean_absolute_error: 18.3993\n",
      "Epoch 323/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2559 - mean_absolute_error: 17.7454\n",
      "Epoch 323: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.2559 - mean_absolute_error: 17.7454 - val_loss: 17.9323 - val_mean_absolute_error: 18.4248\n",
      "Epoch 324/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1870 - mean_absolute_error: 17.6777\n",
      "Epoch 324: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.1870 - mean_absolute_error: 17.6777 - val_loss: 17.9600 - val_mean_absolute_error: 18.4528\n",
      "Epoch 325/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.4937 - mean_absolute_error: 17.9847\n",
      "Epoch 325: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.4937 - mean_absolute_error: 17.9847 - val_loss: 17.8909 - val_mean_absolute_error: 18.3837\n",
      "Epoch 326/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0135 - mean_absolute_error: 17.5022\n",
      "Epoch 326: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.0135 - mean_absolute_error: 17.5022 - val_loss: 17.8830 - val_mean_absolute_error: 18.3762\n",
      "Epoch 327/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9807 - mean_absolute_error: 17.4739\n",
      "Epoch 327: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.9807 - mean_absolute_error: 17.4739 - val_loss: 17.9615 - val_mean_absolute_error: 18.4544\n",
      "Epoch 328/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1607 - mean_absolute_error: 17.6514\n",
      "Epoch 328: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.1607 - mean_absolute_error: 17.6514 - val_loss: 17.9899 - val_mean_absolute_error: 18.4834\n",
      "Epoch 329/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2449 - mean_absolute_error: 17.7376\n",
      "Epoch 329: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.2449 - mean_absolute_error: 17.7376 - val_loss: 18.0602 - val_mean_absolute_error: 18.5527\n",
      "Epoch 330/500\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 17.4933 - mean_absolute_error: 17.9842\n",
      "Epoch 330: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 17.2855 - mean_absolute_error: 17.7756 - val_loss: 18.0354 - val_mean_absolute_error: 18.5284\n",
      "Epoch 331/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1946 - mean_absolute_error: 17.6868\n",
      "Epoch 331: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.1946 - mean_absolute_error: 17.6868 - val_loss: 17.9788 - val_mean_absolute_error: 18.4722\n",
      "Epoch 332/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2909 - mean_absolute_error: 17.7820\n",
      "Epoch 332: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.2909 - mean_absolute_error: 17.7820 - val_loss: 17.9771 - val_mean_absolute_error: 18.4704\n",
      "Epoch 333/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9673 - mean_absolute_error: 17.4622\n",
      "Epoch 333: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.9673 - mean_absolute_error: 17.4622 - val_loss: 18.0484 - val_mean_absolute_error: 18.5410\n",
      "Epoch 334/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9961 - mean_absolute_error: 17.4851\n",
      "Epoch 334: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.9961 - mean_absolute_error: 17.4851 - val_loss: 18.0376 - val_mean_absolute_error: 18.5305\n",
      "Epoch 335/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9418 - mean_absolute_error: 17.4369\n",
      "Epoch 335: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.9418 - mean_absolute_error: 17.4369 - val_loss: 18.0129 - val_mean_absolute_error: 18.5063\n",
      "Epoch 336/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3218 - mean_absolute_error: 17.8164\n",
      "Epoch 336: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 17.3218 - mean_absolute_error: 17.8164 - val_loss: 17.9857 - val_mean_absolute_error: 18.4791\n",
      "Epoch 337/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1858 - mean_absolute_error: 17.6784\n",
      "Epoch 337: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.1858 - mean_absolute_error: 17.6784 - val_loss: 17.8946 - val_mean_absolute_error: 18.3872\n",
      "Epoch 338/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0327 - mean_absolute_error: 17.5219\n",
      "Epoch 338: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.0327 - mean_absolute_error: 17.5219 - val_loss: 17.9100 - val_mean_absolute_error: 18.4026\n",
      "Epoch 339/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9412 - mean_absolute_error: 17.4353\n",
      "Epoch 339: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 16.9412 - mean_absolute_error: 17.4353 - val_loss: 17.9913 - val_mean_absolute_error: 18.4848\n",
      "Epoch 340/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1494 - mean_absolute_error: 17.6394\n",
      "Epoch 340: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.1494 - mean_absolute_error: 17.6394 - val_loss: 17.9488 - val_mean_absolute_error: 18.4413\n",
      "Epoch 341/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0206 - mean_absolute_error: 17.5108\n",
      "Epoch 341: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.0206 - mean_absolute_error: 17.5108 - val_loss: 17.9472 - val_mean_absolute_error: 18.4396\n",
      "Epoch 342/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9929 - mean_absolute_error: 17.4852\n",
      "Epoch 342: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.9929 - mean_absolute_error: 17.4852 - val_loss: 17.9191 - val_mean_absolute_error: 18.4118\n",
      "Epoch 343/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3348 - mean_absolute_error: 17.8270\n",
      "Epoch 343: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.3348 - mean_absolute_error: 17.8270 - val_loss: 17.8627 - val_mean_absolute_error: 18.3566\n",
      "Epoch 344/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9031 - mean_absolute_error: 17.3958\n",
      "Epoch 344: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.9031 - mean_absolute_error: 17.3958 - val_loss: 17.7871 - val_mean_absolute_error: 18.2817\n",
      "Epoch 345/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.7188 - mean_absolute_error: 17.2096\n",
      "Epoch 345: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.7188 - mean_absolute_error: 17.2096 - val_loss: 17.8761 - val_mean_absolute_error: 18.3696\n",
      "Epoch 346/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.6316 - mean_absolute_error: 17.1229\n",
      "Epoch 346: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.6316 - mean_absolute_error: 17.1229 - val_loss: 17.9155 - val_mean_absolute_error: 18.4081\n",
      "Epoch 347/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1412 - mean_absolute_error: 17.6344\n",
      "Epoch 347: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.1412 - mean_absolute_error: 17.6344 - val_loss: 17.9442 - val_mean_absolute_error: 18.4365\n",
      "Epoch 348/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3112 - mean_absolute_error: 17.8071\n",
      "Epoch 348: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.3112 - mean_absolute_error: 17.8071 - val_loss: 17.9900 - val_mean_absolute_error: 18.4835\n",
      "Epoch 349/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9083 - mean_absolute_error: 17.4034\n",
      "Epoch 349: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.9083 - mean_absolute_error: 17.4034 - val_loss: 17.9055 - val_mean_absolute_error: 18.3982\n",
      "Epoch 350/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2477 - mean_absolute_error: 17.7360\n",
      "Epoch 350: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.2477 - mean_absolute_error: 17.7360 - val_loss: 17.9433 - val_mean_absolute_error: 18.4357\n",
      "Epoch 351/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9418 - mean_absolute_error: 17.4345\n",
      "Epoch 351: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.9418 - mean_absolute_error: 17.4345 - val_loss: 17.9325 - val_mean_absolute_error: 18.4251\n",
      "Epoch 352/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.5864 - mean_absolute_error: 18.0772\n",
      "Epoch 352: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.5864 - mean_absolute_error: 18.0772 - val_loss: 17.9186 - val_mean_absolute_error: 18.4113\n",
      "Epoch 353/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1744 - mean_absolute_error: 17.6682\n",
      "Epoch 353: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.1744 - mean_absolute_error: 17.6682 - val_loss: 17.9427 - val_mean_absolute_error: 18.4350\n",
      "Epoch 354/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2667 - mean_absolute_error: 17.7573\n",
      "Epoch 354: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.2667 - mean_absolute_error: 17.7573 - val_loss: 17.9199 - val_mean_absolute_error: 18.4126\n",
      "Epoch 355/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8960 - mean_absolute_error: 17.3879\n",
      "Epoch 355: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.8960 - mean_absolute_error: 17.3879 - val_loss: 17.9307 - val_mean_absolute_error: 18.4232\n",
      "Epoch 356/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0549 - mean_absolute_error: 17.5494\n",
      "Epoch 356: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.0549 - mean_absolute_error: 17.5494 - val_loss: 17.9803 - val_mean_absolute_error: 18.4736\n",
      "Epoch 357/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1060 - mean_absolute_error: 17.5997\n",
      "Epoch 357: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.1060 - mean_absolute_error: 17.5997 - val_loss: 17.9505 - val_mean_absolute_error: 18.4430\n",
      "Epoch 358/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0787 - mean_absolute_error: 17.5694\n",
      "Epoch 358: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.0787 - mean_absolute_error: 17.5694 - val_loss: 17.8311 - val_mean_absolute_error: 18.3254\n",
      "Epoch 359/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9879 - mean_absolute_error: 17.4800\n",
      "Epoch 359: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.9879 - mean_absolute_error: 17.4800 - val_loss: 17.8127 - val_mean_absolute_error: 18.3068\n",
      "Epoch 360/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9848 - mean_absolute_error: 17.4768\n",
      "Epoch 360: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 16.9848 - mean_absolute_error: 17.4768 - val_loss: 17.9136 - val_mean_absolute_error: 18.4063\n",
      "Epoch 361/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1806 - mean_absolute_error: 17.6738\n",
      "Epoch 361: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.1806 - mean_absolute_error: 17.6738 - val_loss: 18.0227 - val_mean_absolute_error: 18.5159\n",
      "Epoch 362/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9545 - mean_absolute_error: 17.4441\n",
      "Epoch 362: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.9545 - mean_absolute_error: 17.4441 - val_loss: 18.1260 - val_mean_absolute_error: 18.6191\n",
      "Epoch 363/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8962 - mean_absolute_error: 17.3865\n",
      "Epoch 363: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.8962 - mean_absolute_error: 17.3865 - val_loss: 17.9238 - val_mean_absolute_error: 18.4165\n",
      "Epoch 364/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8599 - mean_absolute_error: 17.3515\n",
      "Epoch 364: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.8599 - mean_absolute_error: 17.3515 - val_loss: 17.8492 - val_mean_absolute_error: 18.3433\n",
      "Epoch 365/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8923 - mean_absolute_error: 17.3819\n",
      "Epoch 365: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.8923 - mean_absolute_error: 17.3819 - val_loss: 17.8532 - val_mean_absolute_error: 18.3473\n",
      "Epoch 366/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1076 - mean_absolute_error: 17.6012\n",
      "Epoch 366: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.1076 - mean_absolute_error: 17.6012 - val_loss: 17.8957 - val_mean_absolute_error: 18.3882\n",
      "Epoch 367/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0821 - mean_absolute_error: 17.5748\n",
      "Epoch 367: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.0821 - mean_absolute_error: 17.5748 - val_loss: 17.8440 - val_mean_absolute_error: 18.3382\n",
      "Epoch 368/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0303 - mean_absolute_error: 17.5204\n",
      "Epoch 368: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 17.0303 - mean_absolute_error: 17.5204 - val_loss: 17.9245 - val_mean_absolute_error: 18.4171\n",
      "Epoch 369/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0346 - mean_absolute_error: 17.5284\n",
      "Epoch 369: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.0346 - mean_absolute_error: 17.5284 - val_loss: 17.9793 - val_mean_absolute_error: 18.4726\n",
      "Epoch 370/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2149 - mean_absolute_error: 17.7110\n",
      "Epoch 370: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.2149 - mean_absolute_error: 17.7110 - val_loss: 18.0243 - val_mean_absolute_error: 18.5175\n",
      "Epoch 371/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1715 - mean_absolute_error: 17.6639\n",
      "Epoch 371: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.1715 - mean_absolute_error: 17.6639 - val_loss: 18.1174 - val_mean_absolute_error: 18.6102\n",
      "Epoch 372/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0279 - mean_absolute_error: 17.5225\n",
      "Epoch 372: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.0279 - mean_absolute_error: 17.5225 - val_loss: 17.9062 - val_mean_absolute_error: 18.3989\n",
      "Epoch 373/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1065 - mean_absolute_error: 17.5988\n",
      "Epoch 373: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.1065 - mean_absolute_error: 17.5988 - val_loss: 17.8933 - val_mean_absolute_error: 18.3860\n",
      "Epoch 374/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.7725 - mean_absolute_error: 17.2633\n",
      "Epoch 374: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.7725 - mean_absolute_error: 17.2633 - val_loss: 17.9440 - val_mean_absolute_error: 18.4363\n",
      "Epoch 375/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9115 - mean_absolute_error: 17.3992\n",
      "Epoch 375: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 16.9115 - mean_absolute_error: 17.3992 - val_loss: 17.9324 - val_mean_absolute_error: 18.4249\n",
      "Epoch 376/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9052 - mean_absolute_error: 17.3997\n",
      "Epoch 376: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.9052 - mean_absolute_error: 17.3997 - val_loss: 17.9537 - val_mean_absolute_error: 18.4463\n",
      "Epoch 377/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0327 - mean_absolute_error: 17.5266\n",
      "Epoch 377: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 17.0327 - mean_absolute_error: 17.5266 - val_loss: 17.8134 - val_mean_absolute_error: 18.3074\n",
      "Epoch 378/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0655 - mean_absolute_error: 17.5573\n",
      "Epoch 378: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.0655 - mean_absolute_error: 17.5573 - val_loss: 17.8454 - val_mean_absolute_error: 18.3396\n",
      "Epoch 379/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9202 - mean_absolute_error: 17.4106\n",
      "Epoch 379: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.9202 - mean_absolute_error: 17.4106 - val_loss: 17.8982 - val_mean_absolute_error: 18.3907\n",
      "Epoch 380/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.2629 - mean_absolute_error: 17.7538\n",
      "Epoch 380: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.2629 - mean_absolute_error: 17.7538 - val_loss: 17.8905 - val_mean_absolute_error: 18.3833\n",
      "Epoch 381/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.7905 - mean_absolute_error: 17.2810\n",
      "Epoch 381: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.7905 - mean_absolute_error: 17.2810 - val_loss: 17.9816 - val_mean_absolute_error: 18.4750\n",
      "Epoch 382/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9021 - mean_absolute_error: 17.3943\n",
      "Epoch 382: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.9021 - mean_absolute_error: 17.3943 - val_loss: 17.9549 - val_mean_absolute_error: 18.4476\n",
      "Epoch 383/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9923 - mean_absolute_error: 17.4792\n",
      "Epoch 383: val_loss did not improve from 17.75915\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.9923 - mean_absolute_error: 17.4792 - val_loss: 17.8417 - val_mean_absolute_error: 18.3359\n",
      "Epoch 384/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9158 - mean_absolute_error: 17.4082\n",
      "Epoch 384: val_loss improved from 17.75915 to 17.75673, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.9158 - mean_absolute_error: 17.4082 - val_loss: 17.7567 - val_mean_absolute_error: 18.2522\n",
      "Epoch 385/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9471 - mean_absolute_error: 17.4410\n",
      "Epoch 385: val_loss did not improve from 17.75673\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.9471 - mean_absolute_error: 17.4410 - val_loss: 17.7836 - val_mean_absolute_error: 18.2784\n",
      "Epoch 386/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8795 - mean_absolute_error: 17.3716\n",
      "Epoch 386: val_loss did not improve from 17.75673\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.8795 - mean_absolute_error: 17.3716 - val_loss: 17.8125 - val_mean_absolute_error: 18.3066\n",
      "Epoch 387/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0888 - mean_absolute_error: 17.5818\n",
      "Epoch 387: val_loss did not improve from 17.75673\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.0888 - mean_absolute_error: 17.5818 - val_loss: 17.8206 - val_mean_absolute_error: 18.3148\n",
      "Epoch 388/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0345 - mean_absolute_error: 17.5216\n",
      "Epoch 388: val_loss did not improve from 17.75673\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.0345 - mean_absolute_error: 17.5216 - val_loss: 17.8498 - val_mean_absolute_error: 18.3439\n",
      "Epoch 389/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8844 - mean_absolute_error: 17.3731\n",
      "Epoch 389: val_loss did not improve from 17.75673\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.8844 - mean_absolute_error: 17.3731 - val_loss: 17.8234 - val_mean_absolute_error: 18.3176\n",
      "Epoch 390/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9654 - mean_absolute_error: 17.4577\n",
      "Epoch 390: val_loss did not improve from 17.75673\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.9654 - mean_absolute_error: 17.4577 - val_loss: 17.8374 - val_mean_absolute_error: 18.3317\n",
      "Epoch 391/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.7604 - mean_absolute_error: 17.2504\n",
      "Epoch 391: val_loss did not improve from 17.75673\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.7604 - mean_absolute_error: 17.2504 - val_loss: 17.7709 - val_mean_absolute_error: 18.2661\n",
      "Epoch 392/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9091 - mean_absolute_error: 17.4045\n",
      "Epoch 392: val_loss improved from 17.75673 to 17.74408, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.9091 - mean_absolute_error: 17.4045 - val_loss: 17.7441 - val_mean_absolute_error: 18.2397\n",
      "Epoch 393/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1566 - mean_absolute_error: 17.6463\n",
      "Epoch 393: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.1566 - mean_absolute_error: 17.6463 - val_loss: 17.7982 - val_mean_absolute_error: 18.2924\n",
      "Epoch 394/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9193 - mean_absolute_error: 17.4112\n",
      "Epoch 394: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.9193 - mean_absolute_error: 17.4112 - val_loss: 17.9184 - val_mean_absolute_error: 18.4110\n",
      "Epoch 395/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1920 - mean_absolute_error: 17.6837\n",
      "Epoch 395: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 17.1920 - mean_absolute_error: 17.6837 - val_loss: 17.8408 - val_mean_absolute_error: 18.3351\n",
      "Epoch 396/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.7790 - mean_absolute_error: 17.2670\n",
      "Epoch 396: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.7790 - mean_absolute_error: 17.2670 - val_loss: 17.7520 - val_mean_absolute_error: 18.2476\n",
      "Epoch 397/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9786 - mean_absolute_error: 17.4720\n",
      "Epoch 397: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.9786 - mean_absolute_error: 17.4720 - val_loss: 17.7816 - val_mean_absolute_error: 18.2765\n",
      "Epoch 398/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0377 - mean_absolute_error: 17.5306\n",
      "Epoch 398: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.0377 - mean_absolute_error: 17.5306 - val_loss: 17.8051 - val_mean_absolute_error: 18.2990\n",
      "Epoch 399/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.7216 - mean_absolute_error: 17.2127\n",
      "Epoch 399: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.7216 - mean_absolute_error: 17.2127 - val_loss: 17.8576 - val_mean_absolute_error: 18.3516\n",
      "Epoch 400/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0153 - mean_absolute_error: 17.5081\n",
      "Epoch 400: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.0153 - mean_absolute_error: 17.5081 - val_loss: 17.8683 - val_mean_absolute_error: 18.3620\n",
      "Epoch 401/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9662 - mean_absolute_error: 17.4584\n",
      "Epoch 401: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.9662 - mean_absolute_error: 17.4584 - val_loss: 17.8513 - val_mean_absolute_error: 18.3454\n",
      "Epoch 402/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0954 - mean_absolute_error: 17.5814\n",
      "Epoch 402: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.0954 - mean_absolute_error: 17.5814 - val_loss: 17.7831 - val_mean_absolute_error: 18.2779\n",
      "Epoch 403/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0237 - mean_absolute_error: 17.5156\n",
      "Epoch 403: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.0237 - mean_absolute_error: 17.5156 - val_loss: 17.8547 - val_mean_absolute_error: 18.3488\n",
      "Epoch 404/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8857 - mean_absolute_error: 17.3789\n",
      "Epoch 404: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.8857 - mean_absolute_error: 17.3789 - val_loss: 17.8487 - val_mean_absolute_error: 18.3429\n",
      "Epoch 405/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9690 - mean_absolute_error: 17.4598\n",
      "Epoch 405: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.9690 - mean_absolute_error: 17.4598 - val_loss: 17.8857 - val_mean_absolute_error: 18.3788\n",
      "Epoch 406/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9501 - mean_absolute_error: 17.4409\n",
      "Epoch 406: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.9501 - mean_absolute_error: 17.4409 - val_loss: 17.8617 - val_mean_absolute_error: 18.3556\n",
      "Epoch 407/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8951 - mean_absolute_error: 17.3855\n",
      "Epoch 407: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.8951 - mean_absolute_error: 17.3855 - val_loss: 17.8979 - val_mean_absolute_error: 18.3905\n",
      "Epoch 408/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9978 - mean_absolute_error: 17.4896\n",
      "Epoch 408: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.9978 - mean_absolute_error: 17.4896 - val_loss: 17.9077 - val_mean_absolute_error: 18.4004\n",
      "Epoch 409/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8926 - mean_absolute_error: 17.3852\n",
      "Epoch 409: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.8926 - mean_absolute_error: 17.3852 - val_loss: 17.8715 - val_mean_absolute_error: 18.3651\n",
      "Epoch 410/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8178 - mean_absolute_error: 17.3072\n",
      "Epoch 410: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.8178 - mean_absolute_error: 17.3072 - val_loss: 17.9874 - val_mean_absolute_error: 18.4808\n",
      "Epoch 411/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0752 - mean_absolute_error: 17.5645\n",
      "Epoch 411: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.0752 - mean_absolute_error: 17.5645 - val_loss: 17.9201 - val_mean_absolute_error: 18.4128\n",
      "Epoch 412/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9869 - mean_absolute_error: 17.4763\n",
      "Epoch 412: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.9869 - mean_absolute_error: 17.4763 - val_loss: 17.8971 - val_mean_absolute_error: 18.3897\n",
      "Epoch 413/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0741 - mean_absolute_error: 17.5634\n",
      "Epoch 413: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.0741 - mean_absolute_error: 17.5634 - val_loss: 17.8505 - val_mean_absolute_error: 18.3446\n",
      "Epoch 414/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9114 - mean_absolute_error: 17.4005\n",
      "Epoch 414: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.9114 - mean_absolute_error: 17.4005 - val_loss: 17.8765 - val_mean_absolute_error: 18.3700\n",
      "Epoch 415/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9583 - mean_absolute_error: 17.4500\n",
      "Epoch 415: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.9583 - mean_absolute_error: 17.4500 - val_loss: 17.8532 - val_mean_absolute_error: 18.3473\n",
      "Epoch 416/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8421 - mean_absolute_error: 17.3340\n",
      "Epoch 416: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.8421 - mean_absolute_error: 17.3340 - val_loss: 17.9262 - val_mean_absolute_error: 18.4188\n",
      "Epoch 417/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0268 - mean_absolute_error: 17.5202\n",
      "Epoch 417: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17.0268 - mean_absolute_error: 17.5202 - val_loss: 17.9173 - val_mean_absolute_error: 18.4099\n",
      "Epoch 418/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9795 - mean_absolute_error: 17.4674\n",
      "Epoch 418: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.9795 - mean_absolute_error: 17.4674 - val_loss: 17.8932 - val_mean_absolute_error: 18.3859\n",
      "Epoch 419/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0387 - mean_absolute_error: 17.5320\n",
      "Epoch 419: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17.0387 - mean_absolute_error: 17.5320 - val_loss: 17.7519 - val_mean_absolute_error: 18.2475\n",
      "Epoch 420/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.3605 - mean_absolute_error: 17.8555\n",
      "Epoch 420: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.3605 - mean_absolute_error: 17.8555 - val_loss: 17.8353 - val_mean_absolute_error: 18.3296\n",
      "Epoch 421/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8455 - mean_absolute_error: 17.3395\n",
      "Epoch 421: val_loss did not improve from 17.74408\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 16.8455 - mean_absolute_error: 17.3395 - val_loss: 17.7703 - val_mean_absolute_error: 18.2655\n",
      "Epoch 422/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9745 - mean_absolute_error: 17.4655\n",
      "Epoch 422: val_loss improved from 17.74408 to 17.73382, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 16.9745 - mean_absolute_error: 17.4655 - val_loss: 17.7338 - val_mean_absolute_error: 18.2294\n",
      "Epoch 423/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8372 - mean_absolute_error: 17.3259\n",
      "Epoch 423: val_loss did not improve from 17.73382\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.8372 - mean_absolute_error: 17.3259 - val_loss: 17.7582 - val_mean_absolute_error: 18.2537\n",
      "Epoch 424/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.7303 - mean_absolute_error: 17.2210\n",
      "Epoch 424: val_loss did not improve from 17.73382\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 16.7303 - mean_absolute_error: 17.2210 - val_loss: 17.8462 - val_mean_absolute_error: 18.3404\n",
      "Epoch 425/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9088 - mean_absolute_error: 17.3979\n",
      "Epoch 425: val_loss did not improve from 17.73382\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.9088 - mean_absolute_error: 17.3979 - val_loss: 17.7587 - val_mean_absolute_error: 18.2541\n",
      "Epoch 426/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9308 - mean_absolute_error: 17.4215\n",
      "Epoch 426: val_loss did not improve from 17.73382\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 16.9308 - mean_absolute_error: 17.4215 - val_loss: 17.8002 - val_mean_absolute_error: 18.2943\n",
      "Epoch 427/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8395 - mean_absolute_error: 17.3306\n",
      "Epoch 427: val_loss did not improve from 17.73382\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.8395 - mean_absolute_error: 17.3306 - val_loss: 17.8624 - val_mean_absolute_error: 18.3563\n",
      "Epoch 428/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9846 - mean_absolute_error: 17.4773\n",
      "Epoch 428: val_loss did not improve from 17.73382\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.9846 - mean_absolute_error: 17.4773 - val_loss: 17.8330 - val_mean_absolute_error: 18.3272\n",
      "Epoch 429/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9858 - mean_absolute_error: 17.4760\n",
      "Epoch 429: val_loss did not improve from 17.73382\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.9858 - mean_absolute_error: 17.4760 - val_loss: 17.8203 - val_mean_absolute_error: 18.3145\n",
      "Epoch 430/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9286 - mean_absolute_error: 17.4182\n",
      "Epoch 430: val_loss did not improve from 17.73382\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.9286 - mean_absolute_error: 17.4182 - val_loss: 17.8790 - val_mean_absolute_error: 18.3723\n",
      "Epoch 431/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8498 - mean_absolute_error: 17.3431\n",
      "Epoch 431: val_loss did not improve from 17.73382\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.8498 - mean_absolute_error: 17.3431 - val_loss: 17.8920 - val_mean_absolute_error: 18.3847\n",
      "Epoch 432/500\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 16.9849 - mean_absolute_error: 17.4757\n",
      "Epoch 432: val_loss did not improve from 17.73382\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 16.9889 - mean_absolute_error: 17.4796 - val_loss: 17.7733 - val_mean_absolute_error: 18.2684\n",
      "Epoch 433/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.1430 - mean_absolute_error: 17.6349\n",
      "Epoch 433: val_loss improved from 17.73382 to 17.72480, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 17.1430 - mean_absolute_error: 17.6349 - val_loss: 17.7248 - val_mean_absolute_error: 18.2203\n",
      "Epoch 434/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8928 - mean_absolute_error: 17.3822\n",
      "Epoch 434: val_loss did not improve from 17.72480\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 16.8928 - mean_absolute_error: 17.3822 - val_loss: 17.7698 - val_mean_absolute_error: 18.2650\n",
      "Epoch 435/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.6084 - mean_absolute_error: 17.0967\n",
      "Epoch 435: val_loss did not improve from 17.72480\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 16.6084 - mean_absolute_error: 17.0967 - val_loss: 17.7443 - val_mean_absolute_error: 18.2399\n",
      "Epoch 436/500\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 16.8613 - mean_absolute_error: 17.3507\n",
      "Epoch 436: val_loss improved from 17.72480 to 17.70038, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 16.7593 - mean_absolute_error: 17.2481 - val_loss: 17.7004 - val_mean_absolute_error: 18.1959\n",
      "Epoch 437/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8490 - mean_absolute_error: 17.3380\n",
      "Epoch 437: val_loss improved from 17.70038 to 17.67675, saving model to results/2023-01-27_AMZN-sh-1-sc-0-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 16.8490 - mean_absolute_error: 17.3380 - val_loss: 17.6767 - val_mean_absolute_error: 18.1732\n",
      "Epoch 438/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9518 - mean_absolute_error: 17.4382\n",
      "Epoch 438: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 16.9518 - mean_absolute_error: 17.4382 - val_loss: 17.7796 - val_mean_absolute_error: 18.2745\n",
      "Epoch 439/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0177 - mean_absolute_error: 17.5056\n",
      "Epoch 439: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 17.0177 - mean_absolute_error: 17.5056 - val_loss: 17.8414 - val_mean_absolute_error: 18.3357\n",
      "Epoch 440/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8712 - mean_absolute_error: 17.3622\n",
      "Epoch 440: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.8712 - mean_absolute_error: 17.3622 - val_loss: 17.8482 - val_mean_absolute_error: 18.3424\n",
      "Epoch 441/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9099 - mean_absolute_error: 17.4020\n",
      "Epoch 441: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 16.9099 - mean_absolute_error: 17.4020 - val_loss: 17.8450 - val_mean_absolute_error: 18.3392\n",
      "Epoch 442/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9767 - mean_absolute_error: 17.4678\n",
      "Epoch 442: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.9767 - mean_absolute_error: 17.4678 - val_loss: 17.8301 - val_mean_absolute_error: 18.3244\n",
      "Epoch 443/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8158 - mean_absolute_error: 17.3049\n",
      "Epoch 443: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.8158 - mean_absolute_error: 17.3049 - val_loss: 17.7925 - val_mean_absolute_error: 18.2869\n",
      "Epoch 444/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8269 - mean_absolute_error: 17.3196\n",
      "Epoch 444: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 16.8269 - mean_absolute_error: 17.3196 - val_loss: 17.8249 - val_mean_absolute_error: 18.3191\n",
      "Epoch 445/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8414 - mean_absolute_error: 17.3308\n",
      "Epoch 445: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.8414 - mean_absolute_error: 17.3308 - val_loss: 17.7816 - val_mean_absolute_error: 18.2764\n",
      "Epoch 446/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8887 - mean_absolute_error: 17.3775\n",
      "Epoch 446: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 16.8887 - mean_absolute_error: 17.3775 - val_loss: 17.7757 - val_mean_absolute_error: 18.2708\n",
      "Epoch 447/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9526 - mean_absolute_error: 17.4435\n",
      "Epoch 447: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 16.9526 - mean_absolute_error: 17.4435 - val_loss: 17.8000 - val_mean_absolute_error: 18.2941\n",
      "Epoch 448/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8683 - mean_absolute_error: 17.3614\n",
      "Epoch 448: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.8683 - mean_absolute_error: 17.3614 - val_loss: 17.8601 - val_mean_absolute_error: 18.3541\n",
      "Epoch 449/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8755 - mean_absolute_error: 17.3645\n",
      "Epoch 449: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.8755 - mean_absolute_error: 17.3645 - val_loss: 17.9134 - val_mean_absolute_error: 18.4061\n",
      "Epoch 450/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9243 - mean_absolute_error: 17.4138\n",
      "Epoch 450: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.9243 - mean_absolute_error: 17.4138 - val_loss: 17.9045 - val_mean_absolute_error: 18.3971\n",
      "Epoch 451/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8157 - mean_absolute_error: 17.3069\n",
      "Epoch 451: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.8157 - mean_absolute_error: 17.3069 - val_loss: 17.8430 - val_mean_absolute_error: 18.3372\n",
      "Epoch 452/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8125 - mean_absolute_error: 17.3005\n",
      "Epoch 452: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.8125 - mean_absolute_error: 17.3005 - val_loss: 17.7570 - val_mean_absolute_error: 18.2525\n",
      "Epoch 453/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9359 - mean_absolute_error: 17.4301\n",
      "Epoch 453: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.9359 - mean_absolute_error: 17.4301 - val_loss: 17.7373 - val_mean_absolute_error: 18.2328\n",
      "Epoch 454/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.7220 - mean_absolute_error: 17.2130\n",
      "Epoch 454: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.7220 - mean_absolute_error: 17.2130 - val_loss: 17.8044 - val_mean_absolute_error: 18.2982\n",
      "Epoch 455/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9418 - mean_absolute_error: 17.4332\n",
      "Epoch 455: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 16.9418 - mean_absolute_error: 17.4332 - val_loss: 17.9304 - val_mean_absolute_error: 18.4229\n",
      "Epoch 456/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.6259 - mean_absolute_error: 17.1140\n",
      "Epoch 456: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.6259 - mean_absolute_error: 17.1140 - val_loss: 17.8840 - val_mean_absolute_error: 18.3771\n",
      "Epoch 457/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.7401 - mean_absolute_error: 17.2306\n",
      "Epoch 457: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 16.7401 - mean_absolute_error: 17.2306 - val_loss: 17.8627 - val_mean_absolute_error: 18.3566\n",
      "Epoch 458/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8462 - mean_absolute_error: 17.3382\n",
      "Epoch 458: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.8462 - mean_absolute_error: 17.3382 - val_loss: 17.7804 - val_mean_absolute_error: 18.2753\n",
      "Epoch 459/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.7450 - mean_absolute_error: 17.2366\n",
      "Epoch 459: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.7450 - mean_absolute_error: 17.2366 - val_loss: 17.7572 - val_mean_absolute_error: 18.2527\n",
      "Epoch 460/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8374 - mean_absolute_error: 17.3284\n",
      "Epoch 460: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.8374 - mean_absolute_error: 17.3284 - val_loss: 17.7747 - val_mean_absolute_error: 18.2698\n",
      "Epoch 461/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.7907 - mean_absolute_error: 17.2825\n",
      "Epoch 461: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.7907 - mean_absolute_error: 17.2825 - val_loss: 17.8754 - val_mean_absolute_error: 18.3689\n",
      "Epoch 462/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8016 - mean_absolute_error: 17.2901\n",
      "Epoch 462: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 16.8016 - mean_absolute_error: 17.2901 - val_loss: 17.8960 - val_mean_absolute_error: 18.3886\n",
      "Epoch 463/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.7855 - mean_absolute_error: 17.2734\n",
      "Epoch 463: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.7855 - mean_absolute_error: 17.2734 - val_loss: 17.9043 - val_mean_absolute_error: 18.3969\n",
      "Epoch 464/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8238 - mean_absolute_error: 17.3148\n",
      "Epoch 464: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.8238 - mean_absolute_error: 17.3148 - val_loss: 17.8805 - val_mean_absolute_error: 18.3738\n",
      "Epoch 465/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0817 - mean_absolute_error: 17.5732\n",
      "Epoch 465: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 17.0817 - mean_absolute_error: 17.5732 - val_loss: 17.8409 - val_mean_absolute_error: 18.3351\n",
      "Epoch 466/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9748 - mean_absolute_error: 17.4655\n",
      "Epoch 466: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 16.9748 - mean_absolute_error: 17.4655 - val_loss: 17.7510 - val_mean_absolute_error: 18.2466\n",
      "Epoch 467/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8665 - mean_absolute_error: 17.3595\n",
      "Epoch 467: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.8665 - mean_absolute_error: 17.3595 - val_loss: 17.7350 - val_mean_absolute_error: 18.2306\n",
      "Epoch 468/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.7125 - mean_absolute_error: 17.2035\n",
      "Epoch 468: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 16.7125 - mean_absolute_error: 17.2035 - val_loss: 17.8848 - val_mean_absolute_error: 18.3779\n",
      "Epoch 469/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9579 - mean_absolute_error: 17.4488\n",
      "Epoch 469: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.9579 - mean_absolute_error: 17.4488 - val_loss: 17.8346 - val_mean_absolute_error: 18.3288\n",
      "Epoch 470/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8440 - mean_absolute_error: 17.3319\n",
      "Epoch 470: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.8440 - mean_absolute_error: 17.3319 - val_loss: 17.7869 - val_mean_absolute_error: 18.2816\n",
      "Epoch 471/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8016 - mean_absolute_error: 17.2940\n",
      "Epoch 471: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 16.8016 - mean_absolute_error: 17.2940 - val_loss: 17.7932 - val_mean_absolute_error: 18.2876\n",
      "Epoch 472/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8669 - mean_absolute_error: 17.3583\n",
      "Epoch 472: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.8669 - mean_absolute_error: 17.3583 - val_loss: 17.7841 - val_mean_absolute_error: 18.2789\n",
      "Epoch 473/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.7871 - mean_absolute_error: 17.2812\n",
      "Epoch 473: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.7871 - mean_absolute_error: 17.2812 - val_loss: 17.7716 - val_mean_absolute_error: 18.2668\n",
      "Epoch 474/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9967 - mean_absolute_error: 17.4864\n",
      "Epoch 474: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.9967 - mean_absolute_error: 17.4864 - val_loss: 17.7432 - val_mean_absolute_error: 18.2388\n",
      "Epoch 475/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9121 - mean_absolute_error: 17.4041\n",
      "Epoch 475: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.9121 - mean_absolute_error: 17.4041 - val_loss: 17.8317 - val_mean_absolute_error: 18.3259\n",
      "Epoch 476/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 17.0139 - mean_absolute_error: 17.5061\n",
      "Epoch 476: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 17.0139 - mean_absolute_error: 17.5061 - val_loss: 17.8341 - val_mean_absolute_error: 18.3283\n",
      "Epoch 477/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9390 - mean_absolute_error: 17.4322\n",
      "Epoch 477: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.9390 - mean_absolute_error: 17.4322 - val_loss: 17.8431 - val_mean_absolute_error: 18.3373\n",
      "Epoch 478/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.7692 - mean_absolute_error: 17.2589\n",
      "Epoch 478: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 16.7692 - mean_absolute_error: 17.2589 - val_loss: 18.0475 - val_mean_absolute_error: 18.5401\n",
      "Epoch 479/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9501 - mean_absolute_error: 17.4442\n",
      "Epoch 479: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.9501 - mean_absolute_error: 17.4442 - val_loss: 17.8365 - val_mean_absolute_error: 18.3308\n",
      "Epoch 480/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8923 - mean_absolute_error: 17.3812\n",
      "Epoch 480: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.8923 - mean_absolute_error: 17.3812 - val_loss: 17.7151 - val_mean_absolute_error: 18.2104\n",
      "Epoch 481/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9299 - mean_absolute_error: 17.4215\n",
      "Epoch 481: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 16.9299 - mean_absolute_error: 17.4215 - val_loss: 17.7779 - val_mean_absolute_error: 18.2729\n",
      "Epoch 482/500\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 17.0430 - mean_absolute_error: 17.5356\n",
      "Epoch 482: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 16.9367 - mean_absolute_error: 17.4287 - val_loss: 17.7882 - val_mean_absolute_error: 18.2828\n",
      "Epoch 483/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9659 - mean_absolute_error: 17.4595\n",
      "Epoch 483: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 16.9659 - mean_absolute_error: 17.4595 - val_loss: 17.7422 - val_mean_absolute_error: 18.2378\n",
      "Epoch 484/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8499 - mean_absolute_error: 17.3415\n",
      "Epoch 484: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 16.8499 - mean_absolute_error: 17.3415 - val_loss: 17.7981 - val_mean_absolute_error: 18.2923\n",
      "Epoch 485/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.7623 - mean_absolute_error: 17.2499\n",
      "Epoch 485: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 16.7623 - mean_absolute_error: 17.2499 - val_loss: 17.8868 - val_mean_absolute_error: 18.3799\n",
      "Epoch 486/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8549 - mean_absolute_error: 17.3491\n",
      "Epoch 486: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 16.8549 - mean_absolute_error: 17.3491 - val_loss: 17.8300 - val_mean_absolute_error: 18.3242\n",
      "Epoch 487/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8886 - mean_absolute_error: 17.3801\n",
      "Epoch 487: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 16.8886 - mean_absolute_error: 17.3801 - val_loss: 17.7789 - val_mean_absolute_error: 18.2738\n",
      "Epoch 488/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8203 - mean_absolute_error: 17.3082\n",
      "Epoch 488: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.8203 - mean_absolute_error: 17.3082 - val_loss: 17.8404 - val_mean_absolute_error: 18.3346\n",
      "Epoch 489/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8483 - mean_absolute_error: 17.3412\n",
      "Epoch 489: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.8483 - mean_absolute_error: 17.3412 - val_loss: 17.9315 - val_mean_absolute_error: 18.4240\n",
      "Epoch 490/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8740 - mean_absolute_error: 17.3656\n",
      "Epoch 490: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.8740 - mean_absolute_error: 17.3656 - val_loss: 17.9221 - val_mean_absolute_error: 18.4147\n",
      "Epoch 491/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8523 - mean_absolute_error: 17.3417\n",
      "Epoch 491: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 16.8523 - mean_absolute_error: 17.3417 - val_loss: 17.8856 - val_mean_absolute_error: 18.3787\n",
      "Epoch 492/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.7898 - mean_absolute_error: 17.2791\n",
      "Epoch 492: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.7898 - mean_absolute_error: 17.2791 - val_loss: 17.9136 - val_mean_absolute_error: 18.4063\n",
      "Epoch 493/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.7875 - mean_absolute_error: 17.2788\n",
      "Epoch 493: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.7875 - mean_absolute_error: 17.2788 - val_loss: 17.9046 - val_mean_absolute_error: 18.3972\n",
      "Epoch 494/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8808 - mean_absolute_error: 17.3727\n",
      "Epoch 494: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.8808 - mean_absolute_error: 17.3727 - val_loss: 17.8476 - val_mean_absolute_error: 18.3418\n",
      "Epoch 495/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.7753 - mean_absolute_error: 17.2688\n",
      "Epoch 495: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.7753 - mean_absolute_error: 17.2688 - val_loss: 17.8831 - val_mean_absolute_error: 18.3763\n",
      "Epoch 496/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8618 - mean_absolute_error: 17.3539\n",
      "Epoch 496: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.8618 - mean_absolute_error: 17.3539 - val_loss: 17.8490 - val_mean_absolute_error: 18.3432\n",
      "Epoch 497/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9170 - mean_absolute_error: 17.4087\n",
      "Epoch 497: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 16.9170 - mean_absolute_error: 17.4087 - val_loss: 17.8603 - val_mean_absolute_error: 18.3543\n",
      "Epoch 498/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.7706 - mean_absolute_error: 17.2609\n",
      "Epoch 498: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.7706 - mean_absolute_error: 17.2609 - val_loss: 17.8455 - val_mean_absolute_error: 18.3397\n",
      "Epoch 499/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.8696 - mean_absolute_error: 17.3611\n",
      "Epoch 499: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 16.8696 - mean_absolute_error: 17.3611 - val_loss: 17.7202 - val_mean_absolute_error: 18.2156\n",
      "Epoch 500/500\n",
      "9/9 [==============================] - ETA: 0s - loss: 16.9285 - mean_absolute_error: 17.4187\n",
      "Epoch 500: val_loss did not improve from 17.67675\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16.9285 - mean_absolute_error: 17.4187 - val_loss: 17.7537 - val_mean_absolute_error: 18.2493\n"
     ]
    }
   ],
   "source": [
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "# train the model and save the weights whenever we see \n",
    "# a new optimal model using ModelCheckpoint\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    \"\"\"\n",
    "    This function plots true close price along with predicted close price\n",
    "    with blue and red colors respectively\n",
    "    \"\"\"\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(model, data):\n",
    "    \"\"\"\n",
    "    This function takes the `model` and `data` dict to \n",
    "    construct a final dataframe that includes the features along \n",
    "    with true and predicted prices of the testing dataset\n",
    "    \"\"\"\n",
    "    # if predicted future price is higher than the current, \n",
    "    # then calculate the true future price minus the current price, to get the buy profit\n",
    "    buy_profit  = lambda current, pred_future, true_future: true_future - current if pred_future > current else 0\n",
    "    # if the predicted future price is lower than the current price,\n",
    "    # then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, pred_future, true_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    # add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load optimal model weights from results folder\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "# calculate the mean absolute error (inverse scaling)\n",
    "if SCALE:\n",
    "    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
    "else:\n",
    "    mean_absolute_error = mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 16:30:50.610377: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-27 16:30:50.677268: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-27 16:30:50.769215: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 44ms/step\n"
     ]
    }
   ],
   "source": [
    "# get the final dataframe for the testing set\n",
    "final_df = get_final_df(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 128ms/step\n"
     ]
    }
   ],
   "source": [
    "# predict the future price\n",
    "future_price = predict(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we calculate the accuracy by counting the number of positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future price after 15 days is 155.87$\n",
      "huber_loss loss: 17.676748275756836\n",
      "Mean Absolute Error: 18.1732234954834\n",
      "Accuracy score: 0.5303030303030303\n",
      "Total buy profit: 71.61048126220703\n",
      "Total sell profit: 168.3034896850586\n",
      "Total profit: 239.91397094726562\n",
      "Profit per trade: 1.8175300829338306\n"
     ]
    }
   ],
   "source": [
    "# printing metrics\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
    "print(f\"{LOSS} loss:\", loss)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
    "print(\"Accuracy score:\", accuracy_score)\n",
    "print(\"Total buy profit:\", total_buy_profit)\n",
    "print(\"Total sell profit:\", total_sell_profit)\n",
    "print(\"Total profit:\", total_profit)\n",
    "print(\"Profit per trade:\", profit_per_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ee8556f0>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAACx9klEQVR4nO29ebwcVZk+/vRyu++9Se693ITkckkCiCiLLBEUowyCRCEgoOCCk1G+Dl8ZHXAhMw4yftHZFHVcZsAoOuNPxhFcGBUBRxDZ4hICCURW2QwQCEmAkNzcvZf6/VF9qk6dOufUqaW7qrvf5/O5n+7bS/Xp6qo673ne533enGVZFggEAoFAIBAyhHzaAyAQCAQCgUAQQQEKgUAgEAiEzIECFAKBQCAQCJkDBSgEAoFAIBAyBwpQCAQCgUAgZA4UoBAIBAKBQMgcKEAhEAgEAoGQOVCAQiAQCAQCIXMopj2AKKjX69i6dSvmzZuHXC6X9nAIBAKBQCAYwLIs7NmzB6Ojo8jn9RxJWwYoW7duxZIlS9IeBoFAIBAIhAjYsmULFi9erH1NWwYo8+bNA2B/wYGBgZRHQyAQCAQCwQRjY2NYsmSJM4/r0JYBCkvrDAwMUIBCIBAIBEKbwUSeQSJZAoFAIBAImQMFKAQCgUAgEDIHClAIBAKBQCBkDhSgEAgEAoFAyBwoQCEQCAQCgZA5UIBCIBAIBAIhc6AAhUAgEAgEQuZAAQqBQCAQCITMgQIUAoFAIBAImQMFKAQCgUAgEDIHClAIBAKBQCBkDhSgEAgEAoFAyBwoQCEQCISo2LoJWLcGqNfTHgmB0HFoy27GBAKBkAnc/PfA078DFh4KHHhi2qMhEDoKxKAQCARCVEzvtm93b0l3HARCB4ICFAKBQIiKWsW+Hd+e7jgIhA4EBSgEAoEQFXUWoLyQ7jgIhA4EBSgEAoEQFfWqfUsMCoGQOChAIRAIhKiosQBlR7rjIBA6EBSgEAgEQlSwFM8EBShdgVoVmNqV9ii6BhSgEAgEQlQ4IlkKULoCPzgH+OqhwMRLaY+kK0ABCoFAIERFvWbfzowBlal0x0JoPp7/A1CZAF5+Ku2RdAUoQCEQCISoYCkegFiUbkB1xr61aumOo0tAAQqh+ajXgVv/GXj0prRHQiAkixoFKF2FaoMlq1OA0gqQ1T2h+XhuA/CbLwPzDwJefUraoyEQkoFleVfSVGrc2ajXgNps43413bF0CYhBITQfe563b5ktOIHQCeDZE4AqeTod1Wn3PqV4WgIKUAjNx8SL9i2JCAmdBHEVTSmezgbTnwCU4mkRKEAhNB9OgDJp0+IEQiegLjAolOLpbPALLKue3ji6CBSgEJqPiUafEqvmp8UJhHZFjRiUrgKf4iENSktAAQqh+Zh80b1fmUxvHARCkvAxKBSgdDR4BoVSPC1B6ABl7dq1OP300zE6OopcLofrrrvO8/z4+DguvPBCLF68GH19fTj00ENx5ZVXel4zPT2NCy64APPnz8fcuXNx9tlnY/t2okc7FhMUoBA6ECIbSCmezgavQSGRbEsQOkCZmJjAkUceiTVr1kifX716NW666SZ8//vfxyOPPIJPfOITuPDCC3H99dc7r7noootwww034Nprr8Wdd96JrVu34qyzzor+LQjZxgTXip6EsoROgUjzT7xAGqtORpUYlFYjtA/KypUrsXLlSuXzv//973HuuefihBNOAACcf/75+Na3voW7774bZ5xxBnbv3o3vfOc7uOaaa/CWt7wFAPDd734XhxxyCO666y684Q1viPZNCNkFMSiETgQLUAol2x+jMgnMjgPleemOi9AcVHgNCgUorUDiGpQ3vvGNuP766/Hcc8/BsizcfvvteOyxx/C2t70NALBx40ZUKhWsWLHCec/BBx+MpUuXYt26ddJtzszMYGxszPNHaBPUa8Ak11iLGBRCp4CleMoDQGmufZ90KJ0L8kFpORIPUK644goceuihWLx4MUqlEk455RSsWbMGxx9/PABg27ZtKJVKGBoa8rxv0aJF2LZtm3Sbl112GQYHB52/JUuWJD1sQrMwuRMAR3vPTqQ2FAIhUTCRbKEHmLO3fZ8ClM5FlRiUVqMpAcpdd92F66+/Hhs3bsRXvvIVXHDBBfj1r38deZuXXHIJdu/e7fxt2bIlwRETmgq+ggcgBoXQOWBlxvkeYO4i+343CWXFMutOh8cHhQKUViDRXjxTU1P4+7//e/zsZz/DaaedBgA44ogjsGnTJnz5y1/GihUrMDIygtnZWezatcvDomzfvh0jIyPS7ZbLZZTL5SSHSmgVeIEsQBoUQueAaVDyBWDuQvt+tzAo138UeOQG4IJ7gLl7R9tGvQ7segrY6wAgl0t0eE0B+aC0HIkyKJVKBZVKBfm8d7OFQgH1uu28d/TRR6Onpwe33nqr8/yjjz6KZ555BsuXL09yOIQswBegEINC6BDwKR4WoHRLP54/3QFMvQy88Ej0baz9V+DyZcDD1yU1quaCUjwtR2gGZXx8HE888YTz/+bNm7Fp0yYMDw9j6dKlePOb34xPfvKT6Ovrw3777Yc777wT3/ve9/DVr34VADA4OIjzzjsPq1evxvDwMAYGBvDRj34Uy5cvpwqeTsTES97/iUEhdAqYSLYbUzwze+zbOEzCzift2633AYe9M/6Ymg2+iidLVveWBfz4/cDsJPAXP2kPNsoQoQOUDRs24MQTT3T+X716NQDg3HPPxVVXXYUf/vCHuOSSS7Bq1Srs3LkT++23Hz73uc/hwx/+sPOer33ta8jn8zj77LMxMzODk08+Gd/4xjcS+DqEzIFSPIROhVNmXOyuFI9lATPj9v04TALbf3vkxRGZQ1Z9UGYn7HQbYF9v2bHYAQgdoJxwwgmwNGZEIyMj+O53v6vdRm9vL9asWaM0eyN0ECjFQ+hU8AzKnC4KUKozbnorTm8tJ0B5Pv6YWoFKRjUo07vd+zN7OipAoV48hOaCVfH09Nu3xKAQOgWOSLbIpXi6IEBh6R0g3kTNWIi2YVAy6oMyw/mC8cFKB4ACFEJzwVxkh5bat7MUoBA6BCqRbKfb3fMTYtYClHv+E7jjC835DbIqkp3mfo+ZzjIxpQCF0FywFA8LUCjFQ+gU1DgGhRm11WaB6V2pDakl8DAoCWhQZsZcTUscWBZw098Dd1wGvPBo/O2J8PigZEgkywcl/G/TAaAAhdBciAwKpXgInQKeQenpBXoH7f87Pc3jCVAS0KAAybAolSmg1ug4/NyG+NsTkVUfFD6tM00MCoFghiq3miQGhdBp4EWyQPeUGs9ybEesFA8foCQglOUDp+c2xt+eiMymeASRbAeBAhRC88CaBOYKwLxR+z4xKIROAe8kC3RPJU/SIlkgGQaFH9ezTWBQKm0gkiUNCoFgCFbB0z8fKDe6vVKA0jl4eh2wc3Pao0gPjg8KY1C6JUDhRbIxJmp+kt+zNfp2GGa5AGX7Q8mztVn1QfGkeKiKh0AwAxPIzlkA9PTZ9ynF0xl4+WngqlOB751h91TpRvhSPF1id88zFUn4oADJMyhWDXj+D/G3yaM6497PVIBCIlkCITyYQHbOAvJB6TS8/JRdybDrGeDZe9IeTTpwRLINv8uuYVCSSvE0UYMCJJ/myWo3Y0rxEAgR4AQoe7sMCvmgdAamXnbvP3J9euNIE06ZsSCSbRfjsajIrAZFKFVOWihLItmWgwIUQvPAUjz9PINCKZ6OAO/18cj1nW9OJgPvJAt0j5ts0j4oQEIMSoM96NvLvk261DirDAqf4qEyYwLBEI4GZW9viqcbJ7NOA8+g7Hom+Xx/O4D3QQGAeSP27Xg3MShxNCjcJD/2fPzrAhvXfm8CkLOPy/EXtG8JBY8GJUM+KJTiIRAigJUZz5nvpnisWjxhHSEbmNrl/V+X5pl6GXjx8aYOJxU4IlnGoDQClIkXOvsYb4YGpTbjDXqjgPmzDC4GFrzKvp9UmseyhCqeDAnDSSRLIESAjEEBSCjbCWApHjYRPKxJ81xzDrDm9XblTydBLDPun+8GK0mmebLGODZDgwLE16GwcZXnAfsebd9PKkDh2RMgYykecpIlEMKDD1AKPbZhG5BugLLpB8AP3pdM749uBlvtHvFeoFACXnpc3v/Esuz0j1UHdjzc2jE2G2KZcT7PmbUllOb5/deBL70C2PZgMttLAolrUHL2TVwdChtXaS6wmAUoCelQqoJ2Lg2R7OyEnQoTx8H7v8zuyRa7ExMUoBCah4lGiqd/AZDLAaU59v9pCmXv+gbw6P8CT96a3hg6ASzFM7QUeMWJ9n1ZmmfqZffiPpaAGVeWIIpkAVeHsichu/sHrgWmdgKb1yazvSSQdIrH2WcJBSgig5IEAyUyKGloUP77LODfj/Syc7KUzmznpHkoQCE0B5Up90SZs8C+dczaUmRQ2IVm1zPpjaETwBiUvr2AQ0637z8sCVB2P+veT6JSI0twUjyyACWB71qvu9qdLO27pIzaWJpkcLF9m1iAMgAseg1QKNvpj5eejLddwL+oSiPF89ITtlbnxcfcx1h6p9hrM5lAR6V5KEAhNAfMAyXf43Z5zYKbbI0ClETANCi9Q8DBp9npu+0PADv/5H3d2HPc/Q5jUMQUD5Bsw8Cx54DKhH0/KwFKveaOCUiGQRnY175NTIMy104p73Ok/X8SOhTeAwVIJ8XD9tcEV5nEqnbKA/Yf0FFCWQpQCM3BJOcim2vkmJlQdnZC/p5WgE0qnRKgVGfSyTlPNVZufUNA/zCw5Fj7/2fu8r6OZ1A6LUARy4wBYN4+9m0SxmMvcpqerJi/zQrarVgaFJFBifkd2djK8+zbfV9r3yZRAi8GKFYK5xz7TLb4A1y2pHfA/d4dVGpMAQqhOeBt7hmyYNbGUjxZqCjZ+ad4FPnULuCrhwLXvCexIRmhXgNmWIDSMMVacJB9+/JT3tfyDEpWWICkIJYZA8C8BBkUXnQctO9efAK44mhg43/F/1wdxNV5EgzK0FL71vT4eOxXwB1f9GtLeA0KAAwfaN/uSuBcr4gMSgoaFBbQ8QwKS/H0DtpBCkAMCoEQCN5FliELGhSeQUmzfPNPdwKXLwNu+lT0bWy9z2aqnvpNa78LX9bI0nd77W/figHKbj7F02EBCpsw+ABlboIaFD5ACTIyu/e/bI3CQz+N/7k6+AKUBJoFMgbF5PiY2gVc+3+AOz7v77XDKvNKjc7pLPBJgi3NQhWPaYqngzoaU4BCaA74PjwMWWBQmAalMgFM7kxvHC/80b59el30bexsiP+q061dNTGBbGmem95QBSg8gzKzO930XtKQpnhYP54EGBReDFmZ0P/Gj91s3za711WiDIqQ4hnfHjzx3/d9VwPDs1T1uivKZxN1kgGKyKCkIZK1ZAwKn+JhDAqleAgEPXgPFIZMMCiz7v0kqN+oYKucnU9G15Ds3Ozen0jQ0jsIrMS4b8h9TMmgPOv9v5NYFJlIlmlQJnbEW2VblhvEMqg0Gjs3u3qVZp9b4uQX9TvW6wAajNC8fYBc3p6AeX2F7z014O5vu/9PcQsMXhvDUjxDS+zb6V3xK1uyJJLl7ftnKMVDIISHw6DMdx9zfFBSClBqVa+4LQsBSnUa2L0l2jb48slWBijTrMR4yH2MBSjj291VfL3uCmN7Gr/9ng4SysrKjOfs3Zhs6/F+k4kXG0xVDhgM0Gg8/iv3frMZKtHgMCqDwr+vUHIN7nSpscdu8p6zk5IAJV8EimX7fnmeq5GKeo4xpC2S5RcxMg1KmRPJUpkxgRAARu2znDyQfpkxz54A6Vby8CvRqH1qdnIBSis76DIGpXfIfaxvL6Dc0KOwSWTihUYaJAeMHmU/FqaS56HrgCdvizXUpkLGoOQLLmsYpyqFMSJDS4HhAxrbU0zeLL0DtIBBEVbnUUXefICSLwIDrPpJE6Dc9U37lvl98AwKL5BlVYNAcmke55rV2HarRbL850mreAapzJhAMAabpNjFFUg/xVMT3CDTDFD4Vc5LEQKUes2bTploZYAiYVByOWCv/ez7bFxjjfTOvBFgsEG3mwYoEy8B//NB4Mfnxh1t8yBzkgW4rsYxdChMILv3q4GBUfu+bPKeGbdF0gxRGJQwKUZn8os5UfMajnyRK89WBCjbHrS/Z64AHPXn9mOTigCFR1IBCmNQGAvc6hQPv79mdrvViB6RLJUZEwjBqFWBXQ1KdWg/93HHByWtAEVY7bUzg7L7WS8jlGRb+SA4GpS9vI+LOhRWwTOwr36SlWF8m02jz4ylk+83gSOSFQIUp5InBoPCApQFr+LcaSXb23ynfRyw1fPsRLiKrk0/AC5bDDx5u9nrWSDAgtPIGhSeQSnovyMArL/Svj3kdGDkcPs+3/3Y6cMjBCiDTQpQWi2SFfczY1GozJhACImxZ+0TuFByV0ZA+lU8Yj+NdmZQ+PQO0FoGhXeR5SEGKCzNN8gFKKYMCj/5iKm5rKDGGJQe7+NOJU8CKZ69X+2eQ7J9x9I7B5/WeMDy6yV0eOo3dlXMH280ez0LrNlvH1mDwk24uYKeQZl4ye5JBABv+AjQN2zfbyWDUkmZQRH3M9OhyKp4qMyYQNCATVBD+9kdXhmcACUtBkWiQUnLC8XDoDwR/v1if5GWalC4Pjw8fAxKI8UzsDiYwhfBTz5iYJkVyMqMAZdBidPR+IVGifHeB6vZBctyBbKHneU+HoahZKzi9ofMXu8wKI3fPqoPCptwc3n7GqFjULbcZQddC15tOxb3NwIUlQaFR2IpnsaiqietFI+QhmMMitTqnlI8BIIabIJiExZDVkSy5QEAOTtQ0pU1NhP8KmfPVn91RBBYiTGjsFv5PWRlxkAAg8JYAMMAhZ98MsugSESyQPyOxtNjbrXTglcB81h6TJi8t91vB3w9c4ADjreb4wHeXjlBYAHG9ofNgnVWLeMEKDGreJh+Z57m+GDnxsA+ttZJxqA4Nvdzve9lpcZxq3hEBqXlKZ4gBoVSPAQVxrYCN3/a3yitWxEYoKTMoJTmuimHtNI8ToqnITZ8KSSLwlI8Sxs9cLKW4rEsrwaFTbLj293UiA7tkOJxnGQL3sfnxWRQmEHb3EV2EMh3SOYFrSy984oTgJ5eoBRB48WCrJndfs8aGdjkx1iMyBoUwYV3bqPMWHYcs4CLOcQ6DMrLblDlMAmiBqURoEy+FH4RwIOlzVgA1PIUj6hBYQEK06BQmTFBhfuuBtZ9Hfj9FWmPJBtgfW7EACVtH5RqY6Ir9HDUbwpeKLWKSxnv/Wr7NmyAwlI8S99g37ZUJKtI8QwusSn76rQdiDgMymJ7AsoVGmZcBsFUJ6R4ompQeIEs4HZIrle8zNITv7ZvX/U2+5alH8JU8vArc5M0jy/FE5NByTWCOza5ysbOHmMpYj69xJgTJ8Uz4H1v35DbjiEOi5K6SFZkUHZ4ryPUzZigBDtJwk4ynYqsp3iK5XQDFH6FM9rouBqmkocvMV663L6d3dO6/apK8RRLtt4EsM8FpjcZ2NdbqWHUc6UNGJSgFM/49mguwbxAFrD3q+Ot0th31Vlg6yb7/v5/Zt8yBiVMioevbNsRIUCJ7IMisE+MHZFVITFGiAUHPf1uOosFsmIfHh5OJU+MAKUialBa7IMiBkQTL3qvI+UBN8VTm8luUB8SFKAkAXaw8tbj3QwnQNnP+3jqItnGSVsohRfP3fvfwMarkhkHs6fumcMxKCEClN1b7NVjoWyLKNnFulVCWRWDAgDD+9u3W9bbwr580aXvHaGsQSVPOwQojpOsyKAsBJCzn+cZD1PwAlkGUUS642H7eO4dBIZfYT8WpYyfF7kaMSiNSTFpDQobOyx/oM0WgCxAyeX8QlmVSBZIZjHCJnyniqfVTrKSFA9LtZbm2qXufHDWIWkeClCSAFtF7H62YyLXyJje7V40hsQApcGgpO2DUii5YzMJUGYngRs+Dtx4UTJW4nxp4IKD7PthGBSW3tlrf3sF6uTvW5Dmqc64tLKoQWFjAoCnfmffzht1V8lhhLKeFE9GAxSHQRF8UAo9QH+jxUOUNA/rwcNSPIC/1Hjrffbt6DLXOZVNUKEYFD7F83Dw630pnpg+KL4ABf5zrCIwKIBfKGsUoMTQm4kalNR9UF7wVvAA9nnGfGA6pJKHApQk4KxCrHS9NbIApj/pn+9SjgxZ8UEJy6BM77IvSFbd39U0CnhzpfmNAOWlJ81LnpkYe/6B9i2j/1sRoLD0Ti7vz/cDboCyZb19y8TIAFeNEpZByWjQr3KSBTi2KGSAUpl2V/qMXZNtb+u99i1LEQLRRLI8g/LiY/oFlmW5qZS4DIoliGTzeU5DI4hZRQ0K4BXK8u8Rq3iAZCp5fCmeFJ1kAW+Kh2lsgI5zk6UAJQnwFHS3V/Ko9CeAN8WThv+Io0ERAhQ2lsd/DWz4rv99fElwEpMlv/LZa39bKFiZMDcxY8cYo/ZZgNKKFA+bEHoHvR43DOx3ZxPG4L7uc2EYlKyXGVuWWiQLuGZtYSt5XnrcDoTLg644FvD7yPAMCkOUFCqvIbFqbgWRDNUZ9zvHTvGwAIU7hhhDIjIo7H8Pg9L4fIdBEdgEHkkyKKWUNCiyMmO+goehw0qNKUBJAjxN2u06lF2KCh7ATfFYtejiujhgE12hZFeWOBUnO2zB4Q/eC9z4Cb8JmidASWCy5FM8xZK7r0x1KGx8LECZyxiUFgQoqhJjBvF3H+ACFFMGxbK8DEoWUzz8ClrGoESt5NnRSO8sPMTb9I4vNa5MuemYfXkGJUYVT64xFeh0KPykx1btcY3a+H0XJkCJpEFJMEBJK8XjiJNn3bJwPijrsFJjClCSAH+SEoNi3+oYFCBcnjwpOCmesr3qZZPnS48D133EvWiKTd5YWgNIZrIUV3thdSjMA8VJ8TQ0KK0oNdYJZAFgrwO8/w8udu+b2t3PTngDwSwyKPw5r2NQQgcojcBj4SHC9jgGZduD9gQ5Z6E3AHREshGqeBY00knbH1S/lh23pXluR+GkNCgAF6AIKR7GCPHXD58GRVPFwwKUiReip5crog9KSiLZ0lxXZ8KuA54UT2e5yVKAkgR4NuDlDmdQ7rta7/fC29yLKPS4vgdp6FBqAiXPLlz/+0l3YgC8AQnQXAYFAOa/0r41KVOvVV2dz3AjQNGZXCUNVYkxQ99e3hUdP4E6Acrz+hSfWPki2+ebf+PuhzTAn/NimTHgBhRhUzwvcAwKjwFOg+LoT5Z5WZYoPkMs0NrnSPtWJ5R1WIq5bmCRVBUPoB7/rCT4CMOg9A65k3rUUmPR6r7VDIqj2SkAcxbY99n1glI8BEzuBH5+IfDMev9z/EnayQxKdRa44WPAr/6f3cBLBh2DkstxF6E0ApQGg1JslOWyAIUFJ4wVYGkMhqQDFB+D0qjWMGFQ+BJjNvk7ItkW2N2zfaNiUHI5b3k5r0Fhk3ZlQr/C49M7gF+4+dKTwH+9Hbj2/5iMuDnwdOOVpXgYgxLS7j6IQRnfATx7j32fT+8A0VI8LD09epR9a5LiKc9LIECRuPAqUzysikfBoNSqnGGZJEDJ5eKneXzNAlutQWnsr1zBPd9ZqpdSPAT88Ubgvv8G1knYA37Sevnp7LaHj4s9W90TU5aiqdfcC4AsQAHStbt3NCgCgwIAh78beMWJ9v2mMyiCuI2leEw0KIzWHT7AFRgyBqWlItkh9Wv4336AS/GU+l06WieUnQxgUFjaREzFJYlf/yNwz3+qn/cEKAX/81Hs7mcn3AB/4aHe5/oXNIICC3j8FvsxXiALRBPJMgZl5HB3vKrFh1MpIwQoUQTv/ITLoErxBGlQZjm2QBagAO65vjtigOITyabkJJsvugEK06BQiofgTCqylT9P99YrZj0t2hH895KJXPc8b08m+aKX2ueRppusY3XfYFBYie/cRcDKL7lpCx+Dwv2faIAy5B3Hri3B+4WJsFl6B+AYlFameBQMCuAGKIWyS0czmAhlRQZF3OdssmiWNmX3c8Bvvwr86jPq1/AusnyahYE3VjOdwJnFff8C/37L513hLTsexQAlTi+evr3c303lKOthULjAIspkLU3xcG6yPBwNisIHhY2r2CvXAwFuqXEUBqVWcVMsbIxxUjzP3w/cdIk/ENdBluJB47jiUzwUoHQp2EkvuyiKdF+n6lBY8zdAvh+YJmBwie1sKEMUIZ8Ms5PAn+4IJ1bjq3gA4NAzgbdcCrz/OntFxgIGHYPSDJHsnAV2WSksdwWtwo5H7Nv5r3AfYyLZqZebXx3liGSH1K9hE93AqH/yNik1FjUoYoqH/Y7NClBYkFjVBIu6EmPATfHUZv0BlwrstxXTOwws6AFsZooxZwxsAo/SzTjfAyw8zL6v0qHwDfn47x0l3SELUGTXBsvyO8kCXh8Unf6EIU6Kh1808GOIKpT9/eXAXd8AHrnB/D187yK2IGEocwwKC1YoxdNlYCe9rBMrmxRYqV6n6lDGeAZFFqA8Zd+q0jtAcmZt668EvncmcOcXzN/D+6Cw2+P/FljUoNOVDEqTRbK5nFvtwgeBIqZ2AQ9ca9/f703u4317uVR5s83agsqMAWDx6+3bfY/2PzdgwKBMmjIoTQrG2GRg1dWTELsOyASygK1zYvvINPX2QogAZd9l/ucjMSjMrr8ILGIBiqKSh2/IxwcWSQUoMg1Kdcb+HQC5BmVmzA0AZRU8DE6AEkEky443wGWAgeg6FPb7hLkGsuMwLwlQpAwKiWS7C1oGpXGhZBNzp3qheBgUyeRgFKAkpEFhn3XPd8xZDZFBEWHCoCRt1MbAxKRjmvTg+m/Z7114GHDQye7j+XzrzNqCyowBYJ8jgE88CLzzSv9zLMWjDcSCApQmMyj1ivy+5zVsgpXoTxjYhKljYngEMSi8Ky/vIOt8XhQfFI5BYYH61k3ywIxNeqW5QoASIVC0uAmXQZbi4e97UjxDABrsHGNFdAzKYIwUDwtQxBRS1DSPEwCHeL80xdMAOckSnAlVdjKKXgIdm+LhJk+ZJbaqSSCPpBgU9vmTLwJ/NKRKeR8UGYwYlARW7SKDAgQzKNNjNi0M2KyP6OLqmLU1uZInqMyYYWiJPP3B7Nsf/rk69RGU4mETRlSBZhD431j1eweleAC3Wsy0P5cToBwqf55nUET9CRAtxcOX3u97tM3EbX8A+NFf+FfhsioeIKYGJaCKh32XQtmbNs4X3InZCVAkLrIMLLiLIqyucAFKLqb2BnC/e5j3y0SyDPz3pjLjLgU7aWQXLCdAaYgdO5VBGQvSoDxl37aCQeFpV5k9vQyiD4oIIw1KkxgUJipWCazv+U87cJp/kK2dEcF0KM0WygaVGQfh0HfYXXqndgJ3fkn+Gha4sIZ74jnnMXFrQpqHp+5V7AAvklWh2Gvf8scqw9PrgKd+6/4/vds9v/guxjxYqTHglgXzCJviqdfgCC3zPXYa5B3fsIOBR38B/OdbvelqZoZWnmenJdlk3cwUj6yCh4HpUJj2TdaHh8H5nazw2hHGgBV7vQFVXAYlzH7jq55E7ZEnxUNlxt2JikGKh/lZ7NycTq+ZqKjXgLv/w7XZViGoisckQIliJiUDHyg89Ru3Rb0Oog+KiFZoUKoz7oQlY1BkKZ7ZCWDd1+37x/+tPK3QjBRPvQ5891Tge++w7/MW9DoNig6FInDy5+37d39b/rux6gZWtSKm1fgJvxlpHg+DophE6px2QwUVg1KrAFe/G/ivM9wAgJ1780bV7BQzP5x/kDxADFtmzH9PFrQfeQ7wwf+19/0LjwDfPtEdIy+SBeJ5oZg6yToeKJIAhelQWHsNXYqHZxzDBhbs9+tJikGphR8Hzzj5NCh8iqdxn1I8XQYtg9I4eOa/EkDOpiVb4UmRFB79JfC/fwvcfIn6NTPj+nLb2Ul39W7EoMRN8TQmKZau2WjAoog+KCJkDIplJRug8CsbKYMiSfFs+P+AyZdsG/nXvEu+XSfFk6BIduIF4OnfAX+6HXhqrX0OsAtlUIpHh1eeBLxqpb2tX33a/zxL8TC7eF+Kh/u/GQFKsxmUyqTt3WHVgLsbXitBAlkAWLoceNu/2CyHDDwDYbJAUtn1Lz4GOP8OYNHh9jm/8Sr7cV4kC7jBRRQWS2fUxgdYFQMGxUSDEkfUy65Vxb745dX854dhcnjNTt9ebkFGLu8VBzsalD2tt+NvAihAMYUuQGEnemmOK8ZqJx0Ks86eVBg0Ad70DuCfGCYb2odCSU//J5biaUxSR7zbvt10TXDQI/qgiGCTbm3G3dbsuHelE3dC5PuZ8Bc7RyT7nHdyqVXd1gJ/tlq9Ynf68STJoHDH+qYfuOxJoeTtixIFJ3/Ontwf/5XdRZoH+xyHQRHOOU+A0owUj4kGRcIAiFAxKPz/9/23HfwHCWQBmwV440eBJa+XP+/8JpY8rSRCZ9c/sI/N1gG2Xsiy/OW8DoMSRYOiM2qTpHhkxxtjUNi1SVfFE4f5cESy5UZqqzFttjTFw5UZ5wtu+pOl2xgcVtaCz/CuDUEBiim0IlluZT68v32/nUqNtz1g31Y0FzVRG+HTBTT+Z6tGFXpC5slVYBeNV58GDC61V3oPXad/j1NmrAhQygPuhYyxKDx7AsT3QZG1SAdcBqU67Q0UX37KFvb19ANHnKPebjP68fC/8cM/55wrh+TmZGEw/0Dg2L+y7998iTtp1OtugDJPkeKpNZlB4dM6qknEEcnqAhQFg8L/PzMG3P9DtcV9GPAsg0klT5Ab7kFvtVmDl58Cnv+DtxcP4H73xFI8rIqHT/EYMCiMXdCJZONoR9hihS2uHO1NC6t4HMapsb9YmodP7wANnUwj2OwAoSwFKKbQlRnzngjDDQOtdhLKbmv4HujKIX0BimJVqKtqAJKv4in1A0efa98PSvMEpXhyOfeEZ+ksMUBJikERL6bFssuC8Pua2d/PP9D1b5GhGf14+AClOuVS/VEFsiLe/Hd25cmLj7l9iGbG3AmHBShiUNj0FI8BgxLkgwKoGRRxIbD+W2YMShDyBTcoMglQgtxwS3PsIAWwA1Qlg5KSSJYxKAzGKZ6IGhS2b1mwE7cPUZhxWEJKjJUal4UAJZfrqFJjClBMoTNq41dTrN18uzAokztd0ywdgxKU4qkFpE8YovQLkYFX1h/e0GU8u0GfdzUZI0vzqBiUuD4oshJjBj7Nw8AmbmaHr0Iz+vGIbOGDP7Fv4+hPePQOAgsbFSusiy/Tn/T0uxdanw9Ks1M8BhoUozLjAAald9BmDV58zNUOMauCqAhzfpl8B1Yx9vB1mgAligbFMECpaESy/UKgrKviyXFTXegARWBQ2JjTSPE4AQpjUCTXkQ5yk6UAxRRaBoWd6CW7iRvQPhoUlt4B9KyGKN5UlX7qVvlAgiJZriJnYF8AOfuCIXpoyN6jMmoDXKGskkGJOSGqGBRALpRlDMqCgACFXbAmX0yukRn7TXvm2Bd4NhElxaAAwN4NxoAFKMxFtm/Y/Z1UbB0/xiTBL0KUDIqJSJYxKGKA0hh/317AUavcx4f200+yJnAmeYMAxYQFetXJdkC/80/uIs0RycZIdYiMAOD6uFSn3W2ydI9Og8KgY1DiaEcqnAYF4FI8EUWovFOx8Xvq3s9WpXgAr1C2zUEBiglqVfciWa94RYyW5XVjdFI8bcKg8LbW2hRPwyLaUe4rVrW6yR9I3geFuTsy0ZjOiMnRyWjGGMSgyHxQfv91874aWgalIbBm+xoAXnzCvg1iUPoXwA7S6uGakOnAJrA5C9xOz0D0EmMZmHGbw6BwTrXsWBJTPLVmMyi8k6xKgyKZYEU4DIqiTLrYC7z+fPfxOOkdBodBMdGgGOhoyvOAV67wPwa4gU2kFI+migdwWRSnzFgSuImBsi5AAaKnpKpcFQ/glizHZlAiGrUBbvpTDNIArtR4t/+5NgMFKCYQT3YPBczdLxRdP4upl/Upk6yAZ1DqVbXvA0s7sJ4WUVM8SfugsFUNa86mDVCSYFCE7/3y03ap7I2rg0bs3Z6MQZGmeBo+IQteqd9uoeiKBpMSyvKanaP+3H08qRQP4E7KO4QUT/9e7m+rTfE02wclCSdZRYqnWLZ/VxYALHpN+LGKCGPWZsICAcBh73DvF0ru90pag1IsuwyBE6AwDYqEQekXJudSQIASVdzK+6B4thNXgxLi/SLjdOT7gGPOA5b/tf+1xKB0GcSTXXUBy/d4I/24k3ArsO1B7/8yFsWy3LQD09iknuLhVqGAmQaDT8WpEKhBESZElrIxLeljr5dRs2KKZ+plt3x7fkCAAnBusgl5odS5/XXwae7KLNEUT4NBeekJ+/dh7E/fsDv5q5oFyp5LAia9eEL5oGgYFAA4/d+B41YDb5BMNmHBrj+hGJSAAOVVJ7vnDM9SJB2g5HL+fjw6H5QwKR7+s6JW8RQFDYoY6Pz4A8BVbw9O/USq4uHKjAGbQXn7V90GjzxIg9JlEAMN/qIomh0VetyLVtYDlOqsS60zyFifqZfdwIWZsKm8HQJTPAmIZGtV94R1AhQDBiWOBoVdnFSredNUgzbFw9xkGwEKS+/MGw2++AKusj+pSp4aN4n09AHHfND+f5+jktk+YKe1SnPt82jnn4QUj4GPSFNSPLzvTZwy4wANCjt2BxcDKz4LzJkffqwinDJ+kyoeAy8XwA6mD3yLfZ9fgLHVvGof6aBqtii6yTo+KJoyY4bAAKUx3cXxQQHcMfMBRr1uVzo99ZvgBUKkFI9BSpEhKoNyxxeBNW9ofj+vEKAAxQTiyc6vGPiTkwUmUdqeB2Hn5uTEjwwvPmZfaMuD3GQgYTaYJmLOQlfEp/JBMdWgxNk3vAYhFIMS4IMCSBiUxi1zavWVvLLGdRUz984ZTYqHMShjW+3f2hHIGrAngLtvk+gXBPi7P5/0WeDjf7BX1Ekhl3NbRLzwRy7Fw4tkU0zxKBmUGGXGIoOSJMJce0wZFMCt5uE76cZiUJgzqhAclYQAS2d139PvTSkHCYyjpniUPigcU8LvgyBmhO33UGXGku7PKrDjKkzFYa1iG0K+8Ajw3L3m72syQgcoa9euxemnn47R0VHkcjlcd911vtc88sgjOOOMMzA4OIg5c+bgda97HZ55xm1zPT09jQsuuADz58/H3LlzcfbZZ2P79ghdJlsFEwYlV3Aj9ChdRXV4/NfA5UcBv/6HZLbHwASyiw5z86syBoWlHAb3dS8IPg1KWAYlRoqHv+CH0qAE+KAAagaFqeZ16QaTC/W0JsUzb8Q+jqwasGebeYkxg6rqJSrECSyftxm0uCZtIngdyhRXxVNUBCjNNmpLzElWZXXPUgYBeq0oCHPtMdWgAMDh7wHecqnbRwlwj4s4KZ6cgkFh11ydBiWX87IoOidZIIZIVvRBYUyMohw9aPuxevEEsF0AlxoNwS4+e4/dfgGIVjbeJIQOUCYmJnDkkUdizZo10ueffPJJHHfccTj44INxxx134P7778ell16K3l53tXDRRRfhhhtuwLXXXos777wTW7duxVlnnRX9WzQbor7Ao0GRTHpJ6SwYWBrmpSeT2R4DE8iOHO6mMGQMCks5DOyrXtWasBOAN8UTtaEi26/5HndFESpACcGgsFum7/CVvIbsrKsrM84X3LbwY8+ZlxgzOL9NQheYoO7PSYGv5HE0KCmmeGqKiYdHKJGsYvypMygGDQ8ZCkXb+n7pG9zHktagAH43WUeDogg+mA6lNDeYXZClZkzAey4Bci2Lh3ULYlBipHjEgE4G1Xmjw5O3ufebcU5FhMGR6cXKlSuxcuVK5fOf/vSnceqpp+JLX3JbqR944IHO/d27d+M73/kOrrnmGrzlLXZe87vf/S4OOeQQ3HXXXXjDG97g22bqMBHJ8quQpFM8TiflhFbGDE6A8hrg8ZsbnyVjUBopnsHF6ui8KqQDVGDBm1WztxEkqpVBRpEHpXjqde6CHEGDwqht3/cWBZsBPWpUVvcMA/va+3v3s+Ylxgyq4DEqwqyw44D3QmGTev+w5lhrJYOimHxN9BtBRm09TQhQwmi84v6+cRxVlQGKYNam68UDuAxKEHsCxEjxCL+XbDuq+zLEMmoLw6CEODcyGqAkqkGp1+v4xS9+gVe96lU4+eSTsXDhQhx77LGeNNDGjRtRqVSwYoVbW3/wwQdj6dKlWLdunXS7MzMzGBsb8/y1FOLJLqPz+FVI0ikep1Fhghdjy+JSPK/RMyhOimexhkEJmeIBou8fscQYCGZQ+PFG8UFhAZBuNR8mxaPqG8JKjXc9DexsMGamGhT2vRLXoLSIQXnxcVeg18eXGafYzVi1/cwyKEIVjA5hNCgyxGJQFKJPX4Ci0aAAbkWZiYg8qrGcsyBiVTwykSw3JwRqUCJU8ThlxgZTtqo8X4XJnV7dSTuneHTYsWMHxsfH8YUvfAGnnHIKfvWrX+Gd73wnzjrrLNx5550AgG3btqFUKmFoaMjz3kWLFmHbtm3S7V522WUYHBx0/pYsWZLksIMhnuw1Ca3PT8xNY1ASPHD2bLOb0uXytgZAp0HxpHhYdC42cDMsMy70uCuQqCkwHYMy9bJ8gubHG4lBYRoUHYMSIsUj06AAbiXPM3fZ+7RQdg3cgpB0iifuBGaKwSV2UF+vuGxd37BX7+Tp8NzsFE/SZcYig9JEDYooMtXB+Q6hifTG+2JoUJwJV/hstrhzqngat6oAhTEoYQKU0CkeFYOi8MPS7Y963RW8Ni3FE3Kh8qc7APDnVxOC/ohInEEBgDPPPBMXXXQRjjrqKHzqU5/C29/+dlx55ZWRt3vJJZdg9+7dzt+WLVuC35QkfCJZyQWMv1Al1W+GgQU6sgNuz3a7PGzs+XDbZOzJglfZaRctg9JoXudhUFQpnoCLbi7HCeGiBigSBqVvL/c3kJX58eM18UGpTtvjYwGFE6AoAjPxvgyVafc1yhRPI0B56rf27fxXmin3geRFsq1K8eTzwN6v8j7Gp3j4sQACa9WMMmNFlZ7sNVon2RQYlFC9eBj7mwaDElRm3Bi/rhcP4GpQTFoExK3i8TUL5Kp4PHOCZn9YIVJBPMRuxjqEXag8eav3/05N8SxYsADFYhGHHnqo5/FDDjnEqeIZGRnB7Owsdu3a5XnN9u3bMTIyIt1uuVzGwMCA56+lMNGgeFI8CQcoTqNCyYGz8bvAHZ8H7vmPcNvcdr99y9wrVQxKvWaXvQJ2gKKiD8WSVB3i2t07K5o+97FcTp/mYZOCqnMrQ2me27Nj97PuaieJKh6nu2hO7XrJUjxs5Wia3gGaKJKNoBMKC6ZDYegd8gagfNCVhTJjk8nd1KgtScga7qmQlAYlyvFmokGpVdzfV6lBaXjHqFKmPHQB1e5n1b4h4u8lTfEYBh5hypF5yHoXqaBKjUq3awFP3m7f71fo7FJEogFKqVTC6173Ojz66KOexx977DHst99+AICjjz4aPT09uPVWN2p79NFH8cwzz2D58uVJDic5iFoJWYqnmSJZnQaFpSDCugYyB9mRRoCiYlDGt9snR75oBwAq4aJpigeIX+UkY1AAN82zRxKgmFYZ5fNu+uXlp+3bQsllPHw+KCEmS0d/Mk+dS2ZeKAymAlk2TpNxmMLEjCwpMB0K0PDlKXoDI7bf63WzMuA48DAocVI8WWdQktKgRPBnMjFq44MslQj21SuBfY8Bjjwn+DNVKZ6x54F/PxL4/rvk7xMXRFKRrGEVj2kqSPW+UAyKwXXgxcfsFH6xF9j/OPP3tQihrzzj4+N44oknnP83b96MTZs2YXh4GEuXLsUnP/lJvPe978Xxxx+PE088ETfddBNuuOEG3HHHHQCAwcFBnHfeeVi9ejWGh4cxMDCAj370o1i+fHk2K3gAiVGbZIXlKTNOWiSrqeJhF7uwVDdjRVhzQxWDwtI78/axT/Ag8ywjBiVEnlwG1QpUx6CEEXz2Dtlall1PNf4fhNL/JYwGRWfSxsA0KAymJcZAE0SyLWRQ+EZ5LM2WL7i+MGy/61JsScHE6t5IJJuCD0qoXjwhJj0ZYvmgKFIWvMiXXR/yRfXCZ/6BwIdulT8nQpaaAexrXL0KbLnLPu/FVg5iN2NZ9RJ/7uuYEU+AEkWDYsApqJpsyvBEY9/t90Z3EdbOItkNGzZg2bJlWLZsGQBg9erVWLZsGT7zmc8AAN75znfiyiuvxJe+9CUcfvjh+M///E/85Cc/wXHHHeds42tf+xre/va34+yzz8bxxx+PkZER/PSnP03oKzUB2hSPhOpN2gdFl+JxLtwhDyqHUWhcRHsUDAoLUNjKPsgHxWQyYwzFHrkoOhCi9TSDrtTYtJkh4E6QjEHpHTRzNQ06sYNKjAGbsuYDr0gMisGxYHJstkqDAngZFN58S6Srxck+TIAyPQb87nJg1zP61/G6k1hlxilW8STZi0eFJKp4fEZt3OIlSH8SFqomf/z/z270v89XxSPxQTEWyXLvserq16neF4pBMViosPLiA9/inuftnOI54YQTYFmW7++qq65yXvOXf/mXePzxxzE1NYVNmzbhzDPP9Gyjt7cXa9aswc6dOzExMYGf/vSnSv1JJuBL8UiM2pqa4mEMiuRi7AQoIVeSoglXURFUMTZiYB/v68Xo3DSFAgBLXm/fPvUb8/HyiMKgmPq0AG4lz66n3f9VrqZhTMOCSowBWx/Dp3kiaVACLkxb7gYuWwL85iv617WqzBgABpe6zBrfBE4MunzHXYiL6QPXArdcCvzmq/rXGTEoSfig9CFx9IRhUJLyQWmSBoXpsGR9eKJAleLxBCh3+9/nWN2zKh7mJKuwutcGKBFTPKE0KIYLlcq0K8Y/8KTkNWwJgHrxmMDHoEis7puZ4mErCRllF5dBYQelk+IRApSZxkWCTarKVEeIFM8rTrBv/3RHNDfZIA2KLsVjopHRMSjVGe+YQ6V4AkqMGZhQdu6i4NfyMM09b91kH7fPbtC/Lm6VRxjk825PHp5iF0sm4zAozEZ/JkCvpepWziNMiqde8a6cVcdvEghTZhxXY5SIBkWR4qlMBHughIWK8eEDli1CgFKvuftJ64NimLqJneJJ0El22/02Yz5noZ1ijWLw1mRQgGICn1GbJPfIn2itFMlWIwYoYnm0I5IVJgDRh0CZ4gmhV1jyBvt1Y89Fs+8PZFBkKZ4QAZSPQeECFFjeC0uYMmNdJ2MerNQ4THoHMF8BsX0RtIKTsYPNBNOh6FI8qtSiCdh+Cdo/dcXEI9uWSYoH8E4WonV6knAWRwatJEwaHuoQxwfFxKhN14cnClRlxvz4n9voZUb46yH7PWXbMbW6D6rimXpZnmZqhkiWpZwH9rGZ2yg9fJoMClBMwE4URu15GBSZBiXpMuMWpHhUIlkxD6ys4gmxKiz1A0uOte//6XbzMTMoGZSEUjyOm2xjxe0JUCCUvEYoMw4qiZzfEC4vOlT/OhEqzYMIU9atlSJZADj8XXaq59VcKw1fikdkUEJcTJ3AzLDbrG77JuwSr3fix90KBgVWsM4oVQ2KQYonqA9PWLDKOVH7wR8PM2Nu7zPAez1kKTnZ9zYtHw4Kfq+7APjPtwBb7/M+HspJ1jBAERd67FxrZ5FsV4IFKGxlLfVB4S7iSQYo9Zp7IFk1/8VVtbIMgpjiUZUZi70wkhDJAt40T1iIojUGXiQrrh5DiXiHhP8HBU8O7rtH0aAEMSjHnAe89Z+B41YHDtUD0xWQU7Ib1HU1RDO5JPDKFcBFD9iCPQZfiicBBiXoApyUk2yh6E5mVUlQKx6/ScDTSiLg+hPbSdbAB2XL3cCaN7heGwwqTQXvJBvUhycsVAGVeE3ldSjst+IbkwameEw1KBKR7FijKIFVWYpjDMOgBC1UKkKAwrZNKZ6MYsvdwH+/E7j+Y97H2YnOVtZSkWyTUjw+F1tR+2E42YgwZVBmhVWMspolYoDy1G/C57CDNCjVKb/pUhiGh/3ODL2D3t+XnyR9zQI1MGVQ+oeBN33MFSabwlQkGzbF0yoGRQZxNRhHg1I1/N6hnGQDJgyZULaZDEq+4AY+QTqUxJxkNefvo78EXngE+OON8s/WimSbVcWjSfEAwJZ73PuydLIjko0ZoMiYFha0iEFfFKv7wIWKkGp03heBEWsSWrQ0ag9Ys5PIPXkb6gsOxvSs+yP1zU4gB6BWHkABwGxlBtXG88XZGZQAVHNFzDYey+fK6AVQr0x6thMJE2Oe/riTU1OA5V5QytUZFADUqjOYCfFZfbVZ5ABM1fOwZqso5EooA6jNTnq2U54ZRwHATL6M2mwVuXoefQCs2iym+NdVp1EAMG0VUDcZx4LXoK88gNz0bkw/sxH10dcaj71nZhI9ACq5EiqezyqjrzQXudlxTL28FdZ8d88VZqbt75crBu6nQnEA/NQx2zMP1UoNfYUycrUZTE1PwSrb2yhX7P0PADOzM6hptl2afBlFALPFuc7xkyTyVtE+7qqz2uOuZ3YaPQBqtYp2X5Qqs/Z4rXxTxmuCcr7HPv5mplCbrSI/MwleuVGrzBof96XKDIoAalX9e8rVivObVqszznkte82Mldf+5n2FMnIYx9TUBKzG6/oqU/a5ZxWdx5JEX08/ctUpTE3ugTVHcxxUZuzzyCoI55EZeqy8/f7qrPL9PbNT6AFQrXj3Y2+tijyA6XrOe73I9drXu3oVsxM77WtrsU/6G4RFGXn7N6tUPL9ZYXYWZQAWcsjBQn3Leuf8yU2N29e7Yq9zvSshb58XlYpzXhRmZpxrxsxsRXlM5GZmwHizeq3iO097axXkAczMznq2Ua6x4y2nPd4AIGcVG9foGc81WkRxetLev4UyZmerKFoF+3/ht+rrKSCnc99uIihA4TBdGkIfgJdeeB6v+8zNzuOPlsdRzgG/e7aG4wvAv930EL7xC/v58woP4tIe4IYHX8BF99mPHZx7BjeVgZdeftmznShYmtuOtdxsedznb8ZOuCvwX5ZewiF54OEtL+L0EJ/1aHkG5Rzwlq+tw/N4DKfmH8U3SsCGJ5/He7nt/Kj0LI7NAxf97An8709uxt54Gff0AvXKDA7lXvfL0k4ckgf+79UP4LeG5f3f6nkVTi5swOX/8Z/4Ru3M4Dc08KXik3hPEfjq7c/gm7/2fufbSnPxivw4zr38RtxtueZf7y3chy/2ALc9sRsfCthPb8w/jms40uBvrn8KN1x3Mx4o5zEvB6z86q/xlGWzG9eVtuOoxoLq0z+5D//zYzU7ck3PU3hjAfjbG57C9T+Pd1zIsDz/EH5QAh7buhOnaL7jPxWfwAeKwENbXsIZmtd9u+dZvK0AfPYXj+MH1yc/XhP8sDSBN+SB1dfcg1/UCzgpvxHf4X6b3z26FR8wPO6/0rMZZxeADZtf9BzjIn5WehHLGr/pL/+wBR/d4H/ttaUdeF0e+NiPH8TNdXUK4vdlC6M54F1fvwMPWbbo+pHyJPpywFuvuBvPWpuNxh4Gvy3nsDgHnPP1W/GHxmfK8PniZvx5Ebj8jqdwxa3hf9+PFp7C3/QAP17/FD79O/n72bF23can8bd3ua+5qbQLB+eBv/zeffg9l0YrooonGhHoD2/bgA8Uge/f+xL+4e74x9+3el7CyQXgH39+P675qbu9M/L34fIS8Eh9KQ7NP438S49j+Wd+gt2Yi6NyT+C6MvDchIXjGsfMv/XswDsKwBf/9yF854abG9vYiMsbx+XF196H634kZ32OyD2J6xvX82deHMcJwnF4a2k3DswDn7r2XvyM28Z/9+zAnxWAv/vJQ/j5tfp9sQC7saEXyNVmcehnbgIgDy4+VPgDPt0D/PyhnfibTTfjLwqP4196gFsefBYfuc/9jIf/6WT0l9IJFSjFw6NRPbAX9oB1dyyghnLOjiYZl1GES831NO5XLZd6m2zE0v2I7+gpbqMEL23Xg6pvTCZg76s21orTsM+uXngp837YFCf7TpVGTFvIWcjDjUTYuGYt8wP5d/XDAABvzD8YauzlnP1Z9vrPixcwBADYO7fb8zj7vhWDmHy35b24jMH+f7bx3h5uX5e534N9hgrzcjZlvQcJ5dQFVBrHoHiMiGDj7Ak4ZtgxVYUBrdwksOOJfaeSsI+DvoP3tVXPrQpF7nnVedVjuG9mGmyne5xYzv1pqzmps0mrcf3J6a8/7u8bbfKpNb57QfMbsN9N3OeFxrWjZnn3XxVFZ58taJzDU0gmFVZrTHf8dcseiz3+F60B/Klu+3Ety9tu6bLfSrYdfh8UoF6hFQNexx4r5mrSx+sGU/Ys93vqzg/23dj+dq9v2Unx5CwrihFFuhgbG8Pg4CB2796daONAqzKF3OfsA3Ry9Z9s7cH0GPq/egAAoHLUuejZ9F+ovHE1Kid8GgBQ/O2XUVp7GSpHnYvKqQ0DqPHt6L/8UFjIYeqSF/TN6QKQf/Ye9H7vFOf/qY9shLXX/s7/vd94LfK7nkZ9+JWY/vB6s43Wa+j/gq3XmLzoCaBvL+Q334neH5xlp7fO/527/SuPRX7nE5j+ixtQX/pGYGYP+r9if/7kJ591lO29a5Yhv/sZTJ97E+r7vs5oGLkXH0Pft5fDKpQxtfpJY+Oq0v98AMXHfoHZU76M6ms/6H3up3+J4h9/jtm3fh7V1/2V83jx7m+i9Ov/h+ph78Lsmd/Sj2vX0+j7hptyYt+p9/LDkB/fhqm/vA3WyJH2977y9cjvtEulZ9/2RVSP+b/K7bLXOvsyYeS33oveq96K+uASTF+wSfm60vUfQfHBH6O+4NWYPv/3yteVrzkLhafuxMwZ30TtNe9JfLwmKP/4z1F44mbMnPrvqB31Fyg8+GOUr/+I83xt8esx84FfGm2LHTe1fY7CzAfV9ui9//FnyL/wMACgetApmH331f7XfOdE5Lffj+n3/gj1A1eot/XtNyH/4h8x/ec/Q33/44HaLPq/aLNvk6s3BwumI6D83RUoPH8fZt59NWoHnaJ8Xen6D6P44LWYPemfUD32gtCfU7zrCpRu+wdUD38vZk//huIz7GOt+urTMXv2Vc7jzrnw/l+gvsTb4qTvawchN7UTtcXHovDseswefwmqx/1t6PH5xvKz81B85DrMvvUyVF93vvN44Q9Xo/yLj6F24Fth9Q+j+MCPUHnT36Ly5kuQf/JW9P7oPagvOhzT591hb+fGC1G8/weYPfEzqC7/uGcbAJxjVYb8M+vQ+/23AwDq80Yx/dEHPM/3rjkK+d1bMLPya6gt+4DzePm/347ClnWYeed3UTvkDP0XrUyi/1+XAAAm/+Ypu/eXBD13/At6fv81VI45H5W3XYbCAz9E+YYLUDvgRMy873+c1yWd4gkzf1OKh0Oup88Wg86Oo7+yCxiYD0w3RFK5Anr67B+6J1dDj0N52RFqT0/JfWyOvdNzsNCfr8ZzjLS8osC+fB3g6baGSDBfr5jTcBV3hd3f22dvr88WweZr097tNES6vf0D9uvy7uq/v8CNpUHT9vb2e8enwz6HAPP2QW7P8+jftgE48ESz99Xt71wq96MkftaAHWCWpl4UnmswTT1lFIPGN7DA82/v3Pn2d2qIGvty3PfmRJqlXM0/Hh4NwV1v31zzfRQGvfZxlq8FHAuW/Vvl69WA19nHdrnU25zxmqDH3udlVBpjaKzucnnAqqMQ5ri3GnqBei3ge3MMilWVHy+NfdNbKuv3TUN83ouq/bppV7ja3z8HKDZhv5btc7lcn9aPrfEdSj1l/XGrQo/NKhRRV59TjWPNtx8bYlHp/ivNAaZ2ojD5gv1v37xo4xNRtJmCUt7ybq9BShQKRWDpscADP0LP8xvQgxngYXuizpf63WOmUdVWynHbyblsSFm8RvMouHxA3qr7j8NGCXQ5VxO20Xi81BN8LhZdBri/YKlf37iO9pT77Lmr1NsYYsB1oYWgFI8IZhI1udO+5ZXkMnW01EmWo/DjVvL4qngUzdLCVPHwlQ+BPiisiqdx0PNllZ5qFmaEFoKOzeXcap7Nd5q/T9WLB1D34wlTZVSa523KxdxcZRVMYZxkHcvs5qR4XJffgNSiaeVXK63uVXCM2lgVT+O7lRqrwkg+KGGqeGI4yQL+Kh6n9DPXvOoodq4GlRnHdpI1MGpzjjVFVYrMup2Nf9wOUBI7X4KqePIFtw3HsxuAbx0PPPBjADng6P/jvl5WvRTFSVZaxVMNGKPBb5UvuNcvXamxWO5ORm1tgP759u3kS/Ytm6B7+uU/oMxLIF9wJ4u4dvc6m32Ac5IN4wfBnSQ+J1nOB8WyuDJjFqDk5fXyYtmyKfZ7k3373L3m72EnnYyZUpm1hSmZzee9FvPsvuhqyo8FCPbXcAKUJvhfAOYXGNOg1pnAUiwzFoNCtr8Zbd0UHxSDklHTPjaieR5fttqsygjTfjyxnWQVzfc8n6HwadJNuE6pccMqIDGjtgAflHwRWHiow6LjpSeAeaPAB34OHPXn3HbiWN0HGLU5AUqMMmNA3ZKEh9MTioza2gdigOIwKHyAEuAky17Pvz8qdI0K+bGoDkSREeFfmy+6zoQyBqU2634/fhUjO/jD+IzwYJO/6G+hg5ZBUQUobHyGky0zayv2ciewJAAwZVAsyw3+mhagGBo0OZOG4UQd1cgrCYit49n+bqQxQq32jH1QwjjJhvRBaaYHCgO79gQtjpJyktX5ZlQVx5rFBQUiRN+TpKzuHSdZIYDgTePyBeCAN9v/H3om8JHfAa94s/f1QVb3WifZAKM2J0BRBVGGU7aJmyxbMDlGbdSLJ/tQMihz5O2oVXbgfE+MOBADHH7ysSxuspFcJO76JnDZYmCz0DVYxiYwBqU24544vNETf9EQJ2rLim7qFaWDpq5dvSrFE9a2nZm18UyK2ISL/978Z8jABzLNClDYpFev6PuwhE7xpGnUpujFU46R4gkyogrlJBsUoLBjpvH7i5NCM+C4sTbOX8sCdv5J4q5syAKpYGJ1r2qrwKdVRIiMSeJGbaLVvRCIv/NK4EO3A+/+L29fKAYpg8IfM0kYtQnb0AV0Mpj04xGvo5TiaQNoGRQJBSZzkgXcSSh2gKJhUGSOtjyeucseq9jXoS6hdvlJk6302WcXSt5Vlnjw8+MIHaCwVViYAEVzkWcMysQL3hVOWI0MY1A8AYqwwhCZCpPVCtAci3PA+xvp9qexFiPmCjsJ+PZ5Y6Jnk1ikFE8YBiXISdZUgzLjve1pYoAisrebrgYuXwb87t+9r4vbyoD9NloNiirFo5lwRc1JT0IBijLFIwQovQPAvq9Vp+BkqS2TBpO+9+hSPAoGJWyKR6tBERjdKIvFJoMCFBGOSJYxKLxINgspHkX3XNmq2eneqphIC4oAhaV5xEaBDL4Ahdt+WOpal/eceAn49T8CLz7hfVxHk89ZACBnrziY0BkIr5GRMSg+waaQltJdmNi+zPc0r7cNH3zphLKmE3XcFXYScC60s97bcoQAxUnxBFyA64qVsec1piJZgUFRdeJOEg5727h2PPxz+/alx72vi82gmGhQojAoYoonqQBFwnwA3ORvOB3KmBgP66ZxqvQcWzqRbEAQFQTZXCVCvI4Sg9IGcBgUVsUzbt96RLISlb94kjcrxcNPPCrhmfi8SrfCsx35gvsdHAaFfXcxQBFXtXxVUEgGRZY2Y3jwf4DffhX43b95H9dd5As97m/I61DCamSkDIpCsOl8hubEZkFfsyp4AHMGRaULEBFV+JwkxBSPw6BESfGEDMx02zfV5/gYFI1+Kik4ItNJe/xP/947BoZWdDNWBYVakayY4ml2FU/I9ElSzQK1VTwqzY4hgyIupmRw0o1CFQ+JZDMMZYqH16AIzAXgP8mTSvHoRLKqjsLO/wKt7DyuoHadMTcuoqpmXeLBz25zBfMTiEEXtbPmejwTAgQLDWVC2bB6CqkGRRBsqpgpGdhx0Cz9CdAoL2zsfx21W+MmDZ1WJQtlxuLx4dOghEnxGGpQPHqCNmRQHJHspF0dxxYaqutA5G7GYTQoihSPLGXhY1CSquJRMD5h2QlZoMMfJ6YiWavuPf/qdTAHc3UQZZriEa5VMojBMolk2wBOgPKifetMLCoNiuLgdlI8TSwzDtJAOBd1AwYF4FZ7ggbFl+IRDuSoFTz8tmQTARs3KzcEGtUwARd5mVA2bLflhYfZt3u7/XwCGRRtiofle5s4MQFmKyf+omXp6GgWyKZZZqwo02UBSlCQxcOkvLpe9+4TVTBjLJJVaFBaJZLl/YUSZ1DCaFD4CdwKV8WTFOvoMB/CMR+WnZAFZlE0KOL7+MAmTjdjwFAky1hdUYOSHav7bNjFZQn9DRdRh0HhJmmZoFM12SeV4hHfX9WkeMQDSyVQU45ZKDUWTdoYRDFVnFSALmpn253hAhT+daqLfN9e9u30Lv/7TCfbw98FjB4FDB/IfR773sJkKY5XBkeQ1sQUD2D/BpWAsYiVR6oLs+kk3Ez49jnzQeFW1bWKWfm4yjSMh28CkbyWX+kai2RTYlA2r3Uf9zF+rdSg8KwzNxEHalByybGOgUZtpikeSbmyR4NiyKA425AFPCqWJ2yKR8OkVoRj0US30mJQgCKCMShTu+wJ3yOSNXSSBbiLxBRiwWFgcgCskCkelUhWMfGIZm1KBkXBJIRxkfVtS3KRY9ufGXcf44MC1UWe9TeZHvNvy9QHJZcDFhykGGtj/0Wp4mlmigcwc5OVibx1r8uEUZuwz/n+IrVZs9+VfR+rbgcZMk8JMSCRBXr8awJ9UAQGyMn7N1GDwoLgiReBsefcx5ulQdGtuJ0ARTH5BjEopTnJGdoFGrUZTv4ykWwUozbnfWXuvmR7QIQyY6YnNEnxZDdAoRSPCLb6hmWvwGe5FI9sta9K8ThujjFTPCxAYpNuqBSPQgypcggVGRT+u/Pw6QJYgBJhInNYKclJwU5SnkHxWIUrLqzlxr6akQQoUYIoBl+6IUyKp7Evm1VizBDG/wDQaCzq7kUxVQ2KsM/ZsVYSApQg1GtqUSMPVbWJ6jWmDIrIADWVQWlM8C9vDrhetECDImNxwwYoSSGwisc0xZOQDwr/2eJzSZUZR3GStWr6SqQWggIUEYWiW8Ex+ZIrMOPLjD0Hkkoky9GsccCCBDYmTxVPwMVUJVBTalBEBoX77jxEx1I2DlN2QrYtqQZl1jsOwGt0pVpZyQKUaowgyhmrwpNDHK8MFSHf2ywErZzqdeFiqljteViCNKt4FGxdqd8tCzWp5AmqeFM9HsigRLS6b6oPinC+ztvHOwaGZlfx8EEhv/+tECmeJFOi+aRSPJLvzTNEpiJZ8X8VIwOEZ3nE1KgIy5I4yfLNHLNRyUMBigx8JY9HJCtjUBR53KR9UBiz40nxGIpkVeWwvioekUFRpXgUDdyisBO80M7n48IFKOzkNbEKZ2yTR7sSI4hiUDWuEz9DhlZU8QDBIlmTFIb4eKo+KJp0oglbxKCanEWo2EbPawIYAB5Kq/tmimSFSf2gt9q3SWtQ2PVDFeR6XK+5VblHgxJQZpxUBQ+g1qCETZ9Iq3gilBkDXsGurkllWCFvkOlarQJHR1UUGBTd+1oMClBk4AMUmZOs1Oq+yT4orOzVQ9kGaFBUfhcq23eRQVEatSlKP6OsxHTeHfxE4JRKGogMmT7Bo0FJgkERJ8swRm2t0qAE5JGNJ2re2yZDKR4+QA0ToKiqIkTIJhCVNXquEKyP8DEoLdCgiOfrQW/zjoEhrpOswySojiHFscbvY5k5Gh9gJeWBAmhSPIxBMZwOA1M8YTQopimesEZtAU6yfFNYp4qHvxZnQ4dCAYoMHgaF78UjqeJpug+KkOLhg5KgKp5AJ9kgDQpnUsfD5yTLBKgxyowByeqe+36il4Pus5qmQRF9UAICRB5iSV+zEDRpR0l1pNosUFPSHsb5UsUeiJBW7ag0XAaBW9oMyvxXAsOv8H42Q7N78agWUPxkKwvwmqZBMehmbAIWVKlcYcNU8aiCktgaFNOFSs69ZnhSPNkoNaYARQYpg8JV8ci6nTYjxVOvuwGKk+LhA5SIIllV/yCfBoV9d4FmbUYVD7892f8sXROGQfGIaxMwHVMxKDo3XAY+VdhMBInjVEJJEfxxnVQVRRSo0mqhGRTDwMwxMeTbBigYSJOJXaVBaVWAcsCb1avpZmtQVEFhEBvAX2+SPF8Sc5KVpLY8i1ZdVZMidSO+z2PoZoVP8QSlemVavlwu3DnVAlCAIoPTj2cnl+ZQaFCUDApL8cSo4uFpOFmKRxV4iP+rLs6BDEqQUVsSPijcRUGcLPmTdEZgUHQiQ22ZcQwGJciTQxugtKCLLRAskjWeqDNQYsx/flUSDIdhUMT9EeQQyzNdKpt2k9RIGgxKPu8uNg44Xu6JwRvSxWZQVBoUhSYuiA3wMCgJalBk/iWAN2VntJ0Aq/tQIlneqE2hR+EfD9vNWJniUbRcyJibLAUoMngYFK4fjbQXT4CTbBwfFJ59YZbrurJBUVVu1eWvM63i4YMzHgVhoo7jJJvLqU8KT4onDIMiE8kmyaAw8bHQF0anfHc0KE1mUIJWTr4ARTVRx9QnJAXxWIvMoIjnSoAGhT++VKlTk8kiDR8UANj/OGBgX+DAE712+0yIHsbLRYXQDApL8QQwFk3ToCgCqqSt7rUiWUMNisr4zbShYZBIVpVyls1xKYKM2mRQiWTZye1hMVR6jgRSPI7+pZ/zUzBM8ZgwLUrdjFhmLKxiVKWfUSf/Qo99gusqTHwpHgMNyuwe++TOFxLSoIh0fWObYRiUtDUoximejDAovr5PCYlkg5oAFnrsCateVTMooVI8LWRQAODPf2wvUApFYHq3+zhz3U2iSkumyeOhWhgFuaLm8/Y1rzKZrAYlsIonBoPiMaIL6yQreU4VuJgGUUFOsqKLLEPGzNqIQZGBBSh7tnGUb7/8ghjogxIjxcMbpck+W5fi0QYy3EWYh5PiETQoSpGsmOKJOPmrNByeACVCFQ9gB1mWlcyEK6YUHAbFJEBh+7JFKZ64Itm4AsqkwKd46nUuVdcbPEHyMDXVq3PsiOq4jJTiEX1Qmhyo5vPu+Pjzkn1+Ej43gQyKYr+ZMBYsMBE7qcdBkFFb2ABFWYETMcUj89cCgn1jZAhK9aquozpfqhRAAYoMLEDZvcV9jDdqg+UeWE1N8TANSD98uXhAvxo2YlBUKZ4gDYpYxRMjxQOotQRakazms3p63TFOj3m3m4gPiqZxnQrOxJSySNY0xaPyymk1+GPNU/pcCncxDf29e+TGjPxrYjEoTU7xyMbAf34YLxcVPNdDifOoiuE18R1h15yWVPG0MsUTwagtCoMSKJZXGAaGCfpbAApQZHD68bxs3+aLjQuipE48UCQ7KT95TcCXOMdiUBTajiAGRdksUCz9jFkNoFr18ye9o0ExpMj5Sh7+QpmkDwq7zVSKh62cVOK4kExCVlI8Vs1bsl/slZ8TKviOrQAH3XyP+mIdpcy41mCAHB+UJjNpPDzVGY3fn2eKolZp8at52XEUWGasYQMYK5mkBkVWHsz/3xKRrCK9JG6jpghcQnczVqV4FMdhkHalxaAARQZWxcPQM8cr5gTsH9Cy1KspfiKqRmRReP1LUXLg6DQo/ERk6n8QmkFhqY4YZcZA8EoVkKR4Aj6L90Lht5NEgOJUlERI8TS7F4/D8hgYsAHBGpSspHgAr68Nz3BEsbpX+qBwdL9zXKrKjEOIZAH7fE2DQQH8qaYkUnhB1uiq1LJJSsVhUJKs4mmM11IY78VhUFTNEEX4GBQD1sST4jGcsmXzBQ/VQo/KjNsAvUNetTSL4kXX03oNjl2wSoMCeIWyLLAxgcdmXxIR6y66qvuAenXMlxnXKu72fRoURQO3qOkTkyqemZAMCm93z96TK5jncGVQ+b+YpHha1osnpEg20A8kSwFK4xhg3g2xrO4DdBOFHo0GJYRvBn+cVqe5ALvJx4EIsey0nsDvG2TsFSiS1ey/A98ClAeBfY+OPj4RjnYkZp8bWapIlaoREcWoLWwABai9bxiqCka3QCme7COfB/o4FoVN0PkCFz0LVSfiic57EbBAY3o38LXDgB/+udk4eAZDdjHWeTtoAxlFiocvM+a7MPuM2lQ+KBEDFBWtGNXqHnAZlOndnLAy5qrVV70kMiiaibJlRm1hRbIBfiCpByjc57MAhV18Y1ndB3zvfI97sfZNKiH2Tb7oLnaqWWBQGsdsGBZIBZ59kaXMVNcdkwn3hE8BF28GFhwUfXwiEqvikfipRNWgKKt4JGXGpukdIPg6oDoOSSTbJpizwL3P50H5Hz6oVM8RyjYmp20PAOPbgUd/6fXoUEHKoBimeEQ7fj6qV/YP4hgUFqDki35mJEknWYCbCExEsqYaFD7Fk4AHCiD53oIGRda3hcHRoDS7iiekSDYoFZS2BiWXc7+Tw6CwACWG1b1KgyJlUBT7zCQ9kst5g4NWGfaJEIPrJALQfB5AQ79ixKA0PtOUgYrDdkq3l7RIlk/PKAINEcZGbZLthQkmjZ1kBQaFjNraBEwoC3gZBD5Q4A822YkueqGMbW08YQFb7wseg7SKxzTFo2NXFIwHz6CoGgXy7xPFopFFsioGRVfFE0IkGzeAcsapsC3njw/VyqNlVTxBDpIhJ+o0+/AwsO/kC1Ca4IPCTwaqACisiR1v1mbihNwMKBmUmEG7rupDdQ1yGIEWTz9BTrLGVvcyHxRFWbAIlUmceN+zPeb4G4ZBMXSSFY/DjBm1UYCiQr8kxQN4T0jnIMrJDx7RC2XsOfe5ZzcEj8FhUObIJ3GVlTTgPzBlgY2WQVGYtPHvE7sZR6Wtg/wmAHc8jsFQwGfxdvdJsQE+HxRBgwJoVizst2y2SDZAHBe63DZlBgVwvxMTyUYJUIyrl7jJSrXiDhu8seCgMtWaXjwyiALvpJyCdV4ocTQozYCM+QAiVPHINChJp3hkGpQIAUqQkywZtbUpPAwKn+LhcnRBE5/ohbKbC1Ce2xg8BmkVj6R82KgEWcKgKKt4ptQmbZ7PE+zHI2tQwohkIzAoTgAVc7JV+aDwQZx0JcmxbU3vxZOQSDYrGhTAZa5Yb6VClBRPDB8UVeBsyj6w42Z2HI6oPjMalLhpT0UFHiBJQVe8r211gBLYzdgwAJD6oEQVyRpU8UTRoER2kiUNSnuAD1B4N0N+Mg26iLP3sVSNk+KBzaAEVfNIfVAkTAhLw5jqU0yqeFQlxoA/WIotklWVGfMBitAsMFSZcVIMCjt5q/C4mvIBrGyy5M36WiaSVVyYwmpQMpHiaXynWCkeUx8UnkFRlBmHDd7YJDC1y/9Yq9AMDQogd1VlUDYLTCtAUTnJJpHiiVpmbGBvH1bECxgsVIIYFApQsg0lg8Ll6FQusgxObxumQeEYlPFt3v9l4BkU2YHDJmu2gvfoTMSLAx/YKC5OHgaFpXh0GhSW4onrJCtrIVDzisZiaVASDlDYWPmSUd3KwwlQcs1fOTsiWdMUT1CZcRZSPEEi2QgpHuX+MWBQgs57EWy8Tk+cXOv3q49BSShIyCsE7oCaEY0y4SaBpKp4HMM3A/ZDhNaoLSDdE6rMWOI8zkPpJEspnvaAh0HhNSghGBQxxcMYFLa9oDSPp4pHosp2VvCSMledPiVIgwK4LromItm4AYBMaCdOCrPj9gXBlEFh3Z/5MuPEAxRuLCodDeDVn0R17Qw7xk5M8SgZlCgpniANisbqPiqDwgIU5uPSSohdlRNjUDQaFBVbFzalkhSS6mYcpEHRimQNe/F4qjAbgVCoMmNTJ1nRB4WcZNsDQVU8dU4kq8rj8ime6iwwscP+/5Ur7NsgoazKB0XsqixN8Wj0HEG9eAC7kzOg0KAoRLKxNShCabQHlp3yMm22JrO6j8teKBmUst7gqFUN4gB3X6pWTqHLjLMQoLAUj6hBiZPiCfJB0TQLDC2SFRiUVutPAH8FWtJVPO0gklVW8cTsZlyvq0uERZgatVk19zofRSRr7CQr+qCQUVt7gK/i8aR4JFU8gQzKJLDn+cZrS8BBb7Pvh2JQBBdbIFyA4qniUbhIFnpc+nLihca2ZVU8STcLlKRHPCdIY7U5Mx5Rg5LUajHPsT2zbhDA94WRpnhaZNIGBPsfhE3xpG11DyST4jHVoDjnBldm7NOghE3xMAZll/f/VsLpCdQsBkVm1CaydSlrUFQpnrAiVHE7OlZEhK+KR5Em4v+Po0EJ7SRLItn2gCrF4/FBCRLJNn782Qk3vTMwCix+nX1/633Q1pt7qnj4nh6iUdg87+PifTZe8TmR8cjl3O/KGBRZsy7x4K/GXG3LVqpsjLm8G2zMjqfrg8JvozrjZVC0KZ4WmnMFUbvGlu8ZMWoD/AxKlBSPLuXJQ9osUDFxGKd4BAal1R4ogLuiFrsZJ6VBkTKHWRPJJmTU5mNQNPYIIhy2psf7P6DuERTH6r5ekRdjqOwaSIPSJvCkeDgdBv8DmqZ4KlOuIHZgX2DBq+xJtzIJvPCIegxON+G5/vQC4E5CRikeSfWPbNxsEp140bttHj6RLJvMYjYLlGlQCiUu2BgzbxYo9UFJgA3wOAlzrrY69Xur+vAAwZO2cdO8dtKgRGFQDHrxBDYLjKFBaTXEZoEt0aCwa06DAXVSPGkZtSVcxaNkUAyqeNgxrBPXOgFKlDJjyXzBQ9UTiqp42gR8UOBhULgf0DnJFQc2n+JxApRRO1Uwusz+X5fm4b1I8gX3hBYdXFkQwV9IVa3OAf0KkE2ikzu92+ahcpKN6jMimwj4FTyzkp8Jw6A0ApTajH9iiwMn3TDuPlYoqSczoLUpHlORrLOCC5ios1Bm7EvxNH77ApduC4Iq3SBCVmasbLYZkUFJRYMiMiit0KCIIn5RJJsWgxK3ikcIUESGzUQky34PlVEb4O4vZ3whpmt+QStL8yidZEkk2x7I5VwWhZ+k+YkoKE/vWN3zKZ597VvWpVMnlOWt7gF/JU9VCFDipngA9+I/2WBQejQBCqMPY4tkNUZz+aI8XROoQeHcXVm6Kol0hWO7PuY+VuzVU6Ot6sMDBJcXsv3KjqlAJiFLKR5Vs0CTKh7h+5j4oCh7RIUULWaJQXE0KAk5yRYMNChlMUBJS4PCyoOTFslG0KCw30PXw8dhaCIEdB7GXSPcJyfZNsbCQ+3b4Ve4j/GTadDE3CNjUBoByuJj7FsVg2JZXqt7/nOqIoPCNCh8EBLB6h5wJ1FHgyILUATBblyNhyzXz5vJsRVYGA1KvuC+r6kBSk7wzJCtJFmA0gqRbACD4qQFmXdOG5UZs/MhkgaF9cDp179H2ixQpVkw3DcFkUFJU4PSpF48uioe0Qah3Y3afCJZkWEz6MVTlATKvsBJYJzCpHjyBff1Mj2a0klWwwSngAzwtxnGe75ndx+ef6D7GD+ZhvFBYb4iA6P2LWNQdjxirwz5FT97D7PFdhgUIbrVVvEo8uZs7Kpxs5ykuG0eoh4mdopHZ+Pf467Apnb5VyA6lOfZQQ3T0yQaoHDphlwuIMWjUMw3A6Yi2TATddoQj6tIVTyMOZpjV9MEBWYeH5SkUzwZ0KAkpcsyMWoTGd4oZbNJIMjqPmwvHlYKHEWDwoJWlVEb/9qoAV2xbAf1Ug2KQrivE/unAGJQdCjP9QYngMCgBDnJcj4ofBUPAMwbAQYWQ9nZmK0WAXcyEUtIq6JIVpfiMfBBAfxpCKnVvVBRlJQPirTjco+rJ2FpJ8AwQBHel0Tu32e73vjO2hQPW/lnSCTr6JaCNCgZCFB8fj1RUjxCYKYMUBqTRIFrFhjbB6VxrIpVSK2EqEGph/wOKpgwKGzx5ZTNRujOmwSUZcYRRbKA/V1UDJsMYUSyPg1KyP2lS/equmqTBqXNwU+mpgzKzBiwZ5t9n6V4AGDpsfbtU7/1v5fpT4q97oHJC3Qty/18UYQGSESyplU8wiQqS0vwgt3qtH9VEBZBVTzs+03wAYrBZ7ELo8OgJDDZKgWbWaviCfBBCQxQslRmLJpJxajiMdXe5HkflITKjJ3/s8CghPwOKmh9UIIYlJRSPLDguLPW63CYauMUDzdt1muSY4nbvghfgBJGgxIxQBHZVMvSVPGEEJ63ABSghAU/EekmesCdkHY9A8CyT4A5e7vPv+IE+/ZPd/jfK6v84A84/gCSVfFobaYt73fxjFlkUCRGbfxYPNUsTfBByfdwgcYL7mMmJysrNXY0KEkwKIIGxZdu0FXxtDhAkfkfsMA1KMWTlIgyCQSmeEL4oDBW08gHJSknWeGcSsUHRehuy3/PODCxus9cgAKXleBTLKZVMuJ22L7kf2dVJY/D0MlSPAmWGQNq00Zej+hzkiUGpb3BX7SCViE9wip13qj3JGAByrMb3FbyDI5JG19BJBHoApxKnk/jKESy/GukVTzCJCozauPfO8sFKJGdZCXpEX6Vyr4fCzRMV6AssGFjTMQHpfG92e8lrubT1qB4/A9kugCWFgxiErLEoASleJrAoBg5ybYTg6Kwuk+KQdEZtTkMb0xNRVzwE7zMwyRsLx62Hfbd+d85qEpMxqD4jNripngUbS+Y/gQgJ9mOA39RNE3xMDD9CcPQUrtCyKr50zzMpE3lYluVMChakawgrFWN20SDwr+XD1Bia1C4i4XHB0VgUEwDIaZBYUhEgyIRyQIBF+oUUjyAXCgrThqqC1GmNSi93sfDBCiBGhQu+Ah0ko3IoGShF09SQYJjWqYxahOdrlNrFihhUKIEKJ5Ap8pV5vR6H5chVIonZkAnazALuCnnXME/B+iuYymAApSwKHCUpqmTLIMYoADAK060b8U0D29z73w2J3RjJ3+uwHkc8BoUJoISghf+NUYaFFWAwhiUCXdbUTu06lI8hR63jNoJUEwZFCFASYINKIoBSpgUTwuN2lRj8U3Uqp40HJOQNlQ0dKgUjyAoD5pAEnWS7WAGxdlHkuNIWWYcMWURFx7mQ0ifhBmPKJKtyxiUoOPLxKgtZopHVeWms2qgFE+bQ8qgqKp4hMl+cF//axwdyu3exx0GhU/x8DbrrLS3rC/TddI/ooNkUZ5zNWZQBA1KnFWhdPySFE9YJ87eJgQoKgbFJMXTionJ438gYRbEFE+g1X0WUzwJMChB5dWJOsmKDEqXalDiMgJxIU3x8BqUmCJZjwZFIpLlBbmOUZumise3v5LSoChcZIFwpfstAAUoYeHRoAQxKH1w+lAA3goehgP+zD7gX3wM2P2c+7iMQXEOOC7FU+iR03I1gcoX++aoxswzKLmCOhgQxaJxJrKC5CInE8k6YwypQXE+J4kAhVXxMJGsWGacMoMC+EtKeXREiqfkfTxJDYqRk2xYkWwWGZSERNA6HxSnzDhjRm2ARIOSMxfJ5nJusGNxGpRCAIPCP2Zk1BazLFtM6zFoGZRsGbWFDlDWrl2L008/HaOjo8jlcrjuuuuUr/3whz+MXC6Hf/u3f/M8vnPnTqxatQoDAwMYGhrCeeedh/HxcflGsoaCJEBRTXx8d2BAnuLp28vty7P5Tvdx0yqeQlm+ehcZFB+1q3K/5Q7a0hx12kZM8cQKUAKM2sRKItMqiKZoUEQflIyVGQOcm6xGJGuc4slAgKKa4MOkeBwGxdD/ReskG9J6PJMalKQYFIUGpV5z0xclUYOSklFbLueyH2IVT9ix8N+b19Toyq49AUrjmOCZliAn2dAaFAUbonKRBdrfqG1iYgJHHnkk1qxZo33dz372M9x1110YHfVPyqtWrcJDDz2EW265BTfeeCPWrl2L888/P+xQ0oHUB0Vz4PAMiIxBAdw0z5NcmsfpwyNL8VTciUZM8bDSUsc5U1y9BEw8fECkSu/w72ci2agusoD8pOBztb5AwzBA8aV4kvRBUZQZp13FA6j9D+p1d78ap3gyEKCIwW8hJIMi+94tdZLNQopH9EFJuIpHnFz5Vbso4k/LqA2Q2NRHZHP47fDHQ04jGuYfcxaVuhSPMMbEyow116MwrGQLEJpjW7lyJVauXKl9zXPPPYePfvSjuPnmm3Haaad5nnvkkUdw00034Z577sExx9j9aK644gqceuqp+PKXvywNaDIFqZOs5iTnDwIZgwLYAcpvvmILZS3LjvSlDAp3wPEpnoIg/ir0SARqQopHxXjwF09dSiJRBiVAJFsWGBTjKh4xxdPMKh4DJ9mWBSiKC5PHO4eleNqxzFii+2HnjQz89w7j/xLogxJRJNuq48AzBiFoTcxJVmFmxwfHWWkWyD6zXomvh8lLUjys8qs2Y5DiMajiie0ky8qMFZYTsuuoM79p3HBbiMQ1KPV6He9///vxyU9+Eocddpjv+XXr1mFoaMgJTgBgxYoVyOfzWL9+vXSbMzMzGBsb8/ylBn4yNVlJMUo5VwDmLpK/ZsmxtvZjYofdmwcwqOKRpHgAfzmxSiRrIuzVMijCRB1n8pda3WtSPMYalEHhfQmKZNkq0FdRIrP8bnGKR5X64CcNJ8Wj0qCE9PpoJpQ+KNzYdJR0TbKaVwZmMg1KB5QZOwzKdKMDecJOsuL+520QxErCVAMUsRNx4zwOy044TAnHzvEpHqlIlgtGTKp44opkC5xmkYcj2pcxKB3uJPvFL34RxWIRH/vYx6TPb9u2DQsXLvQ8ViwWMTw8jG3btknfc9lll2FwcND5W7JkSdLDNodHJBsgOAXcAGPeiPoAK5aB/d5o32fVPNoqnop3ApeVlvpEsrPe500YFF2Awib7JFI82iqeUmMc3Oo4MoOSYIDijEXQQ0hTPBkRyXomDdYUMohByUKZcYBRG6C/oPIXaPa9TVI8iTnJZkgkC3gXV83SoLCgsFD2ayHSDFD4wMIzljgaFC7YY0JbKYPCV4hJ9pvPqI0FKBGDKLFyi8GEQWlXkawOGzduxL//+7/jqquuQi6qJ4YEl1xyCXbv3u38bdmyJbFth4YsxaNlUBqTkiq9w3Bgww/loevsA1LmJMvnFPkyY/5EVwYohikeUSSrglhmHGfyl4kR+eAvl/MGG5E1KAmsXIMmS2mKp4VlxgBH54spHjZplOQ5cB6ZKjNW9OLhJ1ddgMIuyPme4O/NazMSc5LNgAaF34fV6eZrUHh3VXHSS8uojf/MJFM8/DZMRLL5oj9Q4p8X/49s1BbgJCtjdNtdJKvDb37zG+zYsQNLly5FsVhEsVjE008/jb/5m7/B/vvvDwAYGRnBjh07PO+rVqvYuXMnRkZGpNstl8sYGBjw/KUGnvY1SvGwAEUhkGU45Aybcnv2bluPwlbdnhQPO3hm3ItuoWxP4KIGgh2Uqioe1cHO035aDYogkk1Cg8JPBOK+9QQoURmUBK3unbGITrLiRabOpXhazKCoNCiFkr48FGiPFE++AIdZ06Z4+O8dcAHmKyaUv2lYkWzWGJTZ5FgMVUPFKh8MC/s8LaM2wJ/iiarv4EWyvAbFRCTLH1smKZ7IGpQAJ1ldmXEnBijvf//7cf/992PTpk3O3+joKD75yU/i5ptvBgAsX74cu3btwsaNG5333XbbbajX6zj22GOTHE5z4GFQDGjSkmGAstd+wGlfse/f8Xm7Pw8gpHi48lE+xcM/Vw9gUIJWxh4GZa78Nfz7RUfVKJCVw4krPH4sphf4nn7vRTCRMmNxshE1KApTJCCFKh5xLNxErZpYGMTjK02oWKtczqzqwGEbS9wKWtUrhQvglU6yISf3LGhQ+H3VFAZFoXfyBChZSvHErOKRMih8mbEsQOHLkSWBjEokG7vMOIIPSkY0KKGPkPHxcTzxxBPO/5s3b8amTZswPDyMpUuXYv78+Z7X9/T0YGRkBK9+9asBAIcccghOOeUUfOhDH8KVV16JSqWCCy+8EOecc072K3gA7wrMRCw3tJ99u+jQ4G0vWwU8/Xtg0/eB8YYex8OgKFI8bAyVxrgsSyOSDariCSmSTaKKR5fiYduNkuJhqaHpXfHHyCBe0IOcZFl6B0ghQFFMGsWye4FUaVAyVWassLpn98Xu3iI8gvIAIyqpD0rMMuNCD2ymR3ARbTWKvfa+qM40X4NS5YJCMYhMu4qHH0PUdBMf6Ho0KCxwkYlkZSkeA6M2p8w4JJ/AG3vy0DrJcuLdet3cvK5JCP3pGzZswLJly7BsmW0utnr1aixbtgyf+cxnjLdx9dVX4+CDD8ZJJ52EU089Fccddxy+/e1vhx1KOpAJVXUn+ZsvBs69ETjiHLPtn/qvwEKu+slTZszlFB0KVWBQHPq2cTEUTZICq3h4BsWkzDjBFI+OQSlHYFAArw4lkV48CrpeWc0w5X52q3LuQSJZPtUhW+lZFnfRzYIGhTu/WEpTfE7FBAHC99ascPnHdT4oYUWyuZxQvp9SgOKpAkzaSVbUoPAiWa7yrS4wDq0Gm3BZABE13aRK8eiaJ3pSPEKqiR+LeG6m4SQLZEIoG/roPOGEE2AxMzADPPXUU77HhoeHcc0114T96GyAv2iZ0KSlftvO3hSlfuA9/wV8+wR78udLk2XpJXYQytI/gN+DIBSDYpLiaZIGRUyfeVI8ISjycsIBSqBpmIJBaaX3hcqgif/tdUyCp6FkFqp4uN9bvKiGTvEE5Nj5AF6pQYlAuRfLbrCaJoMC2BNUYgyKSoPCMyhCOXjUlEUSEAOqtESyslQj39NnNgGvljhOsux9aaQjOWTg6tNm8DEVSJ4GX3AQ8MFf2p4oI69xH/dU8QilYvwK3uPiqBDJmmhQTIzaWDl0EmXG9apruOVL8XCBRpgLvOd9KZQZM7GzzHOgWVBdmDwpHsXkK74vayke8Tc0ClA4PUSgBsWAQYmS/vIEWSld9IuyBU5SGhRNmbE46UUVfSYBUcSaiJMsx0ZpRbLc95ameFiAUgZm98QXFQc6yWpSPEAmhLIUoIQFr5doZkO1fY6w/3h4uhkLFxgZu4Kc3znTSUsZVPGYWN07/8e46Ipl0sWSpIonKoPCaVea4oMiCRB5tLoPD2AmktWK+bjvkLUUj49BMag6kIqDJa+3LMGrIiEnWUDPArUKTWFQmJZJTG3yrTj4tEE1elCQBJRVPCHVDvz5I2VQYlTxOJ2OY7I8ylQv+21kDAoXBGUgQKFuxmHBBwmtFhLyEw9fZsw/V694V8qiJ0agUVsZTummiUhW9X8YSJ1wdWXGUTUozfBBEUSyvgClxSZtnrEYMCjtluJRHXdGItmgwIx3+uyB1EnWstxJJRSDwo7ZXHpBnzNh8R5OzdKg8PucYwySLHGOAqVINmyKh2s6KNOgBIlkdUZtjg2+WGYccroOSjvLrqN8tVcGNCgUoISFR4NiIJJN9LN5lkQUyXIreD4IERvHBZUZ84K+MAFKrBSPRJglpngia1BYYJNLhlJWfW9likdDpzYL/ETEQ2pCVnUbTIqvYyZ5aYPf50oGxSDFU+TSDbLUVl0IzGQMiid4C3E8sWO22JvePm0GgxLkgyK2JajNRq+cSQKsEqYuiGQjp3hEq3tDkawuxeO4HbMUT919XxiI134GHYMCwOeplSIoQAkLjxg1oVVI2M+ucmkcmZOpxwZfuMiaWJizyVS36vdpARJM8fC3+ZgMCtOgFMvJTAw+HxRBg6LM97aQQVHmnnldAN9gUtHmPQv6E8C7AldqUHRGbXzpsGm3WYUGhX9NqBRP4zhJU3TYUg2KsMDgf6cspXiidgqWiWQLPYYiWS6QsSROsiKDErmbsWKhonOSBczSpi0CBShhwWsNWm0HbpLi4UWyhbK/1CwoxQO4bEVZ49ibZIrH44QrBCiyFE8YNoKleJL6jXw+KILturgyT6OKJ4xIFlCX0WYlQAG8DAQPkxSP53wwrV7ifFCsOrfi5vU5UQKUlPQn/GdXp5MLEpRGbaJPE+8flaaTrJjiiVrFo9CgGIlkFSkeUYNSE1M8LXCSBcyC/hYhAwnmNkNYJ9kkUeTZG2ESyctSPD3efKJlmQUox/8t8MxdwD5Hql/jm6hjBgCFhjDWoTWFcUZxkgXcICupAEXlgxKU4mnlxBTGSRaQrH5bfFyboFCy9Tzi/jdZ7fGMoomIEbAng4IQxOXL3gA0ikg2LQ8UwCuaTIxBUVRFKRdQKWtQxNRKVI+RuD4o0hSPQoMSVyQbxkkWMEubtggUoIQF+/Gsmlm6JNHP5g44scxYpk8RFfQyi3wZjv4/9p/JWFT/hwXvhAv4xxk3xZMYg6JIbamCgkoKKR7VyimowaT4uixU8DA4qQKFq6yRD0rZz4rwwkPegI1n9dhzxbIbgOby4USLmWJQknSSDUjxsIVLXsKgZCnFE9VJ1qpxiym+OidIJCvZb74qHrHMOKyTrIIJ0TnJAmpdUQqgFE9Y8BM7q9BIQyTLN+Pib3nxbqHkXXHWZpDY6jjxAEU4mbROshFEskl4oAASkaxYZpyhFI9PJMsJq7UalBZrq0zgpHhiBCiim6+vOZtwbvC/dV04LsNOrqrxtxLss6tT7gQam0EJEMk61yeOYUzVSTahXjy82DYodcMQ6CQrBigxK41UZcZOikdxTSKRbBuDn9hnGwFKy8uMhUodwFvF46HyBeOdpHQzKi1GVIgnhfj9ohq1zWt0yO4bjjc+hiCjNh+DwsqMM+Ak6xwXrAN2gH4gaykeIFqKR5naEg3YhPJhmScEb+QWBplgUBr7jvXPApLToASxcFlN8UQuM+YYEE+KRyeS5Y3ahGoiti3A74MSW4OiYFBU12zSoLQxZKuqVgco1aAUj8SDgKWkkupSq2vgFml7AuUpTpJRy4xHlwFnrtHracJA1VlX5R3g0KkZE8kC9sWUv8A6r2ux+NsEygAlog8KoNHeNF7D0jx8W4uo7JJK5NtKsHOWtacAmq9B4ZuZAkjdSVZZxRPWqE1hda8VyQaleBpjEpv8RQ2inBSPQoOirOJRBJ0pgAKUsJCdVC1P8UhEsrJePEVu9VKdSlYc17QUj8qoLaJINpcDlv1FvLHxCJ3iSYFBURq1CYFHvgfAtP9iyufUswLnWFYxKCY+KCVBV6JK8XDfu9DjFW9HTZFmlUGJe96aWN3zn1NL20k2IaM2ldW9UYqnxx8o8fd9KZ6IZcZKJ1lTBiX9FE+GrkBtAua0l0a/Et7HQFTJe6p4JPRqdUr+XFQ0LcUjVvFwDMreh9i9f5JK10SBijkKEsm2tBdPkA8KC1AUF9NMMygRrO75xpr5PGynZEvzvbljWywfj8qaZkmDMrvHfSxukKA0apMskgCkb9QmVvFETfEENAvUimQNevEA7rHmVBol4CRb54o7VNekDDnJUoASBfke78W/5QwKl+KRTZBiEFIsATPsfc1iUBJypFR1Xc7lgL9aa18Q0lzZ5wtwJjjeFZQXAbKGh0A2RbI+99t2KDNmE7zKqM3EB4X73nyrCgbZyt5JPbLjMuLqP4sMCqtWigOljklkUHgn2QwYtflKeCNW8YQqM+bFtJoqHsdJNqFePHyKh7EngLqKR6UrSgEkko0CX6O8FpcZW3VOiS2p4qlKGBQAiXq3qMptI29P8BGRBVLFUmsnehlyOS6vzn1nVVVMKmXGQT4oAQ0Ok9IpJYmiikEJU2bMmCNFWkLWndzH7EWcLAaX2LdDS8K9L0mwfcc0KEkEoEoNikGZcSpGbYKDayLdjLnUoJGTbNFlQ4ycZGN2M65XXTEun+4ho7YOhS9AaREVzn/ObOMiUxBFaIoUj+q5qFCtZKNCpUHJ0iqeoVCyVyKqJna1Wff3SKMXj6qKR3T3dEpEVWXGGdr34rHsPB7GqE2cLANEsvz22STEbMLDMiFHvBfYa39g39eGe1+SYN+fMShJ/L5hNSieMuMsVfHE8UFh1V8hRLK+cXCBiuMky1I8McuMAfscyPe61yOe7fG9LztlxhSgRIF4kWx1igdwV0FSlkSk8jmxVFKTj08smpDYrlbxtr3Pkg6CQaaHUJWvptGLR1nFIzAjYvpCfF2WgsPAKh5dmbGh9kZmXiaKn6fH7NteTRsIGQpFYP83hXtP0mDHK9OgJBEgqHxQVFb31RkAVnKfHxYqkWxYdiLQSTaIQVFY7gMaJ9mIIlnAnhN6eoNdZAF16jcFUIonCsQTq1ViL34SZBcZnwhN5pEi06dkLcXDVlhV74mRpVU8g2yyFF1HGVLRoBg0CwQ0KZ4M9uI5+DQ7TXLA8d7Hjap4xPNB0ZZA1vxTfO1M47zT9anKKtjx6ixuEmRQRDbKl2ZufBaragOyVWacVC8eRyRr2ixQGAfgiledACWiHb/ogQUEu8gC8HlSpQhiUKKA/+Fb2ZKeryBynCCFvLonjSMIC5tZxZPU9vggSvY5WUBRFqDkOb8ZPkBpXJBbWsXDGDNVikdIdZhoMdLGkefYfyJMGBSZ/wug/t4eBkVIITkBCtd6oV3gE8kmqUFRpHhEn6AKJ9JMJcXDDNLiVvEwDYlodW8okvWleAwYlNAdl/NwvI7Y4iTIRRYw03W1CMSgRAE/Gbf6Iq7yH5Ha4IseKTPcKjFjKR5eS+AJULKc4lF4cvArc3ZByIJRm49BUU0uGezFo4KRSFZghNj3Vvmg8OeGaCA400jxtGOA4nQ2b7B6SYj7VcGeikFhnw2kxKAIItao6RMnwBCt7k1FsroARaVBibC/RDY1yAMF4K4flOJpT8go4JZ9tsJ/RFapI2t1npS+IOkUD79S9XSMzSDJ5zBTqoqSlFM8QSJZX6qjDcqMVTBJ8fgCM9X3lkxWPgYlogYlCxAnpSR+X+UxpGJQ+AAlC80CExDJ8ueLw9CE7MXDV/OwxV7cMmPAf344mjgDDQoxKG0KMcXT0s9WGYXxvSFE3we2cppJMMWTtA8Kp/Lng6hWpc/CgH1X3wVfoulIxUk2QCQrK/30vC6DGhQVjFI8YhWPQhwsE8l2ogaFIUkNilWzxe0MIoPC9imvQUmjzLgZvXik4tcADYoqxZMr+APoOGXZRe7az99qRbLZMWqjACUKZBewVsEkxaO0wedMkhJP8cQVyXK9OrKeYpD5oAD+E7tWcVdIWRbJqibqtgpQQvigBDFHHh8UIeicbuMUjyqgjgNVd2jfIokFKI0UQy6P0M6oSUBVPROnisdjda8TyWqM2vggRwyKrYgiWQC+hoGOs7VOJEtGbe0NmZFTGp8NBGhQ2kgky3tTRG3I1iqoGBSRueBXi2kZtfGrWt9ErVjtZT1A5GFUxSOu5lUaFJmTrBDMtDODoupjFAeq5ou+ZoEsxTPpf18rwYtbgRhVPNx2jJ1kNSkekxLkSAEKOz8Yg2KgiSORbJtDJqJrFVQ+EHy5n8/vghfJJlRmzDq92v/Ev+DorPqzBpUGRSy5dPLtudZ+F/635VdBqlSHL8WTopFWWBj5oIgOuiGqlzqqikc8XpsYoKj0TmyCTCO9A/hTMFEFqB6RbNgUT9H7/T1C24L/OhI1DQX49WihRLLEoLQnPFU8LZ5ExYsni+SNRLKS9E+ssXDVLHG1IjytmfkAJcg0jDEonElbK7U0/Lj4VZCxWDSDVvcqhEnxOFU8KoM6AyfZdq7i8bk/JxGg8AaFOgZFSPGkFfwm5iTLa1C4a6qRSLYAX2pMFqDETUOxMQFukG5UZkwBSnuDP7lanuJRBEcyJ1mfSJYPUBKY/EWTuDjgS9uyvoKX+aAA/sksjQoewPt78BO3MsWj0qBkNEDkYWR1r5gsozjJMgalLat4FIxfHPATLb/iZ8yEaHXvpHjSYlCSMmqTWN17gosgDQr3/VUdkR0NShJlxmKKh0SynQtPYNDiSZTPIxcl46hXJc6ZkhRPIiWGCQYovHth2zIogn9AWgEKXyWgZVAULqBZDxB5mLheGvugmDjJMgalDQOUpCvvAJsZFPvP8L+FuIhxesGkpUFRWN3HaRbo0aCYOMkWvZ9XFwIUMYCOyvIAmhRPezjJUoASBVkRyaoYFLH3CLtIVKbh9MFIOsWT1LbqlexXkch68QD+E7uaUoACuGNkx4JnVRvgJJv1AJGHSYontA+KQoNiWaRBkUGc9PmOuWIwXE05QBGdZOO4tAIS9iNks0D2uKfMWJGGSiTFY1DFQymeNocnSEgzxSPppsszEKKCnnVAFrcTeSw93ttY2+Kt+jMeoMx/pfeWQeWZUZrTmnF5xiKIR2Wr2o4oMw64mNbr7vfxWd2rfFB4BoV77eyEW/LZjgGKj0FJKEgQV/yyVhWi1X3qKZ7G7xi1QoZP5TiBfw/0KR6FBsWqe0uJRWF2VDt+AH4nWRMflOwEKG3A4WYQafqg8Gkd/r5JFQ/rwcE/FweixiWJbSVZCt0svPFjwCGnA8Ov8D4unthTu+zbvr1aNjQHxRIwA/+FCeB0AQqb8qwHiDyCGBQ+CPF1cTbxQeHSdizgzBVaWzaeFPJ5OL28gAQZFIE14BkrJg73pXjSruJpjNUJDCKmeKp8b6GCXiTLp05zHDcgpniaUmYcxkmWyozbG6k6yZqIZMUSP0mAkqTNdeIalIxbrefzwPwD/ZU54spn6mX7No0AhdcdAfJVrVKDkvH9zyPoYqpLN4TyQal4K3iy6HBsAg/r2qQUj8jgAm5QmLYPisrBNarVPX985U0ZlKJfu6PqiFzn2JU4TrI+BsWgikcWZLUYFKBEQaq9eAwCFNH3QQxQ8kUk4uIoGsHF2hZ3UrTTCp6HqH5PNUARgiU+aGWTa0eUGQfQ0fzjQdobqQ8Kl3psZ5M2Bk8H7oSCBJUGRXZ9kqXRWomkqnhykgCFT/EEiWTFsXhEstxYanwAFKOKx+lmzDQoGtabRLJtjoIktdKyz1aJZPkqHjHF07hlGpSkVsaJpnjaqIpHBV5HAwDTu+zb3qEUxqLowSFbQfu0GAm1Q2gFghgUdoHng3JVB14Zc8QHzu3cKJCh2AwGRdSgCGXdgP9cTs2oTUhHRe7FI0vxhBDJ8rd1vlQ57x1LNW6AIgQbLz9l387bR/MeA/PDFoEClChItRcPX2ZsKJJlt4xBSWriT1Qky50U7STS5JHJFM+s99ajW1KU27Zjiqde8dr6M8iC3SD/F1U343buw8PgYVAS1qCw46gqYeDEczn1FA8TybIKmZBToS/Fk4O5D0pBGEvVGyjxv4snQInpJFudAV74o/3/Pkeo3yMutFIEBShRoGIxWvLZYTQoCpFsUhN/kmXGPJXecSmeodaPpSisgmQMSkeUGSucTBnErrqAehKpSZgjjwaljUuMGfjqjaZpUDTHmvN/RkSysVM8gjOuWMbMw8egsFJlhV0+v33+M8PAKTNuBCf1qr1gGthX8x4yamtvyHLUaXy2KtXEhGgqDUrSAUqSJcv1Snut4HnwHZmBjDAoTCSr6dSrLDNugyI/lWuu+JhM2C6uEIOcZDtBg9KM9LRPgyJh68RrRFY0KFFLeB3WSNVGIUyKRxTJcoFIXAaF72a87QH7/sjhepE3aVDaHB7motVlxionWe4+U337qngaGpTEApQEq3jaqcxYBb4kFUi3zNgnkpXpAoLKbdtg/wcGKJLvrZpEZNobVRVPu6IZDIrPB0Wjd2JIPcUTt4qHGc8JDEoYkSw/Fvb6XKHRiFXYfpQxAt6FyvP32/dHNOkdz3vSZ1DaYImUQaTaiyfASZaHaDMtOonGhahxiYNOSvGIDEpWRbJiQMXQTgxWvgAgB8CSX1Blx5IyMJPQ/Tzb0hEpniZYJIjCUGmZcVZSPKJINmKAIlbxiJU5UgZF0KCo+vmw7dWrXo1LlNJ29ntXZ4EXHrPvjxyuf0+GjNqIQYmCNBkUpZOsZByi1b1sG7HG0gSRbDtY3avAiy/rdbeKJ7MiWUWKp50YlFxOX8kjDcxUDEqAk2xHVPHwDEqTUzy6BVTaAYrjJBvRqI3pR3wMisDQ8DBN8QBu8ChuPyychcq0N8WjfQ+leNobqVrdK1I8PC3ovFahEUmKXqUyYy+cibIKzO5xL4JZEMlKq1lUfiBtpEEB9AGK1h1WFZgpnGSn27hRIEMzTCZVIlktg5KxFE9YAarIoLDvJ26fhy/FwwS1dUmAwjQuM97/w4KN66XH7WtSoQQseFXAe9hiMX2jtja5AmUMqTrJaiqICiXvCccOajGASIxBSbCKh+8E3K4pHl5cxtI7xd50mwU6bdZlYlF2ERQn6oSt0JsNHSUdRYOidJJt7Je2TvG0oIpHZ9QmvqfVSKqKJ0iDYiSSVRi1Ad7qmyjjY2DH/faH7duFhwT/7k66PX0GhQKUKJBdwFoF7Umv0qcIY0wqQNn7YO9tHLST1b0KfDogzQoewE/TSidqNvmqym3bhMHSMig6HxQTJ1ku+GEunO3MoDTVSbZxHMk0KL4y4w6p4hF7+WhFsjX5az0+KIKZIAuAohrbifrDoPQO/54MaFAoQImCNJ1kde6M/IVVV+KXFHV/zAeBV50CDGhcCU3Ba1DaPsVTSbeCB/CWFwKKVa3KSbaDUjxaHxQTJ1nutR1RxdPEXjw6zx3xs8IaoyUFX4pHCAzCbofBKTM2cZIVjdpqkuBFZFBiBigMQRU8gPtdmHg3Lb0QSIMSDamKZPkgRJO64e83SyQLJBOcAF6avtZmEyQDv9pOs4IHcH/jquiDIpmoVSmedgkQdc6XOuZI6YPSwVU8OvO0qFA2C8xiikdVZhxRJOv8L4pk6/73hEnxiFb6UYMEcY4IE6AAqbMoFKBEgadZYEacZAFhXDqmJYMTDx+g1CWTaTuAZyTSTvEUBVZBq8Xg6GjL4i6WbZJiM0rx8GkbxSrXSW1Jzm/eSbZ3MN5400QzGRSfBiWDIllfs8CoKZ6i/P+cCYMiqfhRVfiwfRk3xcOw6LBw70nZTZYClChItVmgYeChE9OmdXHQIc9N7u22gmfgg6w0S4wB/6StTXVwFyFP9992CVA0ZZFiZ2/+9UqRrCTFU53tDAalGRoUUdMjLWnPSoAiBOVxq3jE7WpFskIwpDJqAziRbNwyY+432OsAsxL5PDEo7Y1UmwUqdCaAkNZpUwalzlXxZDGQ0kGW4kmjxBjwByi60k/+YlpvxwCFM6MSIbW6D/BBkYlkp3cBaDQj7JQApZVVPGKX3tTLjBPqZswgWt1rnWRlRm2K59gxHVYj44yL+w1MBLLOZzdM4ShAaUPILmAt+2zDvG5QOXLWwI836a7LrQKfDshMgKIRyco0KDwL0S4pnp5++7Y65X9Ot5r3aW80ZcaTO9338qW67YaWaFAkKR7AH7CkAWUVT0yRrJGTrFAlJq3iSdiojT/uTfQnQMP8MBtmbRSgREGaRm0e4ZlOJMsbuomvyyAzwV8snWaH7RagcBN+6lU8IUSyvAaFt71vFwalNMe+nRn3PydlUBSTiE4ky4Kf8rxoluNZgawXU1z4ApTGfhQZXlkTxlYjMZGsQoMSRiSba4UGhfu9TRkUwLvYShEUoERBVqzudSke8YLMl/VlceLnxzTLApQMBlI6yMqM06riMRHJysqM+Um6XSbi0lz7ljFvPLTl1SbNAoVjsJ3TO4DemyQqTESygMA8p53iSbiKx+ckKxxbluX3XGHbsGROsgojuLCIkuLhPy/lFE+bzQAZQarNAk2reCTmbOxgz2KAwud0na7LGRynDrzZHJss02ZQTESyshRPO+17xqDIAhQtc2TggyKe3+3chwdorpNsTSOSBdItLnA+V1HF02yRLM9S8g0B2WtFP5aCwKBELTOeu9AOFAf3BQZGzd+nq4xrIShAiYKsMCi6FI8vrVOOH403E6zpW23WTfG0iwaCga9myFoVT02mQZE4yTo6jDba9w6DIkvxhPFBkZUZC/uhnV1kAfnvHxfGDAq3X9MyavMEBXU4wue4ItkgJ1k+YJGmeBQus+z4jbq/+oaAC9bb50gYRjQjbrIZnKnaAGlSlaYW9jqX2ayujvM9DfaBpXjaaJIEhBRPxkSyUvtxdoGUMShttO8dBkWnQZH5oIgW/zINSqeleFrQzVgWFALZYFBynEbEEzSEZCiCNChW3U7rsKBAFqBojdoSEskCwPAB4d+jMz9sIUiDEgWpdjPWsCSe6gMhCNGVHWcFbF9W2rSKh11UZsddFihtBqWqaRaoKzNupwClrNOg6HxQVE6ymvO73RkUnTdJVIg+KLJjTfw/tRQP033UvCxH2AAlyOoe8AbA0gCFZ3MCRLKttpsnkWwbQ5ejbja0PXZMGZSMTj5OD4i69/92ARvvxAuNB3JAOSXXUcbc7HgYePkp81RHO3aSNmJQAjQo9br8uBPP745iUJpcZuxjUDIgkpUFBVHGo7K65wMXz/HFBSvsNSxtIzVqS0gkGxW8ni5FUIASBZnRoOiM2gxdZrMEXVDVDhC9A3oH0/N7WLocWPIGe9L+yYe4tFlAuW07dpJmGhRdmXGQD4pqsvIxKO0eoDSzm3EAg5KFMmOZ7iPKeIJEsoAQoDDH2rx7TeDTQT6jtoTKjKPCuZZJ/FxaCApQoiCrKR5djyCdRX5WIF4ksjpOFcRJPa30DmBf6M76tp2SePZuYMtd9uOdmOIJW2Ys06CoHHTFY7Ldq3h0/XGiIpIGJQNGbTJWw3g74rWqx/+4JUnxyPRNUqM2kUFJK0AhBqX9kMv5xUytQr7g79fAoK3waYcUj2bF1Q4Q92uaAQoA7LUfcNpXvY/JVtDSMuM22vfaMmOd9kbRg0jLoLR5gMKneBKr4hGYOJnuB8hWiseqc79/LnzApKziCdCg8N9ba9TGRLIpa1AoQGlTsJMvjQv50uXA0FJg3j7CmAwrfLI68fvGnNFxquALUIZSGYYHR7wbOOK97v+y48Cq2RUHQAeWGZtqUPgUTydrUJqQ6nVSZiKDoknZppbi4aY8dmxEGYsqxcNvPyhA0VbxsF48Kad4ZJb9LUToAGXt2rU4/fTTMTo6ilwuh+uuu855rlKp4OKLL8bhhx+OOXPmYHR0FB/4wAewdetWzzZ27tyJVatWYWBgAENDQzjvvPMwPi65uGQZx/4VcMjpdofIVuPcG4CP3huyikejXckKVLRpuyBLKR4ep365cZzm7MCWIS8R9LW1UZtOgyITBwdoBAD/yrWjGJQmaFBqFaCiMITMRBUP97lx2AkVg5LLyd1knRQO9z6eefIZtYkMColkjTAxMYEjjzwSa9as8T03OTmJe++9F5deeinuvfde/PSnP8Wjjz6KM844w/O6VatW4aGHHsItt9yCG2+8EWvXrsX5558f/VukgRWfBd77/XRyqfm8fPLuOJFsG02SgH+8WQlQegeAv7oT+Ot1Xk8E/jhwuru2oQbFqMw4ojg4l/M+1vYMShM1KM/cBXz1UGBmt/0/Y7Zkn9fqlIXsc+MwKKpuxvz2ZAydNMVTz6AGpU2N2lauXImVK1dKnxscHMQtt9zieezrX/86Xv/61+OZZ57B0qVL8cgjj+Cmm27CPffcg2OOOQYAcMUVV+DUU0/Fl7/8ZYyOhrDjJXihrfBpwoUpaejSUu0A0fgqrT48MvQO2n88+Im3VgF6+tq0zLgxEVanbVaE/x1MNSiyRoH869nz7R6glAeAw86ymSLGPMUFmzzHnrVv5ywE3vAR216dB/8btDplIfvcOAyKKsXD7tdmzEWy0hRP2j4o2TBqazpvtHv3buRyOQwNDQEA1q1bh6GhISc4AYAVK1Ygn89j/fr1eOc73+nbxszMDGZmZpz/x8bGmj3s9oSnikcnks3oxC9Oilm05NchqwyKCrKSyLYsM+Ym2tlxr/ZH6v8iWeGydI/MXZXfF+1exZPLAe/+brLbXPoGYN4osPergWM+CLz6VHmAm4UyY1mKJ0qwpErx8M+ZalC0Rm3T0ccYBxkRyTb1KJmensbFF1+M973vfRgYsE/sbdu2YeHChd5BFIsYHh7Gtm3bpNu57LLL8I//+I/NHGpnwNgGP6OTjzgpZjWQUiGrGhQVtBqUjB4jMhRK9gW9XrXTPHyAwvQQMg2KVbfp9XyemyBkqVPuMtnuGpRmYNFhwN88Evy6LIhkk0rxaBkUWYAi0aDwVTyiUZvY0yctDUqnOslWKhW85z3vgWVZ+OY3vxlrW5dccgl2797t/G3ZsiWhUXYYdB4pzbC4ThrtbtQmrqqyUMWjA18uz5gTp2FeG+37XE7thTLTYFv59JYsMNNpbzpJg5ImsiCSzeUANPrjxNKgaAT9UpFsEIMiBDA+NjktH5QOTPGw4OTpp5/Gbbfd5rAnADAyMoIdO3Z4Xl+tVrFz506MjIxIt1cul1Eul6XPETjoqnh0+pSsQOx2mpaQLir4jsxA9hkUwJ58eYq5HVM8gB2gTO/yVvJUpl2KnA9QPOLgCoCSvryavb5Q9gf+BHNkQSQLNNi2SjwBqs/qPoJIVuokK/FTAVJM8XQYg8KCk8cffxy//vWvMX/+fM/zy5cvx65du7Bx40bnsdtuuw31eh3HHnts0sPpLrS9SLYNgqgg8BeqdghQRL+DdiwzBuSlxow9QQ4occyHTHvjiGQlEwF7PbEn8ZCZAKXx2Q6DEnEsfNDgKR8W0jNAdKM22fZbgYw4yYZmUMbHx/HEE084/2/evBmbNm3C8PAw9tlnH7zrXe/CvffeixtvvBG1Ws3RlQwPD6NUKuGQQw7BKaecgg996EO48sorUalUcOGFF+Kcc86hCp64aPdmgZ4usm02QTIUegC26MhSFY8KzsVaTPG0mUBZVmo83Sh3LQ8I3iZ89ZLAHEnL9xuPUYASD1lI8QBuYFCNkeIB7HOn1ghCPMEX1wSQQey1w3+uTiTLf1YrkRGjttC/zIYNG3DiiSc6/69evRoAcO655+If/uEfcP311wMAjjrqKM/7br/9dpxwwgkAgKuvvhoXXnghTjrpJOTzeZx99tm4/PLLI34FggNtL542YCeyIKKLC/47ZF2DAnBiuE5hUCQBiq+8Og9bh2BxDIomxcMea/cKnrSRlQAlqQqZfFGuY3ECjzBOsoJRmy9A6U6jttDf+oQTToDFbLEl0D3HMDw8jGuuuSbsRxOCoDNqa4ZBU9Joh1LoILATu9hn+4pkHc7FtMEgVKbsW95xtB0gs7uf3mXfigEKYB9rtVn3e+uYI/YYVfDEg2xyTmUcjSAgjkgWEFI8EUSyOY5pEY3axOOwS8uMqRdPJ8E4xZPRyb8dSqGDwMbdDuwJ4F4I2QVyapd92y7jZ2AMygwfoCgYFMAvZNSJg/OU4kkEmWNQYpqgqVoiGItkuXMvcykeVt3XZr14CBmGtopH4gORNei6yLYLnAClDQSyAEflNiZoh3UYSmM00SErM56WlBgziP14gpxkAWJQ4iILTrL8Z9diBij8d5Clp60AHxRts8C0RbLEoBCSRruLZNuB5QkCG3fbBChCiqfdGZRZUwZFoOF1/i9UxZMMChL2IA3kkxLJ8t/HVCSrqOJRGbWJr20V2HWsU43aCClAZ9TWFiLZNjCTCwK7sLQLAyGq9dueQTEMUMR+PDXJBCK+lgKUeMhMikdkUGJU8Tj3o4hk+Soe0agtbZFsNnrxUIDSSShoUiTtIJLNtwHLE4S2S/Gwi3XjAtr2DIpBFQ/g1wmYOMlSFU88yDpKpwGxzDgqO+FJ8ciYkSANSmP61TULdF5LRm2EdoeHJdE0C8wqO9FRKZ6hVIdhDLHMuF0ZFJ0Pii5AEX1QZCtVtu2+4fjj7GZkzqgtSZGsghlhkPmgOIGMzEk27QClTcuMCRmGVoPS+D9fhM+mOStoB51MENiFpW0CFE6DUqu4KZJ2C1DCpnh8DIomxXPcRcDAKHDomcmMtVuRhW7G/Gc3TYPCiV8ZxDJi/r7UqE24/rVag3LQ24Dz75SfOy0EBSidBF0VDGNUssqeAB1SZtxmIlleg8ImdCD1C1NohC0zFjUoOpHsyOH2HyEesqJBaUYVT2A34yCjtrr3MXFMrd5f/cP2X8rI6FKaEAlakWyP/zVZg2pF0k541cnA3BFg/z9LeyRm4FMdTH9Smtd+VvfSMuOEfFAIySArTtGMQa4mKJKVVSiFqeIRU0BpdzPOCNrsKkTQwnH/zPkvtCxgyTIz0QkMyrF/Bbz+/EZb9zYAn+JhE3q7pKd4aAMUibhV1KA4Ilm6JDYNmdGgsN8+yWaBpiJZiQ+KSS+eNH1jUgSdjZ2EuXsDr/u/dnpB1JmwyT/LE38niGSB9glOACHF87J9v930JwBXxbPHfSwUg6LRoBCSQdaM2hiDErkXj8LqXiqSlWlQWIpHJpIlBgWgAKXzcNpX5I/v/WpgcCnwije3djxh0Aki2XYD3824XUuMAX+ZcXUWqDb6ChlpUCjF03RkJsUjMihJp3hkIlldiqcqMWoTNSgUoBA6GeV5wCfuz/bqvhN8UNoNTplxTd9cL+tgpcC1WTs4mRnjntOkeEycZAnJICsi2bzAoCTSLDCKSFYIlPj3pt3NOCPozm/drchycAK0h9ttp4FnEliJbjsyKD1z3PuVCTe9Ux6Qrz7D+KAQkoGsFDcNsC7CsX1QglI8hlU8VT5AYd2MUy4zzgioioeQHXhoUlrJtgS8pXW7mrQBQLHkBrUz48FskE+D0pgkKDBuHrKW4qnGFMnK2BBAIZKVaFDEcmf+eWJQAFCAQsgSKMXTevCrvXbWoABeHYpOIAv4NSiTL9m3GfB+6Fhkxeo+qV48OW76lJYZB1ndaxiUtJ1kMwIKUAjZQSeUGbcbPGXGu+z77cigALZ/C2AWoIjdjCdesG/n7N288XU7ssKgJNWLR9ks0FAkKwZK/GO+MuPunKq7kzciZBOeZodEtbcEfJmxw6C0iQuuCL7UODBAYb1GWIDyon07Z0HzxtftKA/YWqFiOd0UrpPWTFIkK9HXmBq1VbkAhQUiPqO27pyqu/NbE7IJYlBaj07RoADhUjwiDU8MSvPR0wuc9yv73E6zH5jjJNskDYpWJCthXfhqIlbIQCkeABSgELIEzyqEApSWgJ+op9rYSRbwdjQOo0Gp11wNCgUozcXIa9IeQXK9eGSusPz2TY3aZH4saffiyQi6M7FFyCY6xUm2neBxkt1l329HHxTA29E4jAZl6mXbzRMA+uc3d4yE9JGUURtLx+R7vBYOor6Jv+9J8TTeL5q0sW16Pqs7GRQKUAjZATnJth4OzTztmpu1e4pnxiRA4TQoLL3Ttxcdd92ApNiJIFM1FvQCeqM22f+U4gFAAQohSyANSuvBLoSTO93H2jXFE1WDQvqT7oLIRkSu4lGYqmkZFEVaSPyfuhkDoACFkCXkKcXTcjgBSkOD0TOnfYNDT4qnwQbJbO4BrwaFApTuQlJ9bpR9c2QiWY1Rm/g+wF9WTCkeAiFlFEgk23Kwfe6kOYZSG0pslEKIZPlSUKfEmAKUrkDiKR6FXiTQqE2Txsnl9K/tElCAQsgOSIPSerCLK5uk21V/AnApnjAaFGJQug5J6TtyKg2KaYAiTL++7WSkd1GKoACFkB1Qs8DWg134WAVPWzMopEEhGECXWgkDdu4UwohkFe6z4nPi810aoHQnb0TIJvIFADkAFjEorYK4n9uZQSk3rO6ndtkdjQGNDwpn8c8EwuQi2x1oehVPyGaBqnEUNK/tEhCDQsgW2IRJAUprIF4UO4FBGXvOfUwlkuWFjMSgdBfEACVqn5ucQoOidZINYcZGGhQKUAgZA0vtUIqnNRAvru3MoLAAZc/zjf/n+el3BtKgdC8ST/EkJJL1jYs0KBSgELIFp904MSgtgTiBtzWD0qjiYQ6hOkdcjwaFqni6ComleNi1SlG2bOokazIuSvEQCBmAw6B0J6XZcogX57ZmUOZ6/9cFKOz4mp1wHXRJg9IdSKyKh7O6l23fI5JlGhSdUZtmXMSgEAgZwBHvAUaXAXsfkvZIugPixbWtGZQ53v9NGBSWDsr3tG8PIkI4JJ3iiVxmrNGcAIIvVHcGKLRMJWQLJ38u7RF0FzqKQQkToDQu/ixAmbO3t+EboXPh8x+J6YPis6U3FMn6AiVdmXF3TtXEoBAI3YxO1KAwmDAojkCW0jtdgyBxatjt+KqCJAxKreL/7DBVPKRBIRAIXQcfg9LGaY5CESj2uv+baFAYSCDbPUg8xaNqFijrxcPb2RODEgQKUAiEbkYnlRkD3jRPr8IDBfBf8ClA6R4EaT9MwUSyqhSPFeSDkodtTKkYh0eD0p1TdXd+awKBYKOTUjyAEKAYaFAYKMXTPfAxFRGnQYdBiVhmLL6XUjw+UIBCIHQz+ItgsQ8oltMbSxIozXPvm2hQGIhB6R74/Efi+qBEFMmK/+tSPpTiIRAIXQf+4tru7AlgzqCQBqV7kVSKZ3CJfTu0xPu41ElWokHhXyt7jpxkqcyYQOhq8BfndtefACFSPBSgdC10QUIYHHomcP4dwMJD5ds3YlAMUzxdyqB057cmEAg2eCahExiUMldqTBoUggxJVfHkcrappAhTkSygD1B4kWzUhoZtju781gQCwQY/UXcEg2IaoBCD0rVIyupeuf0QIlltiqfxfy7ftSaCFKAQCN2MfIcxKJ4Uz5D6dT4NCjEoXQNVIJDY9gWRbL0OwPI+J/tslQ9Kl6Z3AApQCITuRqHTGBQuQCkb+qCU5gE9fc0bEyFbSKqKR7l9QYPCMylhzNgYu9mlJcYABSgEQneDv2B2BIPSKDMuzdV3xOZTW8SedBeSquJRbl9I8XgCFF2KRzEuYlAIBEJXouM0KA0GJciyn7/oz13YvPEQsoekqniU2xdEsroAhTeJ84lki/7XdBm695sTCARviqcjGBTDAIVnV0gg211otUhWG6DojNqIQaEAhUDoZnSaDwoLTPr20r+O/96U4ukuJFVmrIJPJMuVG0cxautiDUr3hmYEAqFxUcwBsDqDQXnlScBrPwAc9k796zwaFGJQugpiyiRpBoWJcEWRbK7gLxfWGrUpev10EShAIRC6HfkiUK8Ep0XaAeV5wBlXBL8uTymerkXTRbKMQWkEJpVJ+1ZWKWbiJEspHgKB0LXY50h7kh7aL+2RtA4FSvF0LVqV4mEi2YkX7dv++fqxiEwJ04d1qYssQAwKgUD44C9tBqXUn/ZIWgdiULoXPh1IwgGAKJKdeMG+lR1nZNSmRfd+cwKBYKNYAlBKexStBWlQuhetSvFYdcCygMkGgyINUHRGbSxA6V4NSvdyRwQCoXuRLwLFPnv1PHdR2qMhtBJNd5Lltl+vcQxKUIqHNCgiuvebEwiE7kU+D7zrO0BlCugfTns0hFaiVb14ADvNM6FjUAy6GVOZMYFAIHQZDj4t7REQ0oDObj7p7Vs1cw2K0qitexMd3fvNCQQCgdB94AOBXD75AIAPOngGpV9SLaY1amM+KN3LI1CAQiAQCITugY61SGT7fIqnxqV4JAGK1geFUjyhA5S1a9fi9NNPx+joKHK5HK677jrP85Zl4TOf+Qz22Wcf9PX1YcWKFXj88cc9r9m5cydWrVqFgYEBDA0N4bzzzsP4+HisL0IgEAgEQiB0QUESUIpko1bxEINijImJCRx55JFYs2aN9PkvfelLuPzyy3HllVdi/fr1mDNnDk4++WRMT087r1m1ahUeeugh3HLLLbjxxhuxdu1anH/++dG/BYFAIBAIJtBVziSy/Zz7GfUKMPmSfV/GoPDBjMqorYvLjEP/OitXrsTKlSulz1mWhX/7t3/D//t//w9nnnkmAOB73/seFi1ahOuuuw7nnHMOHnnkEdx000245557cMwxxwAArrjiCpx66qn48pe/jNHR0Rhfh0AgEAgEDTysRZNUDvkiUGukd5ijrEyDomNQFr0GKJSBfV/bnDG2ARL9dTZv3oxt27ZhxYoVzmODg4M49thjsW7dOgDAunXrMDQ05AQnALBixQrk83msX79eut2ZmRmMjY15/ggEAoFACI1mp3j4z9izzb7tHWwYIurGIjAliw4FLn4KeOs/NWWI7YBEA5Rt2+wfY9Eir/HRokWLnOe2bduGhQsXep4vFosYHh52XiPisssuw+DgoPO3ZMmSJIdNIBAIhG5BrskiWcANfMYbc5qMPRE/XxYsdVP7CQnaoornkksuwe7du52/LVu2pD0kAoFAILQjWsGgMG3Jnu32raqdgi7FQ0g2QBkZGQEAbN++3fP49u3bnedGRkawY8cOz/PVahU7d+50XiOiXC5jYGDA80cgEAgEQmi0JMUjMCiqjtm8BqaLy4lVSDRAOeCAAzAyMoJbb73VeWxsbAzr16/H8uXLAQDLly/Hrl27sHHjRuc1t912G+r1Oo499tgkh0MgEAgEgheetEoTRbKAq0FRBSg6ozZC+Cqe8fFxPPHEE87/mzdvxqZNmzA8PIylS5fiE5/4BP7lX/4FBx10EA444ABceumlGB0dxTve8Q4AwCGHHIJTTjkFH/rQh3DllVeiUqngwgsvxDnnnEMVPAQCgUBoLlqRVhFFspTiiYTQe2TDhg048cQTnf9Xr14NADj33HNx1VVX4e/+7u8wMTGB888/H7t27cJxxx2Hm266Cb29vc57rr76alx44YU46aSTkM/ncfbZZ+Pyyy9P4OsQCAQCgaBBK6t4xoM0KC0YSxsj9B454YQTYFmW8vlcLod/+qd/wj/9k7o0anh4GNdcc03YjyYQCAQCIR5aUcWTExiU/vnBY6EUjw9tUcVDIBAIBEIiyOcB5Br3m1xmXK/Yt8SgRAIFKAQCgUDoLjS7U7C4XaMAhRgUERSgEAgEAqG74DTiaxaDImzXqIqHGBQRFKAQCAQCobuQazaDwgcoOaBvWPE6quLRgQIUAoFAIHQXmp3i4ZmR/mGgoPicfAsEu20MClAIBAKB0F1ggUGuyUZtgLoPD0BVPAGgAIVAIBAI3YVWpnhUAlnxdZTi8YECFAKBQCB0F1pZxaMSyPLjaOZY2hgUoBAIBAKhu9DKKh5dgEIpHi0oQCEQCARCd8FJ8TTZSRYISPFQFY8OFKAQCAQCobvAuhhnKsVDDIoIClAIBAKB0F1gAUSzSnv5YENbxcNNwcSg+EABCoFAIBC6C5mp4qEUjw4UoBAIBAKhu+CIZFuR4jEsMyajNh8oQCEQCARCd8HRoDRpCsxFqeIhBkUEBSgEAoFA6C40PcXDaVx6h4Jfh1zzgqU2Bu0RAoFAIHQXmp7iaQRAcxboA49mVxO1OShAIRAIBEJ3wenF0+QqHl0FD//5VGIsBQUoBAKBQOguNDswYIyITn/Cv44YFCkoQCEQCARCd6HZvXhYAKSr4PGMgxgUGShAIRAIBEJ3odmBgSmD0myxbpuDAhQCgUAgdBeaHRgcfBqw8DDg0HfoX9dsJqfNQXuFQCAQCN2FZms/Dvgz4K9/bzCOJot12xzEoBAIBAKhu+AEBilPgZTi0YICFAKBQCB0F3IZ8R9xmBxiUGSgsI1AIBAI3YWslPfucwSw79HAQW9LdxwZBQUoBAKBQOgu9A3Zt72DqQ4DpTnAh25LdwwZBgUoBAKBQOguHP93wKLXAK85K+2REDSgAIVAIBAI3YXBfYHXfyjtURACQCJZAoFAIBAImQMFKAQCgUAgEDIHClAIBAKBQCBkDhSgEAgEAoFAyBwoQCEQCAQCgZA5UIBCIBAIBAIhc6AAhUAgEAgEQuZAAQqBQCAQCITMgQIUAoFAIBAImQMFKAQCgUAgEDIHClAIBAKBQCBkDhSgEAgEAoFAyBwoQCEQCAQCgZA5tGU3Y8uyAABjY2Mpj4RAIBAIBIIp2LzN5nEd2jJA2bNnDwBgyZIlKY+EQCAQCARCWOzZsweDg4Pa1+QskzAmY6jX69i6dSvmzZuHXC6X6LbHxsawZMkSbNmyBQMDA4luu11B+8QL2h9+0D7xg/aJH7RP/Oi2fWJZFvbs2YPR0VHk83qVSVsyKPl8HosXL27qZwwMDHTFwRIGtE+8oP3hB+0TP2if+EH7xI9u2idBzAkDiWQJBAKBQCBkDhSgEAgEAoFAyBwoQBFQLpfx2c9+FuVyOe2hZAa0T7yg/eEH7RM/aJ/4QfvED9onarSlSJZAIBAIBEJngxgUAoFAIBAImQMFKAQCgUAgEDIHClAIBAKBQCBkDhSgEAgEAoFAyBwoQOGwZs0a7L///ujt7cWxxx6Lu+++O+0htQyXXXYZXve612HevHlYuHAh3vGOd+DRRx/1vGZ6ehoXXHAB5s+fj7lz5+Lss8/G9u3bUxpxa/GFL3wBuVwOn/jEJ5zHunF/PPfcc/iLv/gLzJ8/H319fTj88MOxYcMG53nLsvCZz3wG++yzD/r6+rBixQo8/vjjKY64uajVarj00ktxwAEHoK+vDwceeCD++Z//2dNnpNP3ydq1a3H66adjdHQUuVwO1113ned5k++/c+dOrFq1CgMDAxgaGsJ5552H8fHxFn6LZKHbJ5VKBRdffDEOP/xwzJkzB6Ojo/jABz6ArVu3erbRafskCihAaeBHP/oRVq9ejc9+9rO49957ceSRR+Lkk0/Gjh070h5aS3DnnXfiggsuwF133YVbbrkFlUoFb3vb2zAxMeG85qKLLsINN9yAa6+9FnfeeSe2bt2Ks846K8VRtwb33HMPvvWtb+GII47wPN5t++Pll1/Gm970JvT09OCXv/wlHn74YXzlK1/BXnvt5bzmS1/6Ei6//HJceeWVWL9+PebMmYOTTz4Z09PTKY68efjiF7+Ib37zm/j617+ORx55BF/84hfxpS99CVdccYXzmk7fJxMTEzjyyCOxZs0a6fMm33/VqlV46KGHcMstt+DGG2/E2rVrcf7557fqKyQO3T6ZnJzEvffei0svvRT33nsvfvrTn+LRRx/FGWec4Xldp+2TSLAIlmVZ1utf/3rrggsucP6v1WrW6Oioddlll6U4qvSwY8cOC4B15513WpZlWbt27bJ6enqsa6+91nnNI488YgGw1q1bl9Ywm449e/ZYBx10kHXLLbdYb37zm62Pf/zjlmV15/64+OKLreOOO075fL1et0ZGRqx//dd/dR7btWuXVS6XrR/84AetGGLLcdppp1l/+Zd/6XnsrLPOslatWmVZVvftEwDWz372M+d/k+//8MMPWwCse+65x3nNL3/5SyuXy1nPPfdcy8beLIj7RIa7777bAmA9/fTTlmV1/j4xBTEoAGZnZ7Fx40asWLHCeSyfz2PFihVYt25diiNLD7t37wYADA8PAwA2btyISqXi2UcHH3wwli5d2tH76IILLsBpp53m+d5Ad+6P66+/Hscccwze/e53Y+HChVi2bBn+4z/+w3l+8+bN2LZtm2efDA4O4thjj+3YffLGN74Rt956Kx577DEAwB/+8Af89re/xcqVKwF05z7hYfL9161bh6GhIRxzzDHOa1asWIF8Po/169e3fMxpYPfu3cjlchgaGgJA+4ShLZsFJo0XX3wRtVoNixYt8jy+aNEi/PGPf0xpVOmhXq/jE5/4BN70pjfhNa95DQBg27ZtKJVKzgnEsGjRImzbti2FUTYfP/zhD3Hvvffinnvu8T3XjfvjT3/6E775zW9i9erV+Pu//3vcc889+NjHPoZSqYRzzz3X+d6y86hT98mnPvUpjI2N4eCDD0ahUECtVsPnPvc5rFq1CgC6cp/wMPn+27Ztw8KFCz3PF4tFDA8Pd8U+mp6exsUXX4z3ve99TrPAbt8nDBSgEHy44IIL8OCDD+K3v/1t2kNJDVu2bMHHP/5x3HLLLejt7U17OJlAvV7HMcccg89//vMAgGXLluHBBx/ElVdeiXPPPTfl0aWDH//4x7j66qtxzTXX4LDDDsOmTZvwiU98AqOjo127TwjmqFQqeM973gPLsvDNb34z7eFkDpTiAbBgwQIUCgVfBcb27dsxMjKS0qjSwYUXXogbb7wRt99+OxYvXuw8PjIygtnZWezatcvz+k7dRxs3bsSOHTvw2te+FsViEcViEXfeeScuv/xyFItFLFq0qKv2BwDss88+OPTQQz2PHXLIIXjmmWcAwPne3XQeffKTn8SnPvUpnHPOOTj88MPx/ve/HxdddBEuu+wyAN25T3iYfP+RkRFfMUK1WsXOnTs7eh+x4OTpp5/GLbfc4rAnQPfuExEUoAAolUo4+uijceuttzqP1et13HrrrVi+fHmKI2sdLMvChRdeiJ/97Ge47bbbcMABB3ieP/roo9HT0+PZR48++iieeeaZjtxHJ510Eh544AFs2rTJ+TvmmGOwatUq53437Q8AeNOb3uQrPX/sscew3377AQAOOOAAjIyMePbJ2NgY1q9f37H7ZHJyEvm89zJaKBRQr9cBdOc+4WHy/ZcvX45du3Zh48aNzmtuu+021Ot1HHvssS0fcyvAgpPHH38cv/71rzF//nzP8924T6RIW6WbFfzwhz+0yuWyddVVV1kPP/ywdf7551tDQ0PWtm3b0h5aS/CRj3zEGhwctO644w7r+eefd/4mJyed13z4wx+2li5dat12223Whg0brOXLl1vLly9PcdStBV/FY1ndtz/uvvtuq1gsWp/73Oesxx9/3Lr66qut/v5+6/vf/77zmi984QvW0NCQ9fOf/9y6//77rTPPPNM64IADrKmpqRRH3jyce+651r777mvdeOON1ubNm62f/vSn1oIFC6y/+7u/c17T6ftkz5491n333Wfdd999FgDrq1/9qnXfffc5FSkm3/+UU06xli1bZq1fv9767W9/ax100EHW+973vrS+Umzo9sns7Kx1xhlnWIsXL7Y2bdrkud7OzMw42+i0fRIFFKBwuOKKK6ylS5dapVLJev3rX2/dddddaQ+pZQAg/fvud7/rvGZqasr667/+a2uvvfay+vv7rXe+853W888/n96gWwwxQOnG/XHDDTdYr3nNa6xyuWwdfPDB1re//W3P8/V63br00kutRYsWWeVy2TrppJOsRx99NKXRNh9jY2PWxz/+cWvp0qVWb2+v9YpXvML69Kc/7ZloOn2f3H777dJrx7nnnmtZltn3f+mll6z3ve991ty5c62BgQHrgx/8oLVnz54Uvk0y0O2TzZs3K6+3t99+u7ONTtsnUZCzLM7ykEAgEAgEAiEDIA0KgUAgEAiEzIECFAKBQCAQCJkDBSgEAoFAIBAyBwpQCAQCgUAgZA4UoBAIBAKBQMgcKEAhEAgEAoGQOVCAQiAQCAQCIXOgAIVAIBAIBELmQAEKgUAgEAiEzIECFAKBQCAQCJkDBSgEAoFAIBAyBwpQCAQCgUAgZA7/P/Ktpv7kMctsAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot true/pred prices graph\n",
    "plot_graph(final_df)\n",
    "plt.plot(model.predict(data[\"X_test\"]))\n",
    "plt.plot(data[\"y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  open        high         low       close    adjclose  \\\n",
      "2022-09-09  130.910004  133.690002  130.759995  133.270004  133.270004   \n",
      "2022-09-26  113.300003  117.339996  113.129997  115.150002  115.150002   \n",
      "2022-10-03  113.580002  116.910004  112.449997  115.879997  115.879997   \n",
      "2022-10-04  119.889999  123.000000  119.790001  121.089996  121.089996   \n",
      "2022-10-05  118.580002  121.750000  117.690002  120.949997  120.949997   \n",
      "2022-10-07  118.000000  118.169998  113.879997  114.559998  114.559998   \n",
      "2022-10-10  115.099998  116.250000  112.430000  113.669998  113.669998   \n",
      "2022-10-12  112.489998  113.830002  111.400002  112.900002  112.900002   \n",
      "2022-10-14  114.099998  114.959999  106.599998  106.900002  106.900002   \n",
      "2022-10-17  110.110001  114.190002  110.089996  113.790001  113.790001   \n",
      "\n",
      "              volume ticker  adjclose_15  true_adjclose_15  buy_profit  \\\n",
      "2022-09-09  49387600   AMZN   155.866974        113.000000  -20.270004   \n",
      "2022-09-26  62723300   AMZN   155.866974        113.790001   -1.360001   \n",
      "2022-10-03  50941900   AMZN   155.866974        119.820000    3.940002   \n",
      "2022-10-04  62812600   AMZN   155.866974        120.599998   -0.489998   \n",
      "2022-10-05  48217500   AMZN   155.866974        115.660004   -5.289993   \n",
      "2022-10-07  54678000   AMZN   155.866974        103.410004  -11.149994   \n",
      "2022-10-10  42339700   AMZN   155.866974        102.440002  -11.229996   \n",
      "2022-10-12  45728700   AMZN   155.866974         92.120003  -20.779999   \n",
      "2022-10-14  67737300   AMZN   155.866974         90.980003  -15.919998   \n",
      "2022-10-17  62782000   AMZN   155.866974         90.529999  -23.260002   \n",
      "\n",
      "            sell_profit  \n",
      "2022-09-09          0.0  \n",
      "2022-09-26          0.0  \n",
      "2022-10-03          0.0  \n",
      "2022-10-04          0.0  \n",
      "2022-10-05          0.0  \n",
      "2022-10-07          0.0  \n",
      "2022-10-10          0.0  \n",
      "2022-10-12          0.0  \n",
      "2022-10-14          0.0  \n",
      "2022-10-17          0.0  \n"
     ]
    }
   ],
   "source": [
    "print(final_df.tail(10))\n",
    "# save the final dataframe to csv-results folder\n",
    "csv_results_folder = \"csv-results\"\n",
    "if not os.path.isdir(csv_results_folder):\n",
    "    os.mkdir(csv_results_folder)\n",
    "csv_filename = os.path.join(csv_results_folder, model_name + \".csv\")\n",
    "final_df.to_csv(csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 50, 256)           268288    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 50, 256)           0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 793,857\n",
      "Trainable params: 793,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "training = history\n",
    "# plot\n",
    "metrics = [k for k in training.history.keys() if (\"loss\" not in k) and (\"val\" not in k)]    \n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(15,3))\n",
    "       \n",
    "## training    \n",
    "ax[0].set(title=\"Training\")    \n",
    "ax11 = ax[0].twinx()    \n",
    "ax[0].plot(training.history['loss'], color='black')\n",
    "\n",
    "ax[0].set_xlabel('Epochs')\n",
    "\n",
    "ax[0].set_ylabel('Loss', color='black')    \n",
    "for metric in metrics:        \n",
    "    ax11.plot(training.history[metric], label=metric)\n",
    "    ax11.set_ylabel(\"Score\", color='steelblue')    \n",
    "ax11.legend()\n",
    "        \n",
    "## validation    \n",
    "ax[1].set(title=\"Validation\")    \n",
    "ax22 = ax[1].twinx()    \n",
    "ax[1].plot(training.history['val_loss'], color='black')\n",
    "\n",
    "ax[1].set_xlabel('Epochs')\n",
    "\n",
    "ax[1].set_ylabel('Loss', color='black')    \n",
    "for metric in metrics:          \n",
    "    ax22.plot(training.history['val_'+metric], label=metric)\n",
    "    ax22.set_ylabel(\"Score\", color=\"steelblue\")    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6df2b51ba2ec4e9504663404d06fe0b03ff488de6ac12462c4ded2a6159bdf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
